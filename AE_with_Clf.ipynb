{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6uFq9eWOXnl0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "from notebook.services.config import ConfigManager\n",
        "cm = ConfigManager().update('notebook', {'limit_output': 20})\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "yn5nspAuaFKa",
        "outputId": "6b8c33d5-f90f-4f14-ab49-58eddc73557e"
      },
      "outputs": [],
      "source": [
        "Nor_path = \"./Dataset/Normal_mixed.csv\"\n",
        "col_names = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
        "                \"land\", \"wrong_fragment\", \"urgent\", \"count\", \"srv_count\", \"serror_rate\",\n",
        "                \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
        "                \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
        "                \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
        "                \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
        "                \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"]\n",
        "Nor_df = pd.read_csv(Nor_path, header=None,names= col_names, nrows= 600000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "1XsOye7gfrZn",
        "outputId": "dcf538e5-8627-4d38-92a9-eac28001e26a"
      },
      "outputs": [],
      "source": [
        "Abnor_path = \"./Dataset/Abnormal.csv\"\n",
        "Abnor_df = pd.read_csv(Abnor_path, header=None,names= col_names, nrows= 500000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train_nor, Test_nor = train_test_split(Nor_df, test_size=0.2, random_state=1)\n",
        "Train_abnor, Test_abnor = train_test_split(Abnor_df, test_size=0.2, random_state=1) \n",
        "\n",
        "Train = pd.concat([Train_nor, Train_abnor], ignore_index=True)\n",
        "Test = pd.concat([Test_nor, Test_abnor], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train_4classes = Train_abnor[Train_abnor['label'].isin(['DoS_Gas', 'BP', 'OaU','FoT'])]\n",
        "\n",
        "Train_3classes = Train_abnor[Train_abnor['label'].isin(['DoS', 'FoT','BP'])]\n",
        "\n",
        "Train_2classes = Train_abnor[Train_abnor['label'].isin(['DoS','BP'])]\n",
        "\n",
        "Train_1class = Train_abnor[Train_abnor['label'].isin(['OaU'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train_DoS = Train_abnor[Train_abnor['label'].isin(['DoS'])]\n",
        "Train_DoSGas = Train_abnor[Train_abnor['label'].isin(['DoS_Gas'])]\n",
        "Train_FoT = Train_abnor[Train_abnor['label'].isin(['FoT'])]\n",
        "Train_BP = Train_abnor[Train_abnor['label'].isin(['BP'])]\n",
        "Train_OaU = Train_abnor[Train_abnor['label'].isin(['OaU'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train_nor_unlab, Train_nor_lab = train_test_split(Train_nor,test_size=0.1, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((48000, 29), (432000, 29))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Train_nor_lab.shape , Train_nor_unlab.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train_nor_lab = Train_nor_lab[:500]\n",
        "Train_abnor_lab = Train_4classes[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((500, 29), (500, 29), array(['DoS_Gas', 'FoT', 'OaU', 'BP'], dtype=object))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Train_nor_lab.shape, Train_abnor_lab.shape , Train_abnor_lab['label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_hot_encode(data):\n",
        "    unique_labels = [\n",
        "    [\"tcp\", \"udp\", \"icmp\"],\n",
        "    [\"other\", \"private\", \"ecr_i\", \"urp_i\", \"urh_i\", \"red_i\", \"eco_i\", \"tim_i\", \"oth_i\", \"domain_u\", \"tftp_u\", \"ntp_u\", \"IRC\", \n",
        "                \"X11\", \"Z39_50\", \"aol\", \"auth\", \"bgp\", \"courier\", \"csnet_ns\", \"ctf\", \"daytime\", \"discard\", \"domain\", \"echo\", \"efs\", \"exec\", \n",
        "                \"finger\", \"ftp\", \"ftp_data\", \"gopher\", \"harvest\", \"hostnames\", \"http\", \"http_2784\", \"http_443\", \"http_8001\", \"icmp\", \"imap4\",\n",
        "                \"iso_tsap\", \"klogin\", \"kshell\", \"ldap\", \"link\", \"login\", \"mtp\", \"name\", \"netbios_dgm\", \"netbios_ns\", \"netbios_ssn\", \"netstat\",\n",
        "                \"nnsp\", \"nntp\", \"pm_dump\", \"pop_2\", \"pop_3\", \"printer\", \"remote_job\", \"rje\", \"shell\", \"smtp\", \"sql_net\", \"ssh\", \"sunrpc\", \n",
        "                \"supdup\", \"systat\", \"telnet\", \"time\", \"uucp\", \"uucp_path\", \"vmnet\", \"whois\"],\n",
        "    [\"SF\", \"S0\", \"S1\", \"S2\", \"S3\", \"REJ\", \"RSTOS0\", \"RSTO\", \"RSTR\", \"SH\", \"RSTRH\", \"SHR\", \"OTH\"],\n",
        "    [\"Normal\",\"OaU\",\"DoS\",\"DoS_Gas\",\"FoT\",\"BP\"]\n",
        "    ]\n",
        "    encoded_data = []\n",
        "    # Thực hiện mã hóa one-hot\n",
        "    for row in data:\n",
        "        encoding = []\n",
        "        for i, column_value in enumerate(row):\n",
        "            unique_column_values = unique_labels[i]\n",
        "            encoding.extend([1 if column_value == unique else 0 for unique in unique_column_values])\n",
        "        encoded_data.append(encoding)\n",
        "    return np.array(encoded_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder( handle_unknown='ignore')\n",
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_test(df, is_fit=True):\n",
        "    # chuyển normal thành 1 và các lớp khác thành 0\n",
        "    label = df['label'].map(lambda x: 'Abnormal' if x != 'Normal' else x)\n",
        "\n",
        "    # loại bỏ cột dữ liệu không cần thiết\n",
        "    #df = df.drop([\"label\"], axis=1)\n",
        "    df = df.drop([\"land\", \"wrong_fragment\",  \"urgent\", \"rerror_rate\",  \"srv_rerror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"], axis=1)\n",
        "\n",
        "    # chia dữ liệu ra số, chữ để tiện xử lý\n",
        "    numerical_data = df.select_dtypes(exclude='object').values\n",
        "    categorical_data = df.select_dtypes(include='object').values\n",
        "\n",
        "    categorical_data = one_hot_encode(categorical_data)\n",
        "\n",
        "    # nối dữ liệu số và onehot lại\n",
        "    data = np.concatenate([numerical_data, categorical_data], axis=1)\n",
        "\n",
        "    # chỉ fit với dữ liệu train\n",
        "    if is_fit:\n",
        "        scaler.fit(data)\n",
        "\n",
        "    # dữ liệu chuẩn hóa về dạng [0, 1]\n",
        "    data = scaler.transform(data)\n",
        "\n",
        "    return dict(data=data, label=label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dùng hàm preprocess_test\n",
        "Train_nor = preprocess_test(Train_nor, True)\n",
        "Train_abnor = preprocess_test(Train_abnor, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train_nor_unlab = preprocess_test(Train_nor_unlab, True)\n",
        "Train_nor_lab = preprocess_test(Train_nor_lab, True)\n",
        "Train_abnor_lab = preprocess_test(Train_abnor_lab, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((432000, 106), (500, 106), (500, 106))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Train_nor_unlab['data'].shape, Train_nor_lab['data'].shape, Train_abnor_lab['data'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((480000, 106), (293936, 106))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Train_nor['data'].shape , Train_abnor['data'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = preprocess_test(Test, False)\n",
        "Test_nor = test['data'][test['label'] == 'Normal']\n",
        "Test_abnor = test['data'][test['label'] == 'Abnormal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((120000, 106), (73484, 106))"
            ]
          },
          "execution_count": 259,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Test_nor.shape , Test_abnor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train_abnor_4clss = preprocess_test(Train_4classes, False)\n",
        "\n",
        "Train_abnor_3clss = preprocess_test(Train_3classes, False)\n",
        "\n",
        "Train_abnor_2clss = preprocess_test(Train_2classes, False)\n",
        "\n",
        "Train_abnor_1clss = preprocess_test(Train_1class, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train_DoS = preprocess_test(Train_DoS, False)\n",
        "Train_BP = preprocess_test(Train_BP, False)\n",
        "Train_DoSGas = preprocess_test(Train_DoSGas, False)\n",
        "Train_FoT = preprocess_test(Train_FoT, False)\n",
        "Train_OaU = preprocess_test(Train_OaU, False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(213767, 106)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Train_abnor_4clss['data'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "Test_4class =  Test[Test['label'].isin(['DoS_Gas','FoT','BP','OaU','Normal'])]\n",
        "\n",
        "Test_3class =  Test[Test['label'].isin(['FoT','DoS','BP'])]\n",
        "\n",
        "Test_2class =  Test[Test['label'].isin(['DoS','BP','Normal'])]\n",
        "\n",
        "Test_1class =  Test[Test['label'].isin(['OaU', 'Normal'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Normal', 'FoT', 'BP', 'DoS_Gas', 'OaU'], dtype=object)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Test_4class['label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #Trường hợp 4 classes\n",
        "# test = preprocess_test(Test_4class, False)\n",
        "# Test_nor = test['data'][test['label'] == 'Normal']\n",
        "# Test_abnor = test['data'][test['label'] == 'Abnormal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #Trường hợp 3 classes\n",
        "# test = preprocess_test(Test_3class, False)\n",
        "# Test_nor = test['data'][test['label'] == 'Normal']\n",
        "# Test_abnor = test['data'][test['label'] == 'Abnormal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #Trường hợp 2 classes\n",
        "# test = preprocess_test(Test_2class, False)\n",
        "# Test_nor = test['data'][test['label'] == 'Normal']\n",
        "# Test_abnor = test['data'][test['label'] == 'Abnormal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #Trường hợp 1 class\n",
        "# test = preprocess_test(Test_1class, False)\n",
        "# Test_nor = test['data'][test['label'] == 'Normal']\n",
        "# Test_abnor = test['data'][test['label'] == 'Abnormal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train_labeled = np.concatenate((Train_nor_lab['data'],Train_abnor_lab['data']))\n",
        "Labeled = np.concatenate((Train_nor_lab['label'],Train_abnor_lab['label']))\n",
        "Labeled = np.where(Labeled == 'Normal', 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PhScwCsapMEI"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(keras.Model):\n",
        "  def __init__(self, input_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = keras.Sequential([\n",
        "      keras.layers.Dense(input_dim, activation='tanh'),\n",
        "      keras.layers.Dense(52, activation='tanh'),\n",
        "      keras.layers.Dense(26, activation='tanh'),\n",
        "      keras.layers.Dense(13, activation='tanh')\n",
        "    ], name='encoder')\n",
        "    self.decoder = keras.Sequential([\n",
        "      keras.layers.Dense(26, activation='tanh'),\n",
        "      keras.layers.Dense(52, activation='tanh'),\n",
        "      keras.layers.Dense(input_dim, activation='sigmoid'),\n",
        "    ], name='decoder')\n",
        "\n",
        "    self.classifier = keras.Sequential([\n",
        "      keras.layers.Dense(13, activation='relu'),\n",
        "      keras.layers.Dense(1, activation='sigmoid')\n",
        "    ],name='classifier')\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    code = self.encoder(x)\n",
        "    reconstruction = self.decoder(code)\n",
        "    classification = self.classifier(code)\n",
        "    return {'decoder_output': reconstruction, 'classifier_output': classification}\n",
        "\n",
        "  \n",
        "  def get_reconstruction_error(self, x, batch_size = 10000):\n",
        "    r = self.predict(x, batch_size)\n",
        "    return keras.metrics.mean_squared_error(x, r['decoder_output'])\n",
        "  \n",
        "  def get_classifier_prob(self, x, batch_size = 10000):\n",
        "    pr = self.predict(x, batch_size)\n",
        "    return pr['classifier_output'].reshape(-1)\n",
        "\n",
        "  def predict_class(self, x, threshold,w1,w2, batch_size = 10000):\n",
        "    reconstruction_error = self.get_reconstruction_error(x, batch_size)\n",
        "    prob = self.get_classifier_prob(x,batch_size)\n",
        "    anomaly_score = w1*reconstruction_error + w2*prob\n",
        "    return np.where(anomaly_score <= threshold, 'Normal', 'Abnormal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Autoencoder(Train_nor_unlab['data'].shape[1])\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss={'decoder_output': 'mse'},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1fee3298b10>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path = 'Model/AE_500.model'\n",
        "model.load_weights(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_25/kernel:0', 'dense_25/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_25/kernel:0', 'dense_25/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_25/kernel:0', 'dense_25/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_25/kernel:0', 'dense_25/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0492 - decoder_output_loss: 0.0492\n",
            "Epoch 2/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0197 - decoder_output_loss: 0.0197\n",
            "Epoch 3/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0106 - decoder_output_loss: 0.0106\n",
            "Epoch 4/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0041 - decoder_output_loss: 0.0041\n",
            "Epoch 5/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0021 - decoder_output_loss: 0.0021\n",
            "Epoch 6/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0013 - decoder_output_loss: 0.0013\n",
            "Epoch 7/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 8.7814e-04 - decoder_output_loss: 8.7814e-04\n",
            "Epoch 8/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 5.7582e-04 - decoder_output_loss: 5.7582e-04\n",
            "Epoch 9/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.9383e-04 - decoder_output_loss: 3.9383e-04\n",
            "Epoch 10/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.9257e-04 - decoder_output_loss: 2.9257e-04\n",
            "Epoch 11/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.3865e-04 - decoder_output_loss: 2.3865e-04\n",
            "Epoch 12/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0492e-04 - decoder_output_loss: 2.0492e-04\n",
            "Epoch 13/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7824e-04 - decoder_output_loss: 1.7824e-04\n",
            "Epoch 14/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.5956e-04 - decoder_output_loss: 1.5956e-04\n",
            "Epoch 15/500\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 1.4568e-04 - decoder_output_loss: 1.4568e-04\n",
            "Epoch 16/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.3113e-04 - decoder_output_loss: 1.3113e-04\n",
            "Epoch 17/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.1783e-04 - decoder_output_loss: 1.1783e-04\n",
            "Epoch 18/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.0755e-04 - decoder_output_loss: 1.0755e-04\n",
            "Epoch 19/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.0004e-04 - decoder_output_loss: 1.0004e-04\n",
            "Epoch 20/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 9.4494e-05 - decoder_output_loss: 9.4494e-05\n",
            "Epoch 21/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 9.0129e-05 - decoder_output_loss: 9.0129e-05\n",
            "Epoch 22/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 8.6511e-05 - decoder_output_loss: 8.6511e-05\n",
            "Epoch 23/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 8.3514e-05 - decoder_output_loss: 8.3514e-05\n",
            "Epoch 24/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 8.0749e-05 - decoder_output_loss: 8.0749e-05\n",
            "Epoch 25/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 7.8255e-05 - decoder_output_loss: 7.8255e-05\n",
            "Epoch 26/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 7.5914e-05 - decoder_output_loss: 7.5914e-05\n",
            "Epoch 27/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 7.3763e-05 - decoder_output_loss: 7.3763e-05\n",
            "Epoch 28/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 7.1724e-05 - decoder_output_loss: 7.1724e-05\n",
            "Epoch 29/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 6.9523e-05 - decoder_output_loss: 6.9523e-05\n",
            "Epoch 30/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 6.6439e-05 - decoder_output_loss: 6.6439e-05\n",
            "Epoch 31/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 6.3441e-05 - decoder_output_loss: 6.3441e-05\n",
            "Epoch 32/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 6.1026e-05 - decoder_output_loss: 6.1026e-05\n",
            "Epoch 33/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 5.9026e-05 - decoder_output_loss: 5.9026e-05\n",
            "Epoch 34/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 5.7245e-05 - decoder_output_loss: 5.7245e-05\n",
            "Epoch 35/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 5.5645e-05 - decoder_output_loss: 5.5645e-05\n",
            "Epoch 36/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 5.4330e-05 - decoder_output_loss: 5.4330e-05\n",
            "Epoch 37/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 5.3171e-05 - decoder_output_loss: 5.3171e-05\n",
            "Epoch 38/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 5.2131e-05 - decoder_output_loss: 5.2131e-05\n",
            "Epoch 39/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 5.1155e-05 - decoder_output_loss: 5.1155e-05\n",
            "Epoch 40/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 5.0335e-05 - decoder_output_loss: 5.0335e-05\n",
            "Epoch 41/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.9525e-05 - decoder_output_loss: 4.9525e-05\n",
            "Epoch 42/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.8750e-05 - decoder_output_loss: 4.8750e-05\n",
            "Epoch 43/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.8022e-05 - decoder_output_loss: 4.8022e-05\n",
            "Epoch 44/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.7317e-05 - decoder_output_loss: 4.7317e-05\n",
            "Epoch 45/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.6683e-05 - decoder_output_loss: 4.6683e-05\n",
            "Epoch 46/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.6032e-05 - decoder_output_loss: 4.6032e-05\n",
            "Epoch 47/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.5458e-05 - decoder_output_loss: 4.5458e-05\n",
            "Epoch 48/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.4881e-05 - decoder_output_loss: 4.4881e-05\n",
            "Epoch 49/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.4402e-05 - decoder_output_loss: 4.4402e-05\n",
            "Epoch 50/500\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 4.3887e-05 - decoder_output_loss: 4.3887e-05\n",
            "Epoch 51/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.3386e-05 - decoder_output_loss: 4.3386e-05\n",
            "Epoch 52/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.2920e-05 - decoder_output_loss: 4.2920e-05\n",
            "Epoch 53/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.2486e-05 - decoder_output_loss: 4.2486e-05\n",
            "Epoch 54/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.2098e-05 - decoder_output_loss: 4.2098e-05\n",
            "Epoch 55/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.1679e-05 - decoder_output_loss: 4.1679e-05\n",
            "Epoch 56/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.1315e-05 - decoder_output_loss: 4.1315e-05\n",
            "Epoch 57/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.0874e-05 - decoder_output_loss: 4.0874e-05\n",
            "Epoch 58/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 4.0210e-05 - decoder_output_loss: 4.0210e-05\n",
            "Epoch 59/500\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 3.9473e-05 - decoder_output_loss: 3.9473e-05\n",
            "Epoch 60/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.8955e-05 - decoder_output_loss: 3.8955e-05\n",
            "Epoch 61/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.8543e-05 - decoder_output_loss: 3.8543e-05\n",
            "Epoch 62/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.8141e-05 - decoder_output_loss: 3.8141e-05\n",
            "Epoch 63/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.7765e-05 - decoder_output_loss: 3.7765e-05\n",
            "Epoch 64/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.7396e-05 - decoder_output_loss: 3.7396e-05\n",
            "Epoch 65/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.7033e-05 - decoder_output_loss: 3.7033e-05\n",
            "Epoch 66/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.6700e-05 - decoder_output_loss: 3.6700e-05\n",
            "Epoch 67/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.6376e-05 - decoder_output_loss: 3.6376e-05\n",
            "Epoch 68/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.6020e-05 - decoder_output_loss: 3.6020e-05\n",
            "Epoch 69/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.5766e-05 - decoder_output_loss: 3.5766e-05\n",
            "Epoch 70/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.5404e-05 - decoder_output_loss: 3.5404e-05\n",
            "Epoch 71/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.4809e-05 - decoder_output_loss: 3.4809e-05\n",
            "Epoch 72/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.4258e-05 - decoder_output_loss: 3.4258e-05\n",
            "Epoch 73/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.3849e-05 - decoder_output_loss: 3.3849e-05\n",
            "Epoch 74/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.3494e-05 - decoder_output_loss: 3.3494e-05\n",
            "Epoch 75/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.3142e-05 - decoder_output_loss: 3.3142e-05\n",
            "Epoch 76/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.2842e-05 - decoder_output_loss: 3.2842e-05\n",
            "Epoch 77/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.2502e-05 - decoder_output_loss: 3.2502e-05\n",
            "Epoch 78/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.2261e-05 - decoder_output_loss: 3.2261e-05\n",
            "Epoch 79/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.1982e-05 - decoder_output_loss: 3.1982e-05\n",
            "Epoch 80/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.1705e-05 - decoder_output_loss: 3.1705e-05\n",
            "Epoch 81/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.1463e-05 - decoder_output_loss: 3.1463e-05\n",
            "Epoch 82/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.1201e-05 - decoder_output_loss: 3.1201e-05\n",
            "Epoch 83/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.0853e-05 - decoder_output_loss: 3.0853e-05\n",
            "Epoch 84/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.0469e-05 - decoder_output_loss: 3.0469e-05\n",
            "Epoch 85/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 3.0124e-05 - decoder_output_loss: 3.0124e-05\n",
            "Epoch 86/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.9862e-05 - decoder_output_loss: 2.9862e-05\n",
            "Epoch 87/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.9581e-05 - decoder_output_loss: 2.9581e-05\n",
            "Epoch 88/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.9363e-05 - decoder_output_loss: 2.9363e-05\n",
            "Epoch 89/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.9130e-05 - decoder_output_loss: 2.9130e-05\n",
            "Epoch 90/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.8960e-05 - decoder_output_loss: 2.8960e-05\n",
            "Epoch 91/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.8776e-05 - decoder_output_loss: 2.8776e-05\n",
            "Epoch 92/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.8575e-05 - decoder_output_loss: 2.8575e-05\n",
            "Epoch 93/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.8422e-05 - decoder_output_loss: 2.8422e-05\n",
            "Epoch 94/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.8250e-05 - decoder_output_loss: 2.8250e-05\n",
            "Epoch 95/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.8075e-05 - decoder_output_loss: 2.8075e-05\n",
            "Epoch 96/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.7952e-05 - decoder_output_loss: 2.7952e-05\n",
            "Epoch 97/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.7772e-05 - decoder_output_loss: 2.7772e-05\n",
            "Epoch 98/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.7656e-05 - decoder_output_loss: 2.7656e-05\n",
            "Epoch 99/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.7515e-05 - decoder_output_loss: 2.7515e-05\n",
            "Epoch 100/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.7372e-05 - decoder_output_loss: 2.7372e-05\n",
            "Epoch 101/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.7267e-05 - decoder_output_loss: 2.7267e-05\n",
            "Epoch 102/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.7124e-05 - decoder_output_loss: 2.7124e-05\n",
            "Epoch 103/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.7017e-05 - decoder_output_loss: 2.7017e-05\n",
            "Epoch 104/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.6908e-05 - decoder_output_loss: 2.6908e-05\n",
            "Epoch 105/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.6765e-05 - decoder_output_loss: 2.6765e-05\n",
            "Epoch 106/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.6646e-05 - decoder_output_loss: 2.6646e-05\n",
            "Epoch 107/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.6505e-05 - decoder_output_loss: 2.6505e-05\n",
            "Epoch 108/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.6353e-05 - decoder_output_loss: 2.6353e-05\n",
            "Epoch 109/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.6201e-05 - decoder_output_loss: 2.6201e-05\n",
            "Epoch 110/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.6083e-05 - decoder_output_loss: 2.6083e-05\n",
            "Epoch 111/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.5963e-05 - decoder_output_loss: 2.5963e-05\n",
            "Epoch 112/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.5875e-05 - decoder_output_loss: 2.5875e-05\n",
            "Epoch 113/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.5741e-05 - decoder_output_loss: 2.5741e-05\n",
            "Epoch 114/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.5617e-05 - decoder_output_loss: 2.5617e-05\n",
            "Epoch 115/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.5523e-05 - decoder_output_loss: 2.5523e-05\n",
            "Epoch 116/500\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 2.5417e-05 - decoder_output_loss: 2.5417e-05\n",
            "Epoch 117/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.5319e-05 - decoder_output_loss: 2.5319e-05\n",
            "Epoch 118/500\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 2.5250e-05 - decoder_output_loss: 2.5250e-05\n",
            "Epoch 119/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.5118e-05 - decoder_output_loss: 2.5118e-05\n",
            "Epoch 120/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.5032e-05 - decoder_output_loss: 2.5032e-05\n",
            "Epoch 121/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.4927e-05 - decoder_output_loss: 2.4927e-05\n",
            "Epoch 122/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.4842e-05 - decoder_output_loss: 2.4842e-05\n",
            "Epoch 123/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.4746e-05 - decoder_output_loss: 2.4746e-05\n",
            "Epoch 124/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.4662e-05 - decoder_output_loss: 2.4662e-05\n",
            "Epoch 125/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.4558e-05 - decoder_output_loss: 2.4558e-05\n",
            "Epoch 126/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.4461e-05 - decoder_output_loss: 2.4461e-05\n",
            "Epoch 127/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.4336e-05 - decoder_output_loss: 2.4336e-05\n",
            "Epoch 128/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.4254e-05 - decoder_output_loss: 2.4254e-05\n",
            "Epoch 129/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.4119e-05 - decoder_output_loss: 2.4119e-05\n",
            "Epoch 130/500\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 2.4055e-05 - decoder_output_loss: 2.4055e-05\n",
            "Epoch 131/500\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 2.3969e-05 - decoder_output_loss: 2.3969e-05\n",
            "Epoch 132/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.3862e-05 - decoder_output_loss: 2.3862e-05\n",
            "Epoch 133/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.3793e-05 - decoder_output_loss: 2.3793e-05\n",
            "Epoch 134/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.3737e-05 - decoder_output_loss: 2.3737e-05\n",
            "Epoch 135/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.3636e-05 - decoder_output_loss: 2.3636e-05\n",
            "Epoch 136/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.3598e-05 - decoder_output_loss: 2.3598e-05\n",
            "Epoch 137/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.3520e-05 - decoder_output_loss: 2.3520e-05\n",
            "Epoch 138/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.3456e-05 - decoder_output_loss: 2.3456e-05\n",
            "Epoch 139/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.3370e-05 - decoder_output_loss: 2.3370e-05\n",
            "Epoch 140/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.3114e-05 - decoder_output_loss: 2.3114e-05\n",
            "Epoch 141/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2946e-05 - decoder_output_loss: 2.2946e-05\n",
            "Epoch 142/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2832e-05 - decoder_output_loss: 2.2832e-05\n",
            "Epoch 143/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2745e-05 - decoder_output_loss: 2.2745e-05\n",
            "Epoch 144/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2669e-05 - decoder_output_loss: 2.2669e-05\n",
            "Epoch 145/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2587e-05 - decoder_output_loss: 2.2587e-05\n",
            "Epoch 146/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2503e-05 - decoder_output_loss: 2.2503e-05\n",
            "Epoch 147/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2458e-05 - decoder_output_loss: 2.2458e-05\n",
            "Epoch 148/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2400e-05 - decoder_output_loss: 2.2400e-05\n",
            "Epoch 149/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2328e-05 - decoder_output_loss: 2.2328e-05\n",
            "Epoch 150/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2262e-05 - decoder_output_loss: 2.2262e-05\n",
            "Epoch 151/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2219e-05 - decoder_output_loss: 2.2219e-05\n",
            "Epoch 152/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2158e-05 - decoder_output_loss: 2.2158e-05\n",
            "Epoch 153/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2120e-05 - decoder_output_loss: 2.2120e-05\n",
            "Epoch 154/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2054e-05 - decoder_output_loss: 2.2054e-05\n",
            "Epoch 155/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.2020e-05 - decoder_output_loss: 2.2020e-05\n",
            "Epoch 156/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1955e-05 - decoder_output_loss: 2.1955e-05\n",
            "Epoch 157/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1931e-05 - decoder_output_loss: 2.1931e-05\n",
            "Epoch 158/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1861e-05 - decoder_output_loss: 2.1861e-05\n",
            "Epoch 159/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1817e-05 - decoder_output_loss: 2.1817e-05\n",
            "Epoch 160/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1761e-05 - decoder_output_loss: 2.1761e-05\n",
            "Epoch 161/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1725e-05 - decoder_output_loss: 2.1725e-05\n",
            "Epoch 162/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1681e-05 - decoder_output_loss: 2.1681e-05\n",
            "Epoch 163/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1634e-05 - decoder_output_loss: 2.1634e-05\n",
            "Epoch 164/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1583e-05 - decoder_output_loss: 2.1583e-05\n",
            "Epoch 165/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1540e-05 - decoder_output_loss: 2.1540e-05\n",
            "Epoch 166/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1484e-05 - decoder_output_loss: 2.1484e-05\n",
            "Epoch 167/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1431e-05 - decoder_output_loss: 2.1431e-05\n",
            "Epoch 168/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1368e-05 - decoder_output_loss: 2.1368e-05\n",
            "Epoch 169/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1289e-05 - decoder_output_loss: 2.1289e-05\n",
            "Epoch 170/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1213e-05 - decoder_output_loss: 2.1213e-05\n",
            "Epoch 171/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1133e-05 - decoder_output_loss: 2.1133e-05\n",
            "Epoch 172/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1063e-05 - decoder_output_loss: 2.1063e-05\n",
            "Epoch 173/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.1005e-05 - decoder_output_loss: 2.1005e-05\n",
            "Epoch 174/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0969e-05 - decoder_output_loss: 2.0969e-05\n",
            "Epoch 175/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0919e-05 - decoder_output_loss: 2.0919e-05\n",
            "Epoch 176/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0851e-05 - decoder_output_loss: 2.0851e-05\n",
            "Epoch 177/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0815e-05 - decoder_output_loss: 2.0815e-05\n",
            "Epoch 178/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0774e-05 - decoder_output_loss: 2.0774e-05\n",
            "Epoch 179/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0737e-05 - decoder_output_loss: 2.0737e-05\n",
            "Epoch 180/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0663e-05 - decoder_output_loss: 2.0663e-05\n",
            "Epoch 181/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0639e-05 - decoder_output_loss: 2.0639e-05\n",
            "Epoch 182/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0586e-05 - decoder_output_loss: 2.0586e-05\n",
            "Epoch 183/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0548e-05 - decoder_output_loss: 2.0548e-05\n",
            "Epoch 184/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0510e-05 - decoder_output_loss: 2.0510e-05\n",
            "Epoch 185/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0478e-05 - decoder_output_loss: 2.0478e-05\n",
            "Epoch 186/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0452e-05 - decoder_output_loss: 2.0452e-05\n",
            "Epoch 187/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0394e-05 - decoder_output_loss: 2.0394e-05\n",
            "Epoch 188/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0373e-05 - decoder_output_loss: 2.0373e-05\n",
            "Epoch 189/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0326e-05 - decoder_output_loss: 2.0326e-05\n",
            "Epoch 190/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0293e-05 - decoder_output_loss: 2.0293e-05\n",
            "Epoch 191/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0246e-05 - decoder_output_loss: 2.0246e-05\n",
            "Epoch 192/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0228e-05 - decoder_output_loss: 2.0228e-05\n",
            "Epoch 193/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0172e-05 - decoder_output_loss: 2.0172e-05\n",
            "Epoch 194/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0169e-05 - decoder_output_loss: 2.0169e-05\n",
            "Epoch 195/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0100e-05 - decoder_output_loss: 2.0100e-05\n",
            "Epoch 196/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0085e-05 - decoder_output_loss: 2.0085e-05\n",
            "Epoch 197/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0061e-05 - decoder_output_loss: 2.0061e-05\n",
            "Epoch 198/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 2.0015e-05 - decoder_output_loss: 2.0015e-05\n",
            "Epoch 199/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9966e-05 - decoder_output_loss: 1.9966e-05\n",
            "Epoch 200/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9951e-05 - decoder_output_loss: 1.9951e-05\n",
            "Epoch 201/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9920e-05 - decoder_output_loss: 1.9920e-05\n",
            "Epoch 202/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9893e-05 - decoder_output_loss: 1.9893e-05\n",
            "Epoch 203/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9852e-05 - decoder_output_loss: 1.9852e-05\n",
            "Epoch 204/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9834e-05 - decoder_output_loss: 1.9834e-05\n",
            "Epoch 205/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9814e-05 - decoder_output_loss: 1.9814e-05\n",
            "Epoch 206/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9759e-05 - decoder_output_loss: 1.9759e-05\n",
            "Epoch 207/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9756e-05 - decoder_output_loss: 1.9756e-05\n",
            "Epoch 208/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9702e-05 - decoder_output_loss: 1.9702e-05\n",
            "Epoch 209/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9686e-05 - decoder_output_loss: 1.9686e-05\n",
            "Epoch 210/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9647e-05 - decoder_output_loss: 1.9647e-05\n",
            "Epoch 211/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9636e-05 - decoder_output_loss: 1.9636e-05\n",
            "Epoch 212/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9580e-05 - decoder_output_loss: 1.9580e-05\n",
            "Epoch 213/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9558e-05 - decoder_output_loss: 1.9558e-05\n",
            "Epoch 214/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9527e-05 - decoder_output_loss: 1.9527e-05\n",
            "Epoch 215/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9508e-05 - decoder_output_loss: 1.9508e-05\n",
            "Epoch 216/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9502e-05 - decoder_output_loss: 1.9502e-05\n",
            "Epoch 217/500\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 1.9471e-05 - decoder_output_loss: 1.9471e-05\n",
            "Epoch 218/500\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 1.9427e-05 - decoder_output_loss: 1.9427e-05\n",
            "Epoch 219/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9409e-05 - decoder_output_loss: 1.9409e-05\n",
            "Epoch 220/500\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 1.9400e-05 - decoder_output_loss: 1.9400e-05\n",
            "Epoch 221/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9358e-05 - decoder_output_loss: 1.9358e-05\n",
            "Epoch 222/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9330e-05 - decoder_output_loss: 1.9330e-05\n",
            "Epoch 223/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9303e-05 - decoder_output_loss: 1.9303e-05\n",
            "Epoch 224/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9282e-05 - decoder_output_loss: 1.9282e-05\n",
            "Epoch 225/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9255e-05 - decoder_output_loss: 1.9255e-05\n",
            "Epoch 226/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9213e-05 - decoder_output_loss: 1.9213e-05\n",
            "Epoch 227/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9211e-05 - decoder_output_loss: 1.9211e-05\n",
            "Epoch 228/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9181e-05 - decoder_output_loss: 1.9181e-05\n",
            "Epoch 229/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9154e-05 - decoder_output_loss: 1.9154e-05\n",
            "Epoch 230/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9146e-05 - decoder_output_loss: 1.9146e-05\n",
            "Epoch 231/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9111e-05 - decoder_output_loss: 1.9111e-05\n",
            "Epoch 232/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9084e-05 - decoder_output_loss: 1.9084e-05\n",
            "Epoch 233/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9058e-05 - decoder_output_loss: 1.9058e-05\n",
            "Epoch 234/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9061e-05 - decoder_output_loss: 1.9061e-05\n",
            "Epoch 235/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.9033e-05 - decoder_output_loss: 1.9033e-05\n",
            "Epoch 236/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8982e-05 - decoder_output_loss: 1.8982e-05\n",
            "Epoch 237/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8976e-05 - decoder_output_loss: 1.8976e-05\n",
            "Epoch 238/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8956e-05 - decoder_output_loss: 1.8956e-05\n",
            "Epoch 239/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8923e-05 - decoder_output_loss: 1.8923e-05\n",
            "Epoch 240/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8916e-05 - decoder_output_loss: 1.8916e-05\n",
            "Epoch 241/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8913e-05 - decoder_output_loss: 1.8913e-05\n",
            "Epoch 242/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8870e-05 - decoder_output_loss: 1.8870e-05\n",
            "Epoch 243/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8845e-05 - decoder_output_loss: 1.8845e-05\n",
            "Epoch 244/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8834e-05 - decoder_output_loss: 1.8834e-05\n",
            "Epoch 245/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8799e-05 - decoder_output_loss: 1.8799e-05\n",
            "Epoch 246/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8808e-05 - decoder_output_loss: 1.8808e-05\n",
            "Epoch 247/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8765e-05 - decoder_output_loss: 1.8765e-05\n",
            "Epoch 248/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8740e-05 - decoder_output_loss: 1.8740e-05\n",
            "Epoch 249/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8730e-05 - decoder_output_loss: 1.8730e-05\n",
            "Epoch 250/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8711e-05 - decoder_output_loss: 1.8711e-05\n",
            "Epoch 251/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8689e-05 - decoder_output_loss: 1.8689e-05\n",
            "Epoch 252/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8664e-05 - decoder_output_loss: 1.8664e-05\n",
            "Epoch 253/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8642e-05 - decoder_output_loss: 1.8642e-05\n",
            "Epoch 254/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8637e-05 - decoder_output_loss: 1.8637e-05\n",
            "Epoch 255/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8628e-05 - decoder_output_loss: 1.8628e-05\n",
            "Epoch 256/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8582e-05 - decoder_output_loss: 1.8582e-05\n",
            "Epoch 257/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8568e-05 - decoder_output_loss: 1.8568e-05\n",
            "Epoch 258/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8561e-05 - decoder_output_loss: 1.8561e-05\n",
            "Epoch 259/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8544e-05 - decoder_output_loss: 1.8544e-05\n",
            "Epoch 260/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8517e-05 - decoder_output_loss: 1.8517e-05\n",
            "Epoch 261/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8481e-05 - decoder_output_loss: 1.8481e-05\n",
            "Epoch 262/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8486e-05 - decoder_output_loss: 1.8486e-05\n",
            "Epoch 263/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8460e-05 - decoder_output_loss: 1.8460e-05\n",
            "Epoch 264/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8451e-05 - decoder_output_loss: 1.8451e-05\n",
            "Epoch 265/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8417e-05 - decoder_output_loss: 1.8417e-05\n",
            "Epoch 266/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8424e-05 - decoder_output_loss: 1.8424e-05\n",
            "Epoch 267/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8406e-05 - decoder_output_loss: 1.8406e-05\n",
            "Epoch 268/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8370e-05 - decoder_output_loss: 1.8370e-05\n",
            "Epoch 269/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8349e-05 - decoder_output_loss: 1.8349e-05\n",
            "Epoch 270/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8351e-05 - decoder_output_loss: 1.8351e-05\n",
            "Epoch 271/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8324e-05 - decoder_output_loss: 1.8324e-05\n",
            "Epoch 272/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8310e-05 - decoder_output_loss: 1.8310e-05\n",
            "Epoch 273/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8279e-05 - decoder_output_loss: 1.8279e-05\n",
            "Epoch 274/500\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 1.8283e-05 - decoder_output_loss: 1.8283e-05\n",
            "Epoch 275/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8264e-05 - decoder_output_loss: 1.8264e-05\n",
            "Epoch 276/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8231e-05 - decoder_output_loss: 1.8231e-05\n",
            "Epoch 277/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8227e-05 - decoder_output_loss: 1.8227e-05\n",
            "Epoch 278/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8205e-05 - decoder_output_loss: 1.8205e-05\n",
            "Epoch 279/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8200e-05 - decoder_output_loss: 1.8200e-05\n",
            "Epoch 280/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8169e-05 - decoder_output_loss: 1.8169e-05\n",
            "Epoch 281/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8161e-05 - decoder_output_loss: 1.8161e-05\n",
            "Epoch 282/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8167e-05 - decoder_output_loss: 1.8167e-05\n",
            "Epoch 283/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8125e-05 - decoder_output_loss: 1.8125e-05\n",
            "Epoch 284/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8099e-05 - decoder_output_loss: 1.8099e-05\n",
            "Epoch 285/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8113e-05 - decoder_output_loss: 1.8113e-05\n",
            "Epoch 286/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8091e-05 - decoder_output_loss: 1.8091e-05\n",
            "Epoch 287/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8061e-05 - decoder_output_loss: 1.8061e-05\n",
            "Epoch 288/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8043e-05 - decoder_output_loss: 1.8043e-05\n",
            "Epoch 289/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8036e-05 - decoder_output_loss: 1.8036e-05\n",
            "Epoch 290/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8039e-05 - decoder_output_loss: 1.8039e-05\n",
            "Epoch 291/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.8018e-05 - decoder_output_loss: 1.8018e-05\n",
            "Epoch 292/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7984e-05 - decoder_output_loss: 1.7984e-05\n",
            "Epoch 293/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7977e-05 - decoder_output_loss: 1.7977e-05\n",
            "Epoch 294/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7959e-05 - decoder_output_loss: 1.7959e-05\n",
            "Epoch 295/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7956e-05 - decoder_output_loss: 1.7956e-05\n",
            "Epoch 296/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7954e-05 - decoder_output_loss: 1.7954e-05\n",
            "Epoch 297/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7914e-05 - decoder_output_loss: 1.7914e-05\n",
            "Epoch 298/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7902e-05 - decoder_output_loss: 1.7902e-05\n",
            "Epoch 299/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7879e-05 - decoder_output_loss: 1.7879e-05\n",
            "Epoch 300/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7882e-05 - decoder_output_loss: 1.7882e-05\n",
            "Epoch 301/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7865e-05 - decoder_output_loss: 1.7865e-05\n",
            "Epoch 302/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7848e-05 - decoder_output_loss: 1.7848e-05\n",
            "Epoch 303/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7837e-05 - decoder_output_loss: 1.7837e-05\n",
            "Epoch 304/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7830e-05 - decoder_output_loss: 1.7830e-05\n",
            "Epoch 305/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7798e-05 - decoder_output_loss: 1.7798e-05\n",
            "Epoch 306/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7792e-05 - decoder_output_loss: 1.7792e-05\n",
            "Epoch 307/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7786e-05 - decoder_output_loss: 1.7786e-05\n",
            "Epoch 308/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7761e-05 - decoder_output_loss: 1.7761e-05\n",
            "Epoch 309/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7745e-05 - decoder_output_loss: 1.7745e-05\n",
            "Epoch 310/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7748e-05 - decoder_output_loss: 1.7748e-05\n",
            "Epoch 311/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7733e-05 - decoder_output_loss: 1.7733e-05\n",
            "Epoch 312/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7710e-05 - decoder_output_loss: 1.7710e-05\n",
            "Epoch 313/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7704e-05 - decoder_output_loss: 1.7704e-05\n",
            "Epoch 314/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7689e-05 - decoder_output_loss: 1.7689e-05\n",
            "Epoch 315/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7686e-05 - decoder_output_loss: 1.7686e-05\n",
            "Epoch 316/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7664e-05 - decoder_output_loss: 1.7664e-05\n",
            "Epoch 317/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7662e-05 - decoder_output_loss: 1.7662e-05\n",
            "Epoch 318/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7643e-05 - decoder_output_loss: 1.7643e-05\n",
            "Epoch 319/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7622e-05 - decoder_output_loss: 1.7622e-05\n",
            "Epoch 320/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7616e-05 - decoder_output_loss: 1.7616e-05\n",
            "Epoch 321/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7599e-05 - decoder_output_loss: 1.7599e-05\n",
            "Epoch 322/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7591e-05 - decoder_output_loss: 1.7591e-05\n",
            "Epoch 323/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7576e-05 - decoder_output_loss: 1.7576e-05\n",
            "Epoch 324/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7577e-05 - decoder_output_loss: 1.7577e-05\n",
            "Epoch 325/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7545e-05 - decoder_output_loss: 1.7545e-05\n",
            "Epoch 326/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7548e-05 - decoder_output_loss: 1.7548e-05\n",
            "Epoch 327/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7533e-05 - decoder_output_loss: 1.7533e-05\n",
            "Epoch 328/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7532e-05 - decoder_output_loss: 1.7532e-05\n",
            "Epoch 329/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7516e-05 - decoder_output_loss: 1.7516e-05\n",
            "Epoch 330/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7500e-05 - decoder_output_loss: 1.7500e-05\n",
            "Epoch 331/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7483e-05 - decoder_output_loss: 1.7483e-05\n",
            "Epoch 332/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7488e-05 - decoder_output_loss: 1.7488e-05\n",
            "Epoch 333/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7453e-05 - decoder_output_loss: 1.7453e-05\n",
            "Epoch 334/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7450e-05 - decoder_output_loss: 1.7450e-05\n",
            "Epoch 335/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7438e-05 - decoder_output_loss: 1.7438e-05\n",
            "Epoch 336/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7441e-05 - decoder_output_loss: 1.7441e-05\n",
            "Epoch 337/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7421e-05 - decoder_output_loss: 1.7421e-05\n",
            "Epoch 338/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7403e-05 - decoder_output_loss: 1.7403e-05\n",
            "Epoch 339/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7394e-05 - decoder_output_loss: 1.7394e-05\n",
            "Epoch 340/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7400e-05 - decoder_output_loss: 1.7400e-05\n",
            "Epoch 341/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7376e-05 - decoder_output_loss: 1.7376e-05\n",
            "Epoch 342/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7361e-05 - decoder_output_loss: 1.7361e-05\n",
            "Epoch 343/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7348e-05 - decoder_output_loss: 1.7348e-05\n",
            "Epoch 344/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7336e-05 - decoder_output_loss: 1.7336e-05\n",
            "Epoch 345/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7351e-05 - decoder_output_loss: 1.7351e-05\n",
            "Epoch 346/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7315e-05 - decoder_output_loss: 1.7315e-05\n",
            "Epoch 347/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7299e-05 - decoder_output_loss: 1.7299e-05\n",
            "Epoch 348/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7302e-05 - decoder_output_loss: 1.7302e-05\n",
            "Epoch 349/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7286e-05 - decoder_output_loss: 1.7286e-05\n",
            "Epoch 350/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7260e-05 - decoder_output_loss: 1.7260e-05\n",
            "Epoch 351/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7283e-05 - decoder_output_loss: 1.7283e-05\n",
            "Epoch 352/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7254e-05 - decoder_output_loss: 1.7254e-05\n",
            "Epoch 353/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7246e-05 - decoder_output_loss: 1.7246e-05\n",
            "Epoch 354/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7223e-05 - decoder_output_loss: 1.7223e-05\n",
            "Epoch 355/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7223e-05 - decoder_output_loss: 1.7223e-05\n",
            "Epoch 356/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7231e-05 - decoder_output_loss: 1.7231e-05\n",
            "Epoch 357/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7186e-05 - decoder_output_loss: 1.7186e-05\n",
            "Epoch 358/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7194e-05 - decoder_output_loss: 1.7194e-05\n",
            "Epoch 359/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7176e-05 - decoder_output_loss: 1.7176e-05\n",
            "Epoch 360/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7171e-05 - decoder_output_loss: 1.7171e-05\n",
            "Epoch 361/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7153e-05 - decoder_output_loss: 1.7153e-05\n",
            "Epoch 362/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7160e-05 - decoder_output_loss: 1.7160e-05\n",
            "Epoch 363/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7135e-05 - decoder_output_loss: 1.7135e-05\n",
            "Epoch 364/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7137e-05 - decoder_output_loss: 1.7137e-05\n",
            "Epoch 365/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7102e-05 - decoder_output_loss: 1.7102e-05\n",
            "Epoch 366/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7109e-05 - decoder_output_loss: 1.7109e-05\n",
            "Epoch 367/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7105e-05 - decoder_output_loss: 1.7105e-05\n",
            "Epoch 368/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7074e-05 - decoder_output_loss: 1.7074e-05\n",
            "Epoch 369/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7079e-05 - decoder_output_loss: 1.7079e-05\n",
            "Epoch 370/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7060e-05 - decoder_output_loss: 1.7060e-05\n",
            "Epoch 371/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7048e-05 - decoder_output_loss: 1.7048e-05\n",
            "Epoch 372/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7062e-05 - decoder_output_loss: 1.7062e-05\n",
            "Epoch 373/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7052e-05 - decoder_output_loss: 1.7052e-05\n",
            "Epoch 374/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7040e-05 - decoder_output_loss: 1.7040e-05\n",
            "Epoch 375/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7019e-05 - decoder_output_loss: 1.7019e-05\n",
            "Epoch 376/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7007e-05 - decoder_output_loss: 1.7007e-05\n",
            "Epoch 377/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.7001e-05 - decoder_output_loss: 1.7001e-05\n",
            "Epoch 378/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6991e-05 - decoder_output_loss: 1.6991e-05\n",
            "Epoch 379/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6985e-05 - decoder_output_loss: 1.6985e-05\n",
            "Epoch 380/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6976e-05 - decoder_output_loss: 1.6976e-05\n",
            "Epoch 381/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6983e-05 - decoder_output_loss: 1.6983e-05\n",
            "Epoch 382/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6947e-05 - decoder_output_loss: 1.6947e-05\n",
            "Epoch 383/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6967e-05 - decoder_output_loss: 1.6967e-05\n",
            "Epoch 384/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6951e-05 - decoder_output_loss: 1.6951e-05\n",
            "Epoch 385/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6926e-05 - decoder_output_loss: 1.6926e-05\n",
            "Epoch 386/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6922e-05 - decoder_output_loss: 1.6922e-05\n",
            "Epoch 387/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6907e-05 - decoder_output_loss: 1.6907e-05\n",
            "Epoch 388/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6912e-05 - decoder_output_loss: 1.6912e-05\n",
            "Epoch 389/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6897e-05 - decoder_output_loss: 1.6897e-05\n",
            "Epoch 390/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6891e-05 - decoder_output_loss: 1.6891e-05\n",
            "Epoch 391/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6882e-05 - decoder_output_loss: 1.6882e-05\n",
            "Epoch 392/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6873e-05 - decoder_output_loss: 1.6873e-05\n",
            "Epoch 393/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6859e-05 - decoder_output_loss: 1.6859e-05\n",
            "Epoch 394/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6861e-05 - decoder_output_loss: 1.6861e-05\n",
            "Epoch 395/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6839e-05 - decoder_output_loss: 1.6839e-05\n",
            "Epoch 396/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6849e-05 - decoder_output_loss: 1.6849e-05\n",
            "Epoch 397/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6823e-05 - decoder_output_loss: 1.6823e-05\n",
            "Epoch 398/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6832e-05 - decoder_output_loss: 1.6832e-05\n",
            "Epoch 399/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6840e-05 - decoder_output_loss: 1.6840e-05\n",
            "Epoch 400/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6807e-05 - decoder_output_loss: 1.6807e-05\n",
            "Epoch 401/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6812e-05 - decoder_output_loss: 1.6812e-05\n",
            "Epoch 402/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6785e-05 - decoder_output_loss: 1.6785e-05\n",
            "Epoch 403/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6785e-05 - decoder_output_loss: 1.6785e-05\n",
            "Epoch 404/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6762e-05 - decoder_output_loss: 1.6762e-05\n",
            "Epoch 405/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6769e-05 - decoder_output_loss: 1.6769e-05\n",
            "Epoch 406/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6761e-05 - decoder_output_loss: 1.6761e-05\n",
            "Epoch 407/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6751e-05 - decoder_output_loss: 1.6751e-05\n",
            "Epoch 408/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6735e-05 - decoder_output_loss: 1.6735e-05\n",
            "Epoch 409/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6745e-05 - decoder_output_loss: 1.6745e-05\n",
            "Epoch 410/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6718e-05 - decoder_output_loss: 1.6718e-05\n",
            "Epoch 411/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6705e-05 - decoder_output_loss: 1.6705e-05\n",
            "Epoch 412/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6726e-05 - decoder_output_loss: 1.6726e-05\n",
            "Epoch 413/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6703e-05 - decoder_output_loss: 1.6703e-05\n",
            "Epoch 414/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6706e-05 - decoder_output_loss: 1.6706e-05\n",
            "Epoch 415/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6689e-05 - decoder_output_loss: 1.6689e-05\n",
            "Epoch 416/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6668e-05 - decoder_output_loss: 1.6668e-05\n",
            "Epoch 417/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6685e-05 - decoder_output_loss: 1.6685e-05\n",
            "Epoch 418/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6672e-05 - decoder_output_loss: 1.6672e-05\n",
            "Epoch 419/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6667e-05 - decoder_output_loss: 1.6667e-05\n",
            "Epoch 420/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6650e-05 - decoder_output_loss: 1.6650e-05\n",
            "Epoch 421/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6639e-05 - decoder_output_loss: 1.6639e-05\n",
            "Epoch 422/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6643e-05 - decoder_output_loss: 1.6643e-05\n",
            "Epoch 423/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6634e-05 - decoder_output_loss: 1.6634e-05\n",
            "Epoch 424/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6613e-05 - decoder_output_loss: 1.6613e-05\n",
            "Epoch 425/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6612e-05 - decoder_output_loss: 1.6612e-05\n",
            "Epoch 426/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6621e-05 - decoder_output_loss: 1.6621e-05\n",
            "Epoch 427/500\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 1.6601e-05 - decoder_output_loss: 1.6601e-05\n",
            "Epoch 428/500\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 1.6587e-05 - decoder_output_loss: 1.6587e-05\n",
            "Epoch 429/500\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 1.6586e-05 - decoder_output_loss: 1.6586e-05\n",
            "Epoch 430/500\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 1.6587e-05 - decoder_output_loss: 1.6587e-05\n",
            "Epoch 431/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6570e-05 - decoder_output_loss: 1.6570e-05\n",
            "Epoch 432/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6568e-05 - decoder_output_loss: 1.6568e-05\n",
            "Epoch 433/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6550e-05 - decoder_output_loss: 1.6550e-05\n",
            "Epoch 434/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6554e-05 - decoder_output_loss: 1.6554e-05\n",
            "Epoch 435/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6534e-05 - decoder_output_loss: 1.6534e-05\n",
            "Epoch 436/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6543e-05 - decoder_output_loss: 1.6543e-05\n",
            "Epoch 437/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6527e-05 - decoder_output_loss: 1.6527e-05\n",
            "Epoch 438/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6522e-05 - decoder_output_loss: 1.6522e-05\n",
            "Epoch 439/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6520e-05 - decoder_output_loss: 1.6520e-05\n",
            "Epoch 440/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6504e-05 - decoder_output_loss: 1.6504e-05\n",
            "Epoch 441/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6500e-05 - decoder_output_loss: 1.6500e-05\n",
            "Epoch 442/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6509e-05 - decoder_output_loss: 1.6509e-05\n",
            "Epoch 443/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6499e-05 - decoder_output_loss: 1.6499e-05\n",
            "Epoch 444/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6471e-05 - decoder_output_loss: 1.6471e-05\n",
            "Epoch 445/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6492e-05 - decoder_output_loss: 1.6492e-05\n",
            "Epoch 446/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6449e-05 - decoder_output_loss: 1.6449e-05\n",
            "Epoch 447/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6465e-05 - decoder_output_loss: 1.6465e-05\n",
            "Epoch 448/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6448e-05 - decoder_output_loss: 1.6448e-05\n",
            "Epoch 449/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6449e-05 - decoder_output_loss: 1.6449e-05\n",
            "Epoch 450/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6444e-05 - decoder_output_loss: 1.6444e-05\n",
            "Epoch 451/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6444e-05 - decoder_output_loss: 1.6444e-05\n",
            "Epoch 452/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6420e-05 - decoder_output_loss: 1.6420e-05\n",
            "Epoch 453/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6420e-05 - decoder_output_loss: 1.6420e-05\n",
            "Epoch 454/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6417e-05 - decoder_output_loss: 1.6417e-05\n",
            "Epoch 455/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6411e-05 - decoder_output_loss: 1.6411e-05\n",
            "Epoch 456/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6404e-05 - decoder_output_loss: 1.6404e-05\n",
            "Epoch 457/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6400e-05 - decoder_output_loss: 1.6400e-05\n",
            "Epoch 458/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6399e-05 - decoder_output_loss: 1.6399e-05\n",
            "Epoch 459/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6376e-05 - decoder_output_loss: 1.6376e-05\n",
            "Epoch 460/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6382e-05 - decoder_output_loss: 1.6382e-05\n",
            "Epoch 461/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6375e-05 - decoder_output_loss: 1.6375e-05\n",
            "Epoch 462/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6366e-05 - decoder_output_loss: 1.6366e-05\n",
            "Epoch 463/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6366e-05 - decoder_output_loss: 1.6366e-05\n",
            "Epoch 464/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6368e-05 - decoder_output_loss: 1.6368e-05\n",
            "Epoch 465/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6370e-05 - decoder_output_loss: 1.6370e-05\n",
            "Epoch 466/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6334e-05 - decoder_output_loss: 1.6334e-05\n",
            "Epoch 467/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6331e-05 - decoder_output_loss: 1.6331e-05\n",
            "Epoch 468/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6315e-05 - decoder_output_loss: 1.6315e-05\n",
            "Epoch 469/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6314e-05 - decoder_output_loss: 1.6314e-05\n",
            "Epoch 470/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6314e-05 - decoder_output_loss: 1.6314e-05\n",
            "Epoch 471/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6303e-05 - decoder_output_loss: 1.6303e-05\n",
            "Epoch 472/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6295e-05 - decoder_output_loss: 1.6295e-05\n",
            "Epoch 473/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6273e-05 - decoder_output_loss: 1.6273e-05\n",
            "Epoch 474/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6288e-05 - decoder_output_loss: 1.6288e-05\n",
            "Epoch 475/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6273e-05 - decoder_output_loss: 1.6273e-05\n",
            "Epoch 476/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6275e-05 - decoder_output_loss: 1.6275e-05\n",
            "Epoch 477/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6262e-05 - decoder_output_loss: 1.6262e-05\n",
            "Epoch 478/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6260e-05 - decoder_output_loss: 1.6260e-05\n",
            "Epoch 479/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6239e-05 - decoder_output_loss: 1.6239e-05\n",
            "Epoch 480/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6251e-05 - decoder_output_loss: 1.6251e-05\n",
            "Epoch 481/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6244e-05 - decoder_output_loss: 1.6244e-05\n",
            "Epoch 482/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6232e-05 - decoder_output_loss: 1.6232e-05\n",
            "Epoch 483/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6214e-05 - decoder_output_loss: 1.6214e-05\n",
            "Epoch 484/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6214e-05 - decoder_output_loss: 1.6214e-05\n",
            "Epoch 485/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6200e-05 - decoder_output_loss: 1.6200e-05\n",
            "Epoch 486/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6215e-05 - decoder_output_loss: 1.6215e-05\n",
            "Epoch 487/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6182e-05 - decoder_output_loss: 1.6182e-05\n",
            "Epoch 488/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6158e-05 - decoder_output_loss: 1.6158e-05\n",
            "Epoch 489/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6140e-05 - decoder_output_loss: 1.6140e-05\n",
            "Epoch 490/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6148e-05 - decoder_output_loss: 1.6148e-05\n",
            "Epoch 491/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6124e-05 - decoder_output_loss: 1.6124e-05\n",
            "Epoch 492/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6110e-05 - decoder_output_loss: 1.6110e-05\n",
            "Epoch 493/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6097e-05 - decoder_output_loss: 1.6097e-05\n",
            "Epoch 494/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6082e-05 - decoder_output_loss: 1.6082e-05\n",
            "Epoch 495/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6110e-05 - decoder_output_loss: 1.6110e-05\n",
            "Epoch 496/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6093e-05 - decoder_output_loss: 1.6093e-05\n",
            "Epoch 497/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6061e-05 - decoder_output_loss: 1.6061e-05\n",
            "Epoch 498/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6062e-05 - decoder_output_loss: 1.6062e-05\n",
            "Epoch 499/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6052e-05 - decoder_output_loss: 1.6052e-05\n",
            "Epoch 500/500\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.6048e-05 - decoder_output_loss: 1.6048e-05\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x27925035cd0>"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model.fit(\n",
        "#     x=Train_nor_unlab['data'],\n",
        "#     y={'decoder_output': Train_nor_unlab['data']},\n",
        "#     batch_size=256,\n",
        "#     epochs=500,\n",
        "#     shuffle=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MyqtXuQNpThH"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss={'decoder_output': 'mse', 'classifier_output': 'binary_crossentropy'},\n",
        "    #loss_weights={'decoder_output': 1, 'classifier_output': 1.5},\n",
        "    metrics={'classifier_output': 'accuracy'}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4QuVTLSpWS_",
        "outputId": "4a643efb-0f06-4287-bb08-38f7a41efd7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "16/16 [==============================] - 3s 3ms/step - loss: 0.4809 - classifier_output_loss: 0.4720 - decoder_output_loss: 0.0088 - classifier_output_accuracy: 0.8690 \n",
            "Epoch 2/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3470 - classifier_output_loss: 0.3314 - decoder_output_loss: 0.0156 - classifier_output_accuracy: 0.9020\n",
            "Epoch 3/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3066 - classifier_output_loss: 0.2908 - decoder_output_loss: 0.0157 - classifier_output_accuracy: 0.9020\n",
            "Epoch 4/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2903 - classifier_output_loss: 0.2758 - decoder_output_loss: 0.0145 - classifier_output_accuracy: 0.9030\n",
            "Epoch 5/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2795 - classifier_output_loss: 0.2659 - decoder_output_loss: 0.0136 - classifier_output_accuracy: 0.9020\n",
            "Epoch 6/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2648 - classifier_output_loss: 0.2520 - decoder_output_loss: 0.0128 - classifier_output_accuracy: 0.9050\n",
            "Epoch 7/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2606 - classifier_output_loss: 0.2482 - decoder_output_loss: 0.0124 - classifier_output_accuracy: 0.9020\n",
            "Epoch 8/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2545 - classifier_output_loss: 0.2428 - decoder_output_loss: 0.0117 - classifier_output_accuracy: 0.9060\n",
            "Epoch 9/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2539 - classifier_output_loss: 0.2433 - decoder_output_loss: 0.0105 - classifier_output_accuracy: 0.9000\n",
            "Epoch 10/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2470 - classifier_output_loss: 0.2391 - decoder_output_loss: 0.0080 - classifier_output_accuracy: 0.9060\n",
            "Epoch 11/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2464 - classifier_output_loss: 0.2408 - decoder_output_loss: 0.0056 - classifier_output_accuracy: 0.9120\n",
            "Epoch 12/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2434 - classifier_output_loss: 0.2391 - decoder_output_loss: 0.0044 - classifier_output_accuracy: 0.9030\n",
            "Epoch 13/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2386 - classifier_output_loss: 0.2355 - decoder_output_loss: 0.0031 - classifier_output_accuracy: 0.9020\n",
            "Epoch 14/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2372 - classifier_output_loss: 0.2344 - decoder_output_loss: 0.0028 - classifier_output_accuracy: 0.9030\n",
            "Epoch 15/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2443 - classifier_output_loss: 0.2415 - decoder_output_loss: 0.0028 - classifier_output_accuracy: 0.9040\n",
            "Epoch 16/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2395 - classifier_output_loss: 0.2370 - decoder_output_loss: 0.0025 - classifier_output_accuracy: 0.9070\n",
            "Epoch 17/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2361 - classifier_output_loss: 0.2340 - decoder_output_loss: 0.0021 - classifier_output_accuracy: 0.9050\n",
            "Epoch 18/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2316 - classifier_output_loss: 0.2298 - decoder_output_loss: 0.0018 - classifier_output_accuracy: 0.9030\n",
            "Epoch 19/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2309 - classifier_output_loss: 0.2292 - decoder_output_loss: 0.0017 - classifier_output_accuracy: 0.9040\n",
            "Epoch 20/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2278 - classifier_output_loss: 0.2263 - decoder_output_loss: 0.0015 - classifier_output_accuracy: 0.9060\n",
            "Epoch 21/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2302 - classifier_output_loss: 0.2286 - decoder_output_loss: 0.0015 - classifier_output_accuracy: 0.9080\n",
            "Epoch 22/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2297 - classifier_output_loss: 0.2280 - decoder_output_loss: 0.0017 - classifier_output_accuracy: 0.9020\n",
            "Epoch 23/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2307 - classifier_output_loss: 0.2291 - decoder_output_loss: 0.0016 - classifier_output_accuracy: 0.9110\n",
            "Epoch 24/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2282 - classifier_output_loss: 0.2268 - decoder_output_loss: 0.0014 - classifier_output_accuracy: 0.9060\n",
            "Epoch 25/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2243 - classifier_output_loss: 0.2230 - decoder_output_loss: 0.0013 - classifier_output_accuracy: 0.9040\n",
            "Epoch 26/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2270 - classifier_output_loss: 0.2257 - decoder_output_loss: 0.0013 - classifier_output_accuracy: 0.9120\n",
            "Epoch 27/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2231 - classifier_output_loss: 0.2218 - decoder_output_loss: 0.0013 - classifier_output_accuracy: 0.9060\n",
            "Epoch 28/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2208 - classifier_output_loss: 0.2196 - decoder_output_loss: 0.0012 - classifier_output_accuracy: 0.9110\n",
            "Epoch 29/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2218 - classifier_output_loss: 0.2206 - decoder_output_loss: 0.0012 - classifier_output_accuracy: 0.9050\n",
            "Epoch 30/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2208 - classifier_output_loss: 0.2196 - decoder_output_loss: 0.0012 - classifier_output_accuracy: 0.9070\n",
            "Epoch 31/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2223 - classifier_output_loss: 0.2211 - decoder_output_loss: 0.0012 - classifier_output_accuracy: 0.9120\n",
            "Epoch 32/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2177 - classifier_output_loss: 0.2165 - decoder_output_loss: 0.0012 - classifier_output_accuracy: 0.9120\n",
            "Epoch 33/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2175 - classifier_output_loss: 0.2164 - decoder_output_loss: 0.0011 - classifier_output_accuracy: 0.9150\n",
            "Epoch 34/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2179 - classifier_output_loss: 0.2168 - decoder_output_loss: 0.0011 - classifier_output_accuracy: 0.9170\n",
            "Epoch 35/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2256 - classifier_output_loss: 0.2245 - decoder_output_loss: 0.0011 - classifier_output_accuracy: 0.9080\n",
            "Epoch 36/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2183 - classifier_output_loss: 0.2172 - decoder_output_loss: 0.0011 - classifier_output_accuracy: 0.9140\n",
            "Epoch 37/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2142 - classifier_output_loss: 0.2131 - decoder_output_loss: 0.0011 - classifier_output_accuracy: 0.9170\n",
            "Epoch 38/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2180 - classifier_output_loss: 0.2169 - decoder_output_loss: 0.0011 - classifier_output_accuracy: 0.9080\n",
            "Epoch 39/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2213 - classifier_output_loss: 0.2201 - decoder_output_loss: 0.0012 - classifier_output_accuracy: 0.9090\n",
            "Epoch 40/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2206 - classifier_output_loss: 0.2193 - decoder_output_loss: 0.0013 - classifier_output_accuracy: 0.9000\n",
            "Epoch 41/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2208 - classifier_output_loss: 0.2196 - decoder_output_loss: 0.0012 - classifier_output_accuracy: 0.9110\n",
            "Epoch 42/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2194 - classifier_output_loss: 0.2182 - decoder_output_loss: 0.0012 - classifier_output_accuracy: 0.9110\n",
            "Epoch 43/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2120 - classifier_output_loss: 0.2109 - decoder_output_loss: 0.0010 - classifier_output_accuracy: 0.9170\n",
            "Epoch 44/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2115 - classifier_output_loss: 0.2106 - decoder_output_loss: 9.5690e-04 - classifier_output_accuracy: 0.9200\n",
            "Epoch 45/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2110 - classifier_output_loss: 0.2101 - decoder_output_loss: 9.0545e-04 - classifier_output_accuracy: 0.9180\n",
            "Epoch 46/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2122 - classifier_output_loss: 0.2112 - decoder_output_loss: 9.6823e-04 - classifier_output_accuracy: 0.9190\n",
            "Epoch 47/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2113 - classifier_output_loss: 0.2104 - decoder_output_loss: 9.7621e-04 - classifier_output_accuracy: 0.9190\n",
            "Epoch 48/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2121 - classifier_output_loss: 0.2111 - decoder_output_loss: 9.4579e-04 - classifier_output_accuracy: 0.9140\n",
            "Epoch 49/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2121 - classifier_output_loss: 0.2112 - decoder_output_loss: 9.3155e-04 - classifier_output_accuracy: 0.9180\n",
            "Epoch 50/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2099 - classifier_output_loss: 0.2090 - decoder_output_loss: 8.9348e-04 - classifier_output_accuracy: 0.9170\n",
            "Epoch 51/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2086 - classifier_output_loss: 0.2077 - decoder_output_loss: 8.6113e-04 - classifier_output_accuracy: 0.9180\n",
            "Epoch 52/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2133 - classifier_output_loss: 0.2124 - decoder_output_loss: 8.9847e-04 - classifier_output_accuracy: 0.9130\n",
            "Epoch 53/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2084 - classifier_output_loss: 0.2075 - decoder_output_loss: 9.2010e-04 - classifier_output_accuracy: 0.9210\n",
            "Epoch 54/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2048 - classifier_output_loss: 0.2039 - decoder_output_loss: 8.9840e-04 - classifier_output_accuracy: 0.9240\n",
            "Epoch 55/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2100 - classifier_output_loss: 0.2090 - decoder_output_loss: 0.0010 - classifier_output_accuracy: 0.9180\n",
            "Epoch 56/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2111 - classifier_output_loss: 0.2100 - decoder_output_loss: 0.0010 - classifier_output_accuracy: 0.9160\n",
            "Epoch 57/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2048 - classifier_output_loss: 0.2038 - decoder_output_loss: 9.0563e-04 - classifier_output_accuracy: 0.9230\n",
            "Epoch 58/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2073 - classifier_output_loss: 0.2065 - decoder_output_loss: 8.6017e-04 - classifier_output_accuracy: 0.9200\n",
            "Epoch 59/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2066 - classifier_output_loss: 0.2056 - decoder_output_loss: 9.2322e-04 - classifier_output_accuracy: 0.9190\n",
            "Epoch 60/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2112 - classifier_output_loss: 0.2103 - decoder_output_loss: 9.3193e-04 - classifier_output_accuracy: 0.9140\n",
            "Epoch 61/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2162 - classifier_output_loss: 0.2154 - decoder_output_loss: 8.6693e-04 - classifier_output_accuracy: 0.9180\n",
            "Epoch 62/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2086 - classifier_output_loss: 0.2077 - decoder_output_loss: 8.7976e-04 - classifier_output_accuracy: 0.9130\n",
            "Epoch 63/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2095 - classifier_output_loss: 0.2086 - decoder_output_loss: 8.9407e-04 - classifier_output_accuracy: 0.9150\n",
            "Epoch 64/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2080 - classifier_output_loss: 0.2071 - decoder_output_loss: 8.8873e-04 - classifier_output_accuracy: 0.9170\n",
            "Epoch 65/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2050 - classifier_output_loss: 0.2041 - decoder_output_loss: 8.7469e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 66/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2047 - classifier_output_loss: 0.2039 - decoder_output_loss: 8.4459e-04 - classifier_output_accuracy: 0.9190\n",
            "Epoch 67/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2030 - classifier_output_loss: 0.2021 - decoder_output_loss: 8.4072e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 68/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2122 - classifier_output_loss: 0.2113 - decoder_output_loss: 8.9940e-04 - classifier_output_accuracy: 0.9150\n",
            "Epoch 69/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2040 - classifier_output_loss: 0.2032 - decoder_output_loss: 8.6534e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 70/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2036 - classifier_output_loss: 0.2028 - decoder_output_loss: 8.6650e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 71/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2059 - classifier_output_loss: 0.2050 - decoder_output_loss: 9.0600e-04 - classifier_output_accuracy: 0.9210\n",
            "Epoch 72/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2019 - classifier_output_loss: 0.2010 - decoder_output_loss: 8.8031e-04 - classifier_output_accuracy: 0.9250\n",
            "Epoch 73/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2113 - classifier_output_loss: 0.2103 - decoder_output_loss: 9.2970e-04 - classifier_output_accuracy: 0.9190\n",
            "Epoch 74/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2047 - classifier_output_loss: 0.2037 - decoder_output_loss: 9.9324e-04 - classifier_output_accuracy: 0.9230\n",
            "Epoch 75/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2122 - classifier_output_loss: 0.2112 - decoder_output_loss: 0.0010 - classifier_output_accuracy: 0.9170\n",
            "Epoch 76/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2018 - classifier_output_loss: 0.2009 - decoder_output_loss: 8.9646e-04 - classifier_output_accuracy: 0.9240\n",
            "Epoch 77/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2036 - classifier_output_loss: 0.2027 - decoder_output_loss: 8.8044e-04 - classifier_output_accuracy: 0.9200\n",
            "Epoch 78/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2044 - classifier_output_loss: 0.2035 - decoder_output_loss: 8.8865e-04 - classifier_output_accuracy: 0.9160\n",
            "Epoch 79/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1992 - classifier_output_loss: 0.1984 - decoder_output_loss: 8.5603e-04 - classifier_output_accuracy: 0.9250\n",
            "Epoch 80/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2024 - classifier_output_loss: 0.2015 - decoder_output_loss: 8.7841e-04 - classifier_output_accuracy: 0.9210\n",
            "Epoch 81/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1970 - classifier_output_loss: 0.1961 - decoder_output_loss: 8.7529e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 82/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1981 - classifier_output_loss: 0.1972 - decoder_output_loss: 8.4461e-04 - classifier_output_accuracy: 0.9230\n",
            "Epoch 83/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1993 - classifier_output_loss: 0.1984 - decoder_output_loss: 8.6703e-04 - classifier_output_accuracy: 0.9200\n",
            "Epoch 84/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1933 - classifier_output_loss: 0.1924 - decoder_output_loss: 8.9727e-04 - classifier_output_accuracy: 0.9230\n",
            "Epoch 85/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2147 - classifier_output_loss: 0.2137 - decoder_output_loss: 9.7137e-04 - classifier_output_accuracy: 0.9070\n",
            "Epoch 86/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2009 - classifier_output_loss: 0.1999 - decoder_output_loss: 9.1000e-04 - classifier_output_accuracy: 0.9160\n",
            "Epoch 87/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2001 - classifier_output_loss: 0.1993 - decoder_output_loss: 8.6251e-04 - classifier_output_accuracy: 0.9200\n",
            "Epoch 88/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1960 - classifier_output_loss: 0.1952 - decoder_output_loss: 8.3502e-04 - classifier_output_accuracy: 0.9230\n",
            "Epoch 89/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1986 - classifier_output_loss: 0.1978 - decoder_output_loss: 8.0253e-04 - classifier_output_accuracy: 0.9240\n",
            "Epoch 90/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1966 - classifier_output_loss: 0.1958 - decoder_output_loss: 8.0861e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 91/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1948 - classifier_output_loss: 0.1940 - decoder_output_loss: 7.9332e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 92/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1968 - classifier_output_loss: 0.1960 - decoder_output_loss: 8.8562e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 93/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1983 - classifier_output_loss: 0.1974 - decoder_output_loss: 9.1569e-04 - classifier_output_accuracy: 0.9190\n",
            "Epoch 94/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2001 - classifier_output_loss: 0.1992 - decoder_output_loss: 8.3068e-04 - classifier_output_accuracy: 0.9210\n",
            "Epoch 95/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1970 - classifier_output_loss: 0.1961 - decoder_output_loss: 8.3310e-04 - classifier_output_accuracy: 0.9190\n",
            "Epoch 96/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2007 - classifier_output_loss: 0.1999 - decoder_output_loss: 8.7234e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 97/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1974 - classifier_output_loss: 0.1966 - decoder_output_loss: 8.3346e-04 - classifier_output_accuracy: 0.9200\n",
            "Epoch 98/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1961 - classifier_output_loss: 0.1953 - decoder_output_loss: 8.1958e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 99/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1979 - classifier_output_loss: 0.1971 - decoder_output_loss: 7.9602e-04 - classifier_output_accuracy: 0.9190\n",
            "Epoch 100/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1926 - classifier_output_loss: 0.1918 - decoder_output_loss: 7.8223e-04 - classifier_output_accuracy: 0.9240\n",
            "Epoch 101/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1910 - classifier_output_loss: 0.1902 - decoder_output_loss: 7.7984e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 102/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1923 - classifier_output_loss: 0.1916 - decoder_output_loss: 7.6928e-04 - classifier_output_accuracy: 0.9250\n",
            "Epoch 103/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2029 - classifier_output_loss: 0.2021 - decoder_output_loss: 8.2266e-04 - classifier_output_accuracy: 0.9210\n",
            "Epoch 104/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1970 - classifier_output_loss: 0.1962 - decoder_output_loss: 7.9551e-04 - classifier_output_accuracy: 0.9180\n",
            "Epoch 105/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1919 - classifier_output_loss: 0.1911 - decoder_output_loss: 8.4461e-04 - classifier_output_accuracy: 0.9230\n",
            "Epoch 106/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2035 - classifier_output_loss: 0.2026 - decoder_output_loss: 8.7998e-04 - classifier_output_accuracy: 0.9140\n",
            "Epoch 107/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2044 - classifier_output_loss: 0.2036 - decoder_output_loss: 8.1241e-04 - classifier_output_accuracy: 0.9170\n",
            "Epoch 108/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1969 - classifier_output_loss: 0.1960 - decoder_output_loss: 8.4283e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 109/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1965 - classifier_output_loss: 0.1957 - decoder_output_loss: 8.0153e-04 - classifier_output_accuracy: 0.9210\n",
            "Epoch 110/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1949 - classifier_output_loss: 0.1941 - decoder_output_loss: 7.7417e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 111/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2000 - classifier_output_loss: 0.1992 - decoder_output_loss: 7.6254e-04 - classifier_output_accuracy: 0.9190\n",
            "Epoch 112/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1918 - classifier_output_loss: 0.1911 - decoder_output_loss: 7.3112e-04 - classifier_output_accuracy: 0.9200\n",
            "Epoch 113/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1945 - classifier_output_loss: 0.1938 - decoder_output_loss: 7.3679e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 114/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1922 - classifier_output_loss: 0.1914 - decoder_output_loss: 7.3532e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 115/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1902 - classifier_output_loss: 0.1895 - decoder_output_loss: 7.0744e-04 - classifier_output_accuracy: 0.9250\n",
            "Epoch 116/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1937 - classifier_output_loss: 0.1930 - decoder_output_loss: 7.1279e-04 - classifier_output_accuracy: 0.9210\n",
            "Epoch 117/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1904 - classifier_output_loss: 0.1897 - decoder_output_loss: 7.0980e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 118/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1919 - classifier_output_loss: 0.1912 - decoder_output_loss: 7.1909e-04 - classifier_output_accuracy: 0.9210\n",
            "Epoch 119/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1917 - classifier_output_loss: 0.1910 - decoder_output_loss: 7.3721e-04 - classifier_output_accuracy: 0.9240\n",
            "Epoch 120/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2005 - classifier_output_loss: 0.1997 - decoder_output_loss: 7.7198e-04 - classifier_output_accuracy: 0.9170\n",
            "Epoch 121/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1966 - classifier_output_loss: 0.1958 - decoder_output_loss: 7.9899e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 122/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2047 - classifier_output_loss: 0.2040 - decoder_output_loss: 7.4103e-04 - classifier_output_accuracy: 0.9170\n",
            "Epoch 123/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1936 - classifier_output_loss: 0.1928 - decoder_output_loss: 7.1503e-04 - classifier_output_accuracy: 0.9190\n",
            "Epoch 124/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1878 - classifier_output_loss: 0.1871 - decoder_output_loss: 7.1387e-04 - classifier_output_accuracy: 0.9280\n",
            "Epoch 125/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2034 - classifier_output_loss: 0.2027 - decoder_output_loss: 7.2464e-04 - classifier_output_accuracy: 0.9140\n",
            "Epoch 126/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1894 - classifier_output_loss: 0.1887 - decoder_output_loss: 7.1814e-04 - classifier_output_accuracy: 0.9230\n",
            "Epoch 127/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1902 - classifier_output_loss: 0.1895 - decoder_output_loss: 7.0183e-04 - classifier_output_accuracy: 0.9200\n",
            "Epoch 128/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2029 - classifier_output_loss: 0.2022 - decoder_output_loss: 7.2975e-04 - classifier_output_accuracy: 0.9160\n",
            "Epoch 129/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1899 - classifier_output_loss: 0.1891 - decoder_output_loss: 7.2063e-04 - classifier_output_accuracy: 0.9290\n",
            "Epoch 130/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1949 - classifier_output_loss: 0.1942 - decoder_output_loss: 7.2067e-04 - classifier_output_accuracy: 0.9150\n",
            "Epoch 131/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1876 - classifier_output_loss: 0.1869 - decoder_output_loss: 7.0836e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 132/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1924 - classifier_output_loss: 0.1917 - decoder_output_loss: 6.9868e-04 - classifier_output_accuracy: 0.9230\n",
            "Epoch 133/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1869 - classifier_output_loss: 0.1863 - decoder_output_loss: 6.9178e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 134/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1872 - classifier_output_loss: 0.1865 - decoder_output_loss: 6.8785e-04 - classifier_output_accuracy: 0.9290\n",
            "Epoch 135/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1931 - classifier_output_loss: 0.1924 - decoder_output_loss: 7.1920e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 136/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1855 - classifier_output_loss: 0.1848 - decoder_output_loss: 7.1430e-04 - classifier_output_accuracy: 0.9320\n",
            "Epoch 137/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1916 - classifier_output_loss: 0.1909 - decoder_output_loss: 7.1158e-04 - classifier_output_accuracy: 0.9230\n",
            "Epoch 138/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1851 - classifier_output_loss: 0.1844 - decoder_output_loss: 7.0846e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 139/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1919 - classifier_output_loss: 0.1912 - decoder_output_loss: 7.0606e-04 - classifier_output_accuracy: 0.9210\n",
            "Epoch 140/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1858 - classifier_output_loss: 0.1850 - decoder_output_loss: 7.2088e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 141/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1980 - classifier_output_loss: 0.1973 - decoder_output_loss: 6.9379e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 142/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1934 - classifier_output_loss: 0.1928 - decoder_output_loss: 6.7969e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 143/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1893 - classifier_output_loss: 0.1885 - decoder_output_loss: 7.1094e-04 - classifier_output_accuracy: 0.9250\n",
            "Epoch 144/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1865 - classifier_output_loss: 0.1858 - decoder_output_loss: 6.8665e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 145/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1830 - classifier_output_loss: 0.1823 - decoder_output_loss: 6.7856e-04 - classifier_output_accuracy: 0.9250\n",
            "Epoch 146/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1853 - classifier_output_loss: 0.1846 - decoder_output_loss: 6.7894e-04 - classifier_output_accuracy: 0.9250\n",
            "Epoch 147/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1850 - classifier_output_loss: 0.1843 - decoder_output_loss: 7.4379e-04 - classifier_output_accuracy: 0.9320\n",
            "Epoch 148/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1998 - classifier_output_loss: 0.1991 - decoder_output_loss: 7.4200e-04 - classifier_output_accuracy: 0.9200\n",
            "Epoch 149/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1863 - classifier_output_loss: 0.1856 - decoder_output_loss: 7.1844e-04 - classifier_output_accuracy: 0.9230\n",
            "Epoch 150/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1891 - classifier_output_loss: 0.1884 - decoder_output_loss: 6.8718e-04 - classifier_output_accuracy: 0.9250\n",
            "Epoch 151/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1874 - classifier_output_loss: 0.1867 - decoder_output_loss: 7.1511e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 152/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1852 - classifier_output_loss: 0.1845 - decoder_output_loss: 7.0997e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 153/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1858 - classifier_output_loss: 0.1851 - decoder_output_loss: 6.7683e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 154/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1829 - classifier_output_loss: 0.1823 - decoder_output_loss: 6.7485e-04 - classifier_output_accuracy: 0.9250\n",
            "Epoch 155/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1817 - classifier_output_loss: 0.1810 - decoder_output_loss: 7.0640e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 156/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1811 - classifier_output_loss: 0.1804 - decoder_output_loss: 6.9491e-04 - classifier_output_accuracy: 0.9310\n",
            "Epoch 157/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2028 - classifier_output_loss: 0.2020 - decoder_output_loss: 7.3594e-04 - classifier_output_accuracy: 0.9180\n",
            "Epoch 158/200\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1877 - classifier_output_loss: 0.1870 - decoder_output_loss: 7.3792e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 159/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1838 - classifier_output_loss: 0.1831 - decoder_output_loss: 6.9997e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 160/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1824 - classifier_output_loss: 0.1818 - decoder_output_loss: 6.8566e-04 - classifier_output_accuracy: 0.9280\n",
            "Epoch 161/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1822 - classifier_output_loss: 0.1815 - decoder_output_loss: 6.7117e-04 - classifier_output_accuracy: 0.9300\n",
            "Epoch 162/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1845 - classifier_output_loss: 0.1839 - decoder_output_loss: 6.8422e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 163/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1887 - classifier_output_loss: 0.1879 - decoder_output_loss: 7.6134e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 164/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1886 - classifier_output_loss: 0.1878 - decoder_output_loss: 7.8401e-04 - classifier_output_accuracy: 0.9230\n",
            "Epoch 165/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1858 - classifier_output_loss: 0.1851 - decoder_output_loss: 7.0174e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 166/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1915 - classifier_output_loss: 0.1907 - decoder_output_loss: 7.7255e-04 - classifier_output_accuracy: 0.9190\n",
            "Epoch 167/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1831 - classifier_output_loss: 0.1824 - decoder_output_loss: 7.2614e-04 - classifier_output_accuracy: 0.9310\n",
            "Epoch 168/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1830 - classifier_output_loss: 0.1824 - decoder_output_loss: 6.6355e-04 - classifier_output_accuracy: 0.9300\n",
            "Epoch 169/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1790 - classifier_output_loss: 0.1783 - decoder_output_loss: 6.8291e-04 - classifier_output_accuracy: 0.9350\n",
            "Epoch 170/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1821 - classifier_output_loss: 0.1814 - decoder_output_loss: 6.9026e-04 - classifier_output_accuracy: 0.9280\n",
            "Epoch 171/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1888 - classifier_output_loss: 0.1881 - decoder_output_loss: 6.9974e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 172/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1834 - classifier_output_loss: 0.1827 - decoder_output_loss: 6.9393e-04 - classifier_output_accuracy: 0.9290\n",
            "Epoch 173/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1877 - classifier_output_loss: 0.1870 - decoder_output_loss: 6.7705e-04 - classifier_output_accuracy: 0.9210\n",
            "Epoch 174/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1858 - classifier_output_loss: 0.1851 - decoder_output_loss: 7.0494e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 175/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1814 - classifier_output_loss: 0.1807 - decoder_output_loss: 7.0455e-04 - classifier_output_accuracy: 0.9300\n",
            "Epoch 176/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1911 - classifier_output_loss: 0.1904 - decoder_output_loss: 6.9760e-04 - classifier_output_accuracy: 0.9160\n",
            "Epoch 177/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1803 - classifier_output_loss: 0.1796 - decoder_output_loss: 6.8232e-04 - classifier_output_accuracy: 0.9340\n",
            "Epoch 178/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1766 - classifier_output_loss: 0.1760 - decoder_output_loss: 6.5331e-04 - classifier_output_accuracy: 0.9350\n",
            "Epoch 179/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1818 - classifier_output_loss: 0.1811 - decoder_output_loss: 6.8690e-04 - classifier_output_accuracy: 0.9310\n",
            "Epoch 180/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1882 - classifier_output_loss: 0.1876 - decoder_output_loss: 6.7404e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 181/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1904 - classifier_output_loss: 0.1898 - decoder_output_loss: 6.8288e-04 - classifier_output_accuracy: 0.9260\n",
            "Epoch 182/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1831 - classifier_output_loss: 0.1824 - decoder_output_loss: 6.8680e-04 - classifier_output_accuracy: 0.9290\n",
            "Epoch 183/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1942 - classifier_output_loss: 0.1936 - decoder_output_loss: 6.7293e-04 - classifier_output_accuracy: 0.9210\n",
            "Epoch 184/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1903 - classifier_output_loss: 0.1896 - decoder_output_loss: 6.9579e-04 - classifier_output_accuracy: 0.9210\n",
            "Epoch 185/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1952 - classifier_output_loss: 0.1945 - decoder_output_loss: 7.1874e-04 - classifier_output_accuracy: 0.9220\n",
            "Epoch 186/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1836 - classifier_output_loss: 0.1829 - decoder_output_loss: 6.8128e-04 - classifier_output_accuracy: 0.9320\n",
            "Epoch 187/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1795 - classifier_output_loss: 0.1788 - decoder_output_loss: 7.0859e-04 - classifier_output_accuracy: 0.9310\n",
            "Epoch 188/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1769 - classifier_output_loss: 0.1762 - decoder_output_loss: 7.0569e-04 - classifier_output_accuracy: 0.9360\n",
            "Epoch 189/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1771 - classifier_output_loss: 0.1764 - decoder_output_loss: 6.6531e-04 - classifier_output_accuracy: 0.9310\n",
            "Epoch 190/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1768 - classifier_output_loss: 0.1761 - decoder_output_loss: 6.8759e-04 - classifier_output_accuracy: 0.9330\n",
            "Epoch 191/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1803 - classifier_output_loss: 0.1797 - decoder_output_loss: 6.7999e-04 - classifier_output_accuracy: 0.9280\n",
            "Epoch 192/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1837 - classifier_output_loss: 0.1830 - decoder_output_loss: 7.0443e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 193/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1762 - classifier_output_loss: 0.1755 - decoder_output_loss: 6.9782e-04 - classifier_output_accuracy: 0.9320\n",
            "Epoch 194/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1806 - classifier_output_loss: 0.1799 - decoder_output_loss: 6.8807e-04 - classifier_output_accuracy: 0.9300\n",
            "Epoch 195/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1802 - classifier_output_loss: 0.1795 - decoder_output_loss: 6.8860e-04 - classifier_output_accuracy: 0.9270\n",
            "Epoch 196/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1741 - classifier_output_loss: 0.1734 - decoder_output_loss: 6.7522e-04 - classifier_output_accuracy: 0.9320\n",
            "Epoch 197/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1761 - classifier_output_loss: 0.1755 - decoder_output_loss: 6.5323e-04 - classifier_output_accuracy: 0.9280\n",
            "Epoch 198/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1757 - classifier_output_loss: 0.1751 - decoder_output_loss: 6.6611e-04 - classifier_output_accuracy: 0.9320\n",
            "Epoch 199/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1723 - classifier_output_loss: 0.1716 - decoder_output_loss: 6.9676e-04 - classifier_output_accuracy: 0.9320\n",
            "Epoch 200/200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1754 - classifier_output_loss: 0.1747 - decoder_output_loss: 6.9199e-04 - classifier_output_accuracy: 0.9320\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1fee3581a10>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    x=Train_labeled,\n",
        "    y={'decoder_output': Train_labeled, 'classifier_output': Labeled},\n",
        "    batch_size=64,\n",
        "    epochs=200,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1c0825a4d90>"
            ]
          },
          "execution_count": 235,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#model.save('Model/AE_500.model', save_format='tf')  # The file needs to end with the .keras extension\n",
        "\n",
        "# model_path = 'Model/AE_fullclass_200_new.model'\n",
        "# model.load_weights(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcLTa9lNyZDC",
        "outputId": "ea9b9f99-750c-4ba1-fdb6-0236106e6e81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48/48 [==============================] - 1s 13ms/step\n",
            "22/22 [==============================] - 0s 13ms/step\n",
            "12/12 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n"
          ]
        }
      ],
      "source": [
        "train_normal_re = model.get_reconstruction_error(Train_nor['data'], batch_size=10000)\n",
        "train_abnormal_re = model.get_reconstruction_error(Train_abnor_4clss['data'], batch_size=10000)\n",
        "\n",
        "test_normal_re = model.get_reconstruction_error(Test_nor, batch_size=10000)\n",
        "test_abnormal_re = model.get_reconstruction_error(Test_abnor, batch_size=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48/48 [==============================] - 1s 12ms/step\n",
            "22/22 [==============================] - 0s 13ms/step\n"
          ]
        }
      ],
      "source": [
        "anomaly_scores_nor = 0.6 * train_normal_re + 0.4 * model.get_classifier_prob(Train_nor['data'])\n",
        "anomaly_scores_abnor = 0.6 * train_abnormal_re + 0.4* model.get_classifier_prob(Train_abnor_4clss['data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(480000,), dtype=float32, numpy=\n",
              "array([7.4005447e-04, 3.5647410e-01, 1.9824183e-01, ..., 4.6437318e-04,\n",
              "       7.5907103e-04, 5.3909975e-05], dtype=float32)>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "anomaly_scores_nor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "sigma = 5\n",
        "alpha = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3591022402048111"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sigma_threshold = np.percentile(anomaly_scores_nor, 100 - sigma)\n",
        "sigma_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ngưỡng vừa tìm được: 0.07139948010444641\n"
          ]
        }
      ],
      "source": [
        "threshold = np.concatenate([anomaly_scores_nor,anomaly_scores_abnor]).mean() * alpha\n",
        "print('Ngưỡng vừa tìm được:', threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = np.concatenate((Train_nor['data'], Train_abnor_4clss['data']), axis=0)\n",
        "label = np.concatenate((Train_nor['label'], Train_abnor_4clss['label']), axis=0)\n",
        "train_fullclss = np.concatenate((Train_nor['data'], Train_abnor['data']), axis=0)\n",
        "label_fullclss = np.concatenate((Train_nor['label'], Train_abnor['label']), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kết quả trước khi threshold qua vòng tối ưu "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48/48 [==============================] - 1s 10ms/step\n",
            "48/48 [==============================] - 1s 10ms/step\n",
            "Acc AE với tập train 0.8304520833333333\n"
          ]
        }
      ],
      "source": [
        "Nor_P = model.predict_class(Train_nor['data'],threshold,0.6,0.4,batch_size=10000)\n",
        "acc_Nor = accuracy_score(Train_nor['label'],Nor_P)\n",
        "print(\"Acc AE với tập train\",acc_Nor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 9ms/step\n",
            "9/9 [==============================] - 0s 9ms/step\n",
            "Acc AE với tập train 0.5951552345669773\n"
          ]
        }
      ],
      "source": [
        "#new attack\n",
        "DoS_P = model.predict_class(Train_DoS['data'],threshold,0.6,0.4,batch_size=10000)\n",
        "acc_DoS = accuracy_score(Train_DoS['label'], DoS_P)\n",
        "print(\"Acc AE với tập train\",acc_DoS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 9ms/step\n",
            "8/8 [==============================] - 0s 9ms/step\n",
            "Acc AE với tập train 0.9959751088643762\n"
          ]
        }
      ],
      "source": [
        "DoS_Gas_P = model.predict_class(Train_DoSGas['data'],threshold,0.6,0.4,batch_size=10000)\n",
        "acc_DoSGas = accuracy_score(Train_DoSGas['label'], DoS_Gas_P)\n",
        "print(\"Acc AE với tập train\",acc_DoSGas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 10ms/step\n",
            "5/5 [==============================] - 0s 9ms/step\n",
            "Acc AE với tập train 0.9827505941734251\n"
          ]
        }
      ],
      "source": [
        "OaU_P = model.predict_class(Train_OaU['data'],threshold,0.6,0.4,batch_size=10000)\n",
        "acc_OaU = accuracy_score(Train_OaU['label'], OaU_P)\n",
        "print(\"Acc AE với tập train\",acc_OaU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 10ms/step\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "Acc AE với tập train 0.9944313048266196\n"
          ]
        }
      ],
      "source": [
        "FoT_P = model.predict_class(Train_FoT['data'],threshold,0.6,0.4,batch_size=10000)\n",
        "acc_FoT = accuracy_score(Train_FoT['label'], FoT_P)\n",
        "print(\"Acc AE với tập train\",acc_FoT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 6ms/step\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "Acc AE với tập train 0.9854292205867826\n"
          ]
        }
      ],
      "source": [
        "BP_P = model.predict_class(Train_BP['data'],threshold,0.6,0.4,batch_size=10000)\n",
        "acc_BP = accuracy_score(Train_BP['label'], BP_P)\n",
        "print(\"Acc AE với tập train\",acc_BP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "values = [acc_DoS, acc_BP, acc_DoSGas, acc_FoT, acc_OaU, acc_Nor]\n",
        "\n",
        "labels = ['DoS', 'BP', 'DoS_Gas', 'FoT', 'OaU', 'Nor']\n",
        "bars = plt.bar(labels, values)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Acc')\n",
        "plt.title('Accuracy each class')\n",
        "\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval, round(yval, 2), va='bottom')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "DoS_re = model.get_reconstruction_error(Train_DoSGas['data'], batch_size=10000)\n",
        "anomaly_DoS = DoS_re * 0.5 + 0.5 * model.get_classifier_prob(Train_DoSGas['data'],batch_size=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "Acc AE với tập train 4 class 0.8801903232641507\n",
            "78/78 [==============================] - 1s 13ms/step\n",
            "78/78 [==============================] - 1s 13ms/step\n",
            "Acc AE với tập train full class 0.8413706042876931\n",
            "20/20 [==============================] - 0s 13ms/step\n",
            "20/20 [==============================] - 0s 13ms/step\n",
            "Acc AE với tập test full class 0.8501994997002336\n"
          ]
        }
      ],
      "source": [
        "P_CL = model.predict_class(train,threshold,0.6,0.4,batch_size=10000)\n",
        "print(\"Acc AE với tập train 4 class\",accuracy_score(label, P_CL)) \n",
        "#AE: 4 class attack 89,493% , full class attack 89,956% / Classifier 4 clss 87,54% , full class attack 88,805%\n",
        "# Bỏ DoS: AE 4 class 87,85% , full class 84,9 / Clf 4 class 88,01 , full class 82,19 (chưa tối ưu ngưỡng)\n",
        "P_CL2 = model.predict_class(train_fullclss,threshold,0.6,0.4,batch_size=10000)\n",
        "print(\"Acc AE với tập train full class\",accuracy_score(label_fullclss, P_CL2))\n",
        "\n",
        "P_CL2 = model.predict_class(test['data'],threshold,0.6,0.4,batch_size=10000)\n",
        "print(\"Acc AE với tập test full class\",accuracy_score(test['label'], P_CL2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70/70 [==============================] - 1s 13ms/step\n",
            "Acc Clf với tập train 4 class: 0.8919334589278533\n",
            "78/78 [==============================] - 1s 13ms/step\n",
            "Acc Clf với tập train full class: 0.8355316201856484\n",
            "20/20 [==============================] - 0s 12ms/step\n",
            "Acc Clf với tập train full class: 0.8344824378243162\n"
          ]
        }
      ],
      "source": [
        "label_1 = np.where(label == 'Normal', 0, 1)\n",
        "label_2 = np.where(label_fullclss == 'Normal', 0, 1)\n",
        "label_3 = np.where(test['label'] == 'Normal', 0, 1)\n",
        "\n",
        "y_pred = model.get_classifier_prob(train, batch_size=10000)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "acc_test = accuracy_score(label_1, y_pred_binary)\n",
        "print(\"Acc Clf với tập train 4 class:\",acc_test)\n",
        "\n",
        "y_pred2 = model.get_classifier_prob(train_fullclss, batch_size=10000)\n",
        "y_pred_binary2 = (y_pred2 > 0.5).astype(int)\n",
        "acc_test2 = accuracy_score(label_2, y_pred_binary2)\n",
        "print(\"Acc Clf với tập train full class:\",acc_test2)\n",
        "\n",
        "y_pred3 = model.get_classifier_prob(test['data'], batch_size=10000)\n",
        "y_pred_binary3 = (y_pred3 > 0.5).astype(int)\n",
        "acc_test3 = accuracy_score(label_3, y_pred_binary3)\n",
        "print(\"Acc Clf với tập train full class:\",acc_test3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 12ms/step\n",
            "Accuracy: 0.8801903232641507 \n",
            "Threshold: 0.07239948010444641\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "Accuracy: 0.8803950029332615 \n",
            "Threshold: 0.07339948010444641\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "Accuracy: 0.8806241865064207 \n",
            "Threshold: 0.07439948010444641\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 12ms/step\n",
            "Accuracy: 0.8807971552408805 \n",
            "Threshold: 0.07539948010444641\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "Accuracy: 0.8810148075650759 \n",
            "Threshold: 0.07639948010444642\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 12ms/step\n",
            "Accuracy: 0.8812382255137532 \n",
            "Threshold: 0.07739948010444642\n",
            "70/70 [==============================] - 1s 12ms/step\n",
            "70/70 [==============================] - 1s 12ms/step\n",
            "Accuracy: 0.881416959872695 \n",
            "Threshold: 0.07839948010444642\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "Accuracy: 0.8816288465724084 \n",
            "Threshold: 0.07939948010444642\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "Accuracy: 0.8818205535864346 \n",
            "Threshold: 0.08039948010444642\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "Accuracy: 0.8820079363820995 \n",
            "Threshold: 0.08139948010444642\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 14ms/step\n",
            "Accuracy: 0.8821967605838847 \n",
            "Threshold: 0.08239948010444642\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "Accuracy: 0.8824057644713571 \n",
            "Threshold: 0.08339948010444642\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 14ms/step\n",
            "Accuracy: 0.882544139458925 \n",
            "Threshold: 0.08439948010444642\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "Accuracy: 0.8827214324117463 \n",
            "Threshold: 0.08539948010444642\n",
            "70/70 [==============================] - 1s 12ms/step\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "Accuracy: 0.8829390847359416 \n",
            "Threshold: 0.08639948010444642\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "Accuracy: 0.8831235847193655 \n",
            "Threshold: 0.08739948010444643\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 14ms/step\n",
            "Accuracy: 0.8832879050171023 \n",
            "Threshold: 0.08839948010444643\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "Accuracy: 0.8834421354719957 \n",
            "Threshold: 0.08939948010444643\n",
            "70/70 [==============================] - 1s 13ms/step\n",
            "70/70 [==============================] - 1s 14ms/step\n",
            "Accuracy: 0.88359924873913 \n",
            "Threshold: 0.09039948010444643\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8837592448185053 \n",
            "Threshold: 0.09139948010444643\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8838889713693502 \n",
            "Threshold: 0.09239948010444643\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8840129322957131 \n",
            "Threshold: 0.09339948010444643\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8841786939995705 \n",
            "Threshold: 0.09439948010444643\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8843271588299818 \n",
            "Threshold: 0.09539948010444643\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.8845116588134057 \n",
            "Threshold: 0.09639948010444643\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8846269713030456 \n",
            "Threshold: 0.09739948010444643\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8847595806661315 \n",
            "Threshold: 0.09839948010444644\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8849080454965428 \n",
            "Threshold: 0.09939948010444644\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8850608345453157 \n",
            "Threshold: 0.10039948010444644\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.885180471253317 \n",
            "Threshold: 0.10139948010444644\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.885307314991921 \n",
            "Threshold: 0.10239948010444644\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8854356001366454 \n",
            "Threshold: 0.10339948010444644\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8855465884079237 \n",
            "Threshold: 0.10439948010444644\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8856993774566966 \n",
            "Threshold: 0.10539948010444644\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8858262211953004 \n",
            "Threshold: 0.10639948010444644\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8859415336849403 \n",
            "Threshold: 0.10739948010444644\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.8860525219562188 \n",
            "Threshold: 0.10839948010444644\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8862038695988711 \n",
            "Threshold: 0.10939948010444644\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.886304768027306 \n",
            "Threshold: 0.11039948010444645\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.886379721145572 \n",
            "Threshold: 0.11139948010444645\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.8864993578535734 \n",
            "Threshold: 0.11239948010444645\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8865757523779597 \n",
            "Threshold: 0.11339948010444645\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8866982718982022 \n",
            "Threshold: 0.11439948010444645\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8867962875143961 \n",
            "Threshold: 0.11539948010444645\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8868986273489514 \n",
            "Threshold: 0.11639948010444645\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8869923187467839 \n",
            "Threshold: 0.11739948010444645\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8871278109221107 \n",
            "Threshold: 0.11839948010444645\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8872460062239916 \n",
            "Threshold: 0.11939948010444645\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.8873224007483781 \n",
            "Threshold: 0.12039948010444645\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8874405960502589 \n",
            "Threshold: 0.12139948010444646\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8875818538500678 \n",
            "Threshold: 0.12239948010444646\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8876899593091052 \n",
            "Threshold: 0.12339948010444646\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8877908577375401 \n",
            "Threshold: 0.12439948010444646\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8878686936680471 \n",
            "Threshold: 0.12539948010444646\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.887940763974072 \n",
            "Threshold: 0.12639948010444646\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8880387795902659 \n",
            "Threshold: 0.12739948010444646\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8881151741146524 \n",
            "Threshold: 0.12839948010444646\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8881901272329182 \n",
            "Threshold: 0.12939948010444646\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8883371506572091 \n",
            "Threshold: 0.13039948010444646\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8883371506572091 \n",
            "Threshold: 0.13139948010444646\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8884034553387521 \n",
            "Threshold: 0.13239948010444647\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8884683186141745 \n",
            "Threshold: 0.13339948010444647\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8885634514181274 \n",
            "Threshold: 0.13439948010444647\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8886975021873338 \n",
            "Threshold: 0.13539948010444647\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.8887753381178407 \n",
            "Threshold: 0.13639948010444647\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8888733537340346 \n",
            "Threshold: 0.13739948010444647\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.8889598381012646 \n",
            "Threshold: 0.13839948010444647\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.889018935752205 \n",
            "Threshold: 0.13939948010444647\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8891083029316759 \n",
            "Threshold: 0.14039948010444647\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8891947872989058 \n",
            "Threshold: 0.14139948010444647\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8893014513518227 \n",
            "Threshold: 0.14239948010444647\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8893591075966427 \n",
            "Threshold: 0.14339948010444648\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.8894585646189571 \n",
            "Threshold: 0.14439948010444648\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8895565802351509 \n",
            "Threshold: 0.14539948010444648\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8896502716329834 \n",
            "Threshold: 0.14639948010444648\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8897309903757313 \n",
            "Threshold: 0.14739948010444648\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8897742325593463 \n",
            "Threshold: 0.14839948010444648\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8898318888041662 \n",
            "Threshold: 0.14939948010444648\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8898217989613227 \n",
            "Threshold: 0.15039948010444648\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8899010762979501 \n",
            "Threshold: 0.15139948010444648\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8899731466039751 \n",
            "Threshold: 0.15239948010444648\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8900394512855181 \n",
            "Threshold: 0.15339948010444648\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.890117287216025 \n",
            "Threshold: 0.15439948010444648\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8901980059587729 \n",
            "Threshold: 0.15539948010444649\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8902801661076414 \n",
            "Threshold: 0.1563994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8903378223524613 \n",
            "Threshold: 0.1573994801044465\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8903925957850403 \n",
            "Threshold: 0.1583994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8904401621870167 \n",
            "Threshold: 0.1593994801044465\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8904891699951136 \n",
            "Threshold: 0.1603994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.890577095768464 \n",
            "Threshold: 0.1613994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.890640517637766 \n",
            "Threshold: 0.1623994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8907082637254294 \n",
            "Threshold: 0.1633994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.890640517637766 \n",
            "Threshold: 0.1643994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8907961894987798 \n",
            "Threshold: 0.1653994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8908322246517923 \n",
            "Threshold: 0.1663994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8909374472985887 \n",
            "Threshold: 0.1673994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8910498769759876 \n",
            "Threshold: 0.1683994801044465\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8910758222861566 \n",
            "Threshold: 0.1693994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8911190644697715 \n",
            "Threshold: 0.1703994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8911796035268325 \n",
            "Threshold: 0.1713994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.891195458994158 \n",
            "Threshold: 0.1723994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8912387011777729 \n",
            "Threshold: 0.1733994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8913352753878464 \n",
            "Threshold: 0.1743994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8913511308551718 \n",
            "Threshold: 0.1753994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8914491464713657 \n",
            "Threshold: 0.1763994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8914664433448117 \n",
            "Threshold: 0.1773994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8914866230304987 \n",
            "Threshold: 0.1783994801044465\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8915039199039447 \n",
            "Threshold: 0.1793994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8915428378691982 \n",
            "Threshold: 0.1803994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8916033769262591 \n",
            "Threshold: 0.1813994801044465\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8916394120792716 \n",
            "Threshold: 0.1823994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917777870668394 \n",
            "Threshold: 0.1833994801044465\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917777870668394 \n",
            "Threshold: 0.1843994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917849940974419 \n",
            "Threshold: 0.1853994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8918801269013948 \n",
            "Threshold: 0.1863994801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8919132792421663 \n",
            "Threshold: 0.18739948010444651\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8919147206482868 \n",
            "Threshold: 0.18839948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8919839081420707 \n",
            "Threshold: 0.18939948010444652\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8920127362644807 \n",
            "Threshold: 0.19039948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8916999511363325 \n",
            "Threshold: 0.19139948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.891744634726068 \n",
            "Threshold: 0.19239948010444652\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8918037323770084 \n",
            "Threshold: 0.19339948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.8918195878443339 \n",
            "Threshold: 0.19439948010444652\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8918570644034669 \n",
            "Threshold: 0.19539948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8918325604994184 \n",
            "Threshold: 0.19639948010444652\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8918253534688159 \n",
            "Threshold: 0.19739948010444652\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8918311190932979 \n",
            "Threshold: 0.19839948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8918714784646719 \n",
            "Threshold: 0.19939948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8918974237748408 \n",
            "Threshold: 0.20039948010444653\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8919262518972508 \n",
            "Threshold: 0.20139948010444653\n",
            "--------------------------------------------------\n",
            "Best accuracy: 0.8920127362644807 \n",
            "Final threshold: 0.19039948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.8916999511363325 \n",
            "Threshold: 0.19089948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917287792587425 \n",
            "Threshold: 0.19139948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.891744634726068 \n",
            "Threshold: 0.19189948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917821112852009 \n",
            "Threshold: 0.19239948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8918037323770084 \n",
            "Threshold: 0.19289948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8918181464382134 \n",
            "Threshold: 0.19339948010444652\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 12ms/step\n",
            "Accuracy: 0.8918195878443339 \n",
            "Threshold: 0.19389948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8918296776871774 \n",
            "Threshold: 0.19439948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8918570644034669 \n",
            "Threshold: 0.19489948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8918340019055389 \n",
            "Threshold: 0.19539948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.8918325604994184 \n",
            "Threshold: 0.19589948010444652\n",
            "--------------------------------------------------\n",
            "Best accuracy: 0.8920127362644807 \n",
            "Final threshold: 0.19039948010444652\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8916999511363325 \n",
            "Threshold: 0.19064948010444652\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917085995730555 \n",
            "Threshold: 0.19089948010444652\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917287792587425 \n",
            "Threshold: 0.19114948010444652\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917230136342605 \n",
            "Threshold: 0.19139948010444652\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.891744634726068 \n",
            "Threshold: 0.19164948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917936425341649 \n",
            "Threshold: 0.19189948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917821112852009 \n",
            "Threshold: 0.19214948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917777870668394 \n",
            "Threshold: 0.19239948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8918037323770084 \n",
            "Threshold: 0.19264948010444652\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8918210292504544 \n",
            "Threshold: 0.19289948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8918181464382134 \n",
            "Threshold: 0.19314948010444652\n",
            "--------------------------------------------------\n",
            "Best accuracy: 0.8920127362644807 \n",
            "Final threshold: 0.19039948010444652\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8916999511363325 \n",
            "Threshold: 0.1905244801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.891704275354694 \n",
            "Threshold: 0.1906494801044465\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917085995730555 \n",
            "Threshold: 0.19077448010444648\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.891718689415899 \n",
            "Threshold: 0.19089948010444646\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917287792587425 \n",
            "Threshold: 0.19102448010444645\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.891733103477104 \n",
            "Threshold: 0.19114948010444643\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917230136342605 \n",
            "Threshold: 0.19127448010444642\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.891735986289345 \n",
            "Threshold: 0.1913994801044464\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.891744634726068 \n",
            "Threshold: 0.1915244801044464\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8917547245689115 \n",
            "Threshold: 0.19164948010444638\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917936425341649 \n",
            "Threshold: 0.19177448010444637\n",
            "--------------------------------------------------\n",
            "Best accuracy: 0.8920127362644807 \n",
            "Final threshold: 0.19039948010444638\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8916999511363325 \n",
            "Threshold: 0.19046198010444637\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.8917013925424531 \n",
            "Threshold: 0.19052448010444636\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.891704275354694 \n",
            "Threshold: 0.19058698010444636\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 11ms/step\n",
            "Accuracy: 0.8917057167608146 \n",
            "Threshold: 0.19064948010444635\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.8917085995730555 \n",
            "Threshold: 0.19071198010444634\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.891744634726068 \n",
            "Threshold: 0.19077448010444634\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.891718689415899 \n",
            "Threshold: 0.19083698010444633\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917287792587425 \n",
            "Threshold: 0.19089948010444632\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917287792587425 \n",
            "Threshold: 0.19096198010444632\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.8917345448832245 \n",
            "Threshold: 0.1910244801044463\n",
            "70/70 [==============================] - 1s 9ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Accuracy: 0.891733103477104 \n",
            "Threshold: 0.1910869801044463\n",
            "--------------------------------------------------\n",
            "Best accuracy: 0.8920127362644807 \n",
            "Final threshold: 0.1903994801044463\n"
          ]
        }
      ],
      "source": [
        "threshold = threshold # Initial threshold\n",
        "best_threshold = threshold      # Initial best threshold\n",
        "step = 1e-3                     # Initial step\n",
        "decay = 0.5                     # Decay rate\n",
        "num_decay = 5                   # Number of decay times\n",
        "pre = 0                         # Previous accuracy\n",
        "cur = 1e-9                      # Current accuracy\n",
        "best_acc = 1                    # Initial best accuracy\n",
        "occ = 10                        # Occurence of the previous accuracy better than the current one\n",
        "count = 0                       # Counter\n",
        "\n",
        "for d_i in range (num_decay):\n",
        "    for i in range (1000):\n",
        "        pre = cur\n",
        "        pred = model.predict_class(train,threshold,0.6,0.4, 10000)\n",
        "        acc  = accuracy_score(label, pred)\n",
        "        threshold = threshold + step\n",
        "        cur = acc\n",
        "        print(\"Accuracy:\", acc, \"\\nThreshold:\", threshold)\n",
        "\n",
        "        # If the previous accuracy is better than the current one. Plus the counter and store the best threshold and accuracy\n",
        "        if (pre > cur):\n",
        "            count = count + 1\n",
        "            cur = pre\n",
        "            best_threshold = threshold - count*step\n",
        "            best_acc = pre\n",
        "        else:\n",
        "            count = 0\n",
        "            best_threshold = threshold\n",
        "            continue\n",
        "\n",
        "        if count == occ + 1:\n",
        "            step = step * decay\n",
        "            threshold = best_threshold\n",
        "            count = 0\n",
        "            cur = best_acc\n",
        "            print(\"--------------------------------------------------\")\n",
        "            print(\"Best accuracy:\", best_acc, \"\\nFinal threshold:\", best_threshold)\n",
        "            break    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kết quả sau khi tối ưu threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_threshold = 0.1903994801044463"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48/48 [==============================] - 1s 11ms/step\n",
            "48/48 [==============================] - 0s 10ms/step\n",
            "Acc AE với tập train 0.8632416666666667\n",
            "9/9 [==============================] - 0s 9ms/step\n",
            "9/9 [==============================] - 0s 9ms/step\n",
            "Acc AE với tập train 0.5919869276154125\n",
            "8/8 [==============================] - 0s 9ms/step\n",
            "8/8 [==============================] - 0s 9ms/step\n",
            "Acc AE với tập train 0.9623610863085017\n",
            "5/5 [==============================] - 0s 8ms/step\n",
            "5/5 [==============================] - 0s 8ms/step\n",
            "Acc AE với tập train 0.920736039987259\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "Acc AE với tập train 0.9666879403336212\n",
            "3/3 [==============================] - 0s 7ms/step\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "Acc AE với tập train 0.9578188284105502\n"
          ]
        }
      ],
      "source": [
        "Nor_P = model.predict_class(Train_nor['data'],new_threshold,0.6,0.4,batch_size=10000)\n",
        "acc_Nor = accuracy_score(Train_nor['label'],Nor_P)\n",
        "print(\"Acc AE với tập train\",acc_Nor)\n",
        "\n",
        "#new attack\n",
        "DoS_P = model.predict_class(Train_DoS['data'],new_threshold,0.6,0.4,batch_size=10000)\n",
        "acc_DoS = accuracy_score(Train_DoS['label'], DoS_P)\n",
        "print(\"Acc AE với tập train\",acc_DoS)\n",
        "\n",
        "DoS_Gas_P = model.predict_class(Train_DoSGas['data'],new_threshold,0.6,0.4,batch_size=10000)\n",
        "acc_DoSGas = accuracy_score(Train_DoSGas['label'], DoS_Gas_P)\n",
        "print(\"Acc AE với tập train\",acc_DoSGas)\n",
        "\n",
        "OaU_P = model.predict_class(Train_OaU['data'],new_threshold,0.6,0.4,batch_size=10000)\n",
        "acc_OaU = accuracy_score(Train_OaU['label'], OaU_P)\n",
        "print(\"Acc AE với tập train\",acc_OaU)\n",
        "\n",
        "FoT_P = model.predict_class(Train_FoT['data'],new_threshold,0.6,0.4,batch_size=10000)\n",
        "acc_FoT = accuracy_score(Train_FoT['label'], FoT_P)\n",
        "print(\"Acc AE với tập train\",acc_FoT)\n",
        "\n",
        "BP_P = model.predict_class(Train_BP['data'],new_threshold,0.6,0.4,batch_size=10000)\n",
        "acc_BP = accuracy_score(Train_BP['label'], BP_P)\n",
        "print(\"Acc AE với tập train\",acc_BP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "values = [acc_DoS, acc_BP, acc_DoSGas, acc_FoT, acc_OaU, acc_Nor]\n",
        "\n",
        "labels = ['DoS', 'BP', 'DoS_Gas', 'FoT', 'OaU', 'Nor']\n",
        "bars = plt.bar(labels, values)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Acc')\n",
        "plt.title('Accuracy each class')\n",
        "\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval, round(yval, 2), va='bottom')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70/70 [==============================] - 1s 10ms/step\n",
            "70/70 [==============================] - 1s 10ms/step\n",
            "Acc AE với tập train 4 class 0.8916999511363325\n",
            "78/78 [==============================] - 1s 10ms/step\n",
            "78/78 [==============================] - 1s 10ms/step\n",
            "Acc AE với tập train full class 0.8355613384052428\n",
            "20/20 [==============================] - 0s 10ms/step\n",
            "20/20 [==============================] - 0s 9ms/step\n",
            "Acc AE với tập test full class 0.8604949246449319\n"
          ]
        }
      ],
      "source": [
        "P_CL = model.predict_class(train,new_threshold,0.6,0.4,batch_size=10000)\n",
        "print(\"Acc AE với tập train 4 class\",accuracy_score(label, P_CL)) \n",
        "\n",
        "P_CL2 = model.predict_class(train_fullclss,new_threshold,0.6,0.4,batch_size=10000)\n",
        "print(\"Acc AE với tập train full class\",accuracy_score(label_fullclss, P_CL2))\n",
        "\n",
        "P_CL2 = model.predict_class(test['data'],new_threshold,0.6,0.4,batch_size=10000)\n",
        "print(\"Acc AE với tập test full class\",accuracy_score(test['label'], P_CL2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = tf.concat([train_normal_re,train_abnormal_re], axis = 0)\n",
        "a= a.numpy()\n",
        "a = a.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(773936,)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_mapping = {\"Normal\": 0, \"Abnormal\": 1}\n",
        "label_z = [label_mapping[label] for label in label]\n",
        "label_z = np.array(label_z)\n",
        "label_z.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_re, X_test_re, y_train_re, y_test_re = train_test_split(a,label_z, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((619148, 1), (154788, 1), (619148,), (154788,))"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_re.shape, X_test_re.shape, y_train_re.shape, y_test_re.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/29 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 28/29 [17:54:19<1:19:17, 4757.66s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 235148, number of negative: 384000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001513 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 619148, number of used features: 1\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.379793 -> initscore=-0.490427\n",
            "[LightGBM] [Info] Start training from score -0.490427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29/29 [17:54:21<00:00, 2222.82s/it]  \n"
          ]
        }
      ],
      "source": [
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "models,predictions = clf.fit(X_train_re, X_test_re, y_train_re, y_test_re)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "      <th>ROC AUC</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier</th>\n",
              "      <td>0.73</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.70</td>\n",
              "      <td>19.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <td>0.73</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Perceptron</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>0.73</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.69</td>\n",
              "      <td>17.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>47.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>123.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingClassifier</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.68</td>\n",
              "      <td>12.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.68</td>\n",
              "      <td>8.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.68</td>\n",
              "      <td>1.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreeClassifier</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NuSVC</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.67</td>\n",
              "      <td>36780.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveClassifier</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.71</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.66</td>\n",
              "      <td>27401.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.70</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.66</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.66</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>37.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuadraticDiscriminantAnalysis</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernoulliNB</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CalibratedClassifierCV</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>5.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NearestCentroid</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CategoricalNB</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearDiscriminantAnalysis</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifier</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifierCV</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyClassifier</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
              "Model                                                                           \n",
              "XGBClassifier                      0.73               0.66     0.66      0.70   \n",
              "LGBMClassifier                     0.73               0.66     0.66      0.70   \n",
              "Perceptron                         0.72               0.65     0.65      0.69   \n",
              "AdaBoostClassifier                 0.73               0.65     0.65      0.69   \n",
              "ExtraTreesClassifier               0.72               0.65     0.65      0.68   \n",
              "RandomForestClassifier             0.72               0.65     0.65      0.68   \n",
              "BaggingClassifier                  0.72               0.64     0.64      0.68   \n",
              "KNeighborsClassifier               0.69               0.64     0.64      0.68   \n",
              "DecisionTreeClassifier             0.72               0.64     0.64      0.68   \n",
              "ExtraTreeClassifier                0.72               0.64     0.64      0.68   \n",
              "NuSVC                              0.72               0.64     0.64      0.67   \n",
              "PassiveAggressiveClassifier        0.72               0.63     0.63      0.66   \n",
              "SVC                                0.71               0.63     0.63      0.66   \n",
              "LogisticRegression                 0.70               0.61     0.61      0.64   \n",
              "SGDClassifier                      0.66               0.55     0.55      0.56   \n",
              "LinearSVC                          0.66               0.55     0.55      0.55   \n",
              "QuadraticDiscriminantAnalysis      0.65               0.55     0.55      0.55   \n",
              "GaussianNB                         0.65               0.55     0.55      0.55   \n",
              "BernoulliNB                        0.65               0.54     0.54      0.54   \n",
              "CalibratedClassifierCV             0.65               0.54     0.54      0.54   \n",
              "NearestCentroid                    0.65               0.54     0.54      0.54   \n",
              "CategoricalNB                      0.65               0.53     0.53      0.53   \n",
              "LinearDiscriminantAnalysis         0.65               0.53     0.53      0.53   \n",
              "RidgeClassifier                    0.65               0.53     0.53      0.53   \n",
              "RidgeClassifierCV                  0.65               0.53     0.53      0.53   \n",
              "DummyClassifier                    0.62               0.50     0.50      0.47   \n",
              "\n",
              "                               Time Taken  \n",
              "Model                                      \n",
              "XGBClassifier                       19.21  \n",
              "LGBMClassifier                       1.74  \n",
              "Perceptron                           0.50  \n",
              "AdaBoostClassifier                  17.23  \n",
              "ExtraTreesClassifier                47.71  \n",
              "RandomForestClassifier             123.21  \n",
              "BaggingClassifier                   12.76  \n",
              "KNeighborsClassifier                 8.78  \n",
              "DecisionTreeClassifier               1.60  \n",
              "ExtraTreeClassifier                  0.61  \n",
              "NuSVC                            36780.12  \n",
              "PassiveAggressiveClassifier          0.56  \n",
              "SVC                              27401.53  \n",
              "LogisticRegression                   0.76  \n",
              "SGDClassifier                        0.64  \n",
              "LinearSVC                           37.21  \n",
              "QuadraticDiscriminantAnalysis        0.22  \n",
              "GaussianNB                           0.20  \n",
              "BernoulliNB                          0.26  \n",
              "CalibratedClassifierCV               5.04  \n",
              "NearestCentroid                      0.24  \n",
              "CategoricalNB                        0.28  \n",
              "LinearDiscriminantAnalysis           0.29  \n",
              "RidgeClassifier                      0.26  \n",
              "RidgeClassifierCV                    0.38  \n",
              "DummyClassifier                      0.17  "
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "      <th>ROC AUC</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier</th>\n",
              "      <td>0.66</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.65</td>\n",
              "      <td>8.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.62</td>\n",
              "      <td>3.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.60</td>\n",
              "      <td>30.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingClassifier</th>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.60</td>\n",
              "      <td>3.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.62</td>\n",
              "      <td>1.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Perceptron</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>11.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreeClassifier</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.56</td>\n",
              "      <td>983.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CalibratedClassifierCV</th>\n",
              "      <td>0.61</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.54</td>\n",
              "      <td>1.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.58</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.49</td>\n",
              "      <td>2.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveClassifier</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuadraticDiscriminantAnalysis</th>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernoulliNB</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NearestCentroid</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearDiscriminantAnalysis</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifierCV</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CategoricalNB</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyClassifier</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NuSVC</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1625.17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
              "Model                                                                           \n",
              "XGBClassifier                      0.66               0.66     0.66      0.65   \n",
              "LGBMClassifier                     0.65               0.65     0.65      0.64   \n",
              "AdaBoostClassifier                 0.65               0.65     0.65      0.62   \n",
              "DecisionTreeClassifier             0.63               0.63     0.63      0.60   \n",
              "RandomForestClassifier             0.63               0.63     0.63      0.60   \n",
              "BaggingClassifier                  0.63               0.63     0.63      0.60   \n",
              "LogisticRegression                 0.62               0.63     0.63      0.57   \n",
              "KNeighborsClassifier               0.63               0.63     0.63      0.62   \n",
              "Perceptron                         0.62               0.62     0.62      0.57   \n",
              "ExtraTreesClassifier               0.62               0.62     0.62      0.62   \n",
              "ExtraTreeClassifier                0.62               0.62     0.62      0.62   \n",
              "SVC                                0.62               0.62     0.62      0.56   \n",
              "CalibratedClassifierCV             0.61               0.61     0.61      0.54   \n",
              "LinearSVC                          0.58               0.58     0.58      0.49   \n",
              "PassiveAggressiveClassifier        0.57               0.58     0.58      0.48   \n",
              "SGDClassifier                      0.55               0.55     0.55      0.44   \n",
              "QuadraticDiscriminantAnalysis      0.54               0.54     0.54      0.42   \n",
              "GaussianNB                         0.54               0.54     0.54      0.42   \n",
              "BernoulliNB                        0.53               0.54     0.54      0.41   \n",
              "NearestCentroid                    0.53               0.54     0.54      0.41   \n",
              "LinearDiscriminantAnalysis         0.53               0.54     0.54      0.41   \n",
              "RidgeClassifier                    0.53               0.54     0.54      0.41   \n",
              "RidgeClassifierCV                  0.53               0.54     0.54      0.41   \n",
              "CategoricalNB                      0.53               0.53     0.53      0.40   \n",
              "DummyClassifier                    0.50               0.50     0.50      0.33   \n",
              "NuSVC                              0.39               0.38     0.38      0.29   \n",
              "\n",
              "                               Time Taken  \n",
              "Model                                      \n",
              "XGBClassifier                        8.14  \n",
              "LGBMClassifier                       0.49  \n",
              "AdaBoostClassifier                   3.55  \n",
              "DecisionTreeClassifier               0.47  \n",
              "RandomForestClassifier              30.06  \n",
              "BaggingClassifier                    3.28  \n",
              "LogisticRegression                   0.14  \n",
              "KNeighborsClassifier                 1.92  \n",
              "Perceptron                           0.09  \n",
              "ExtraTreesClassifier                11.53  \n",
              "ExtraTreeClassifier                  0.16  \n",
              "SVC                                983.77  \n",
              "CalibratedClassifierCV               1.14  \n",
              "LinearSVC                            2.54  \n",
              "PassiveAggressiveClassifier          0.13  \n",
              "SGDClassifier                        0.14  \n",
              "QuadraticDiscriminantAnalysis        0.05  \n",
              "GaussianNB                           0.05  \n",
              "BernoulliNB                          0.06  \n",
              "NearestCentroid                      0.50  \n",
              "LinearDiscriminantAnalysis           0.09  \n",
              "RidgeClassifier                      0.07  \n",
              "RidgeClassifierCV                    0.07  \n",
              "CategoricalNB                        0.06  \n",
              "DummyClassifier                      0.04  \n",
              "NuSVC                             1625.17  "
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "#sns.histplot(data=anomaly_scores_nor, label='Normal', kde=False, ax=ax, color='#330C2F')\n",
        "sns.histplot(data=anomaly_DoS, label='Abnormal', kde=False, ax=ax, color='#CBF3D2')\n",
        "ax.axvline(0.01, ls='-.', label='Threshold')\n",
        "ax.legend(loc='best', fontsize=20)\n",
        "ax.set_xlim([0, 0.2])\n",
        "fig.tight_layout()\n",
        "plt.title('Histogramm độ lỗi tái tạo của tập huấn luyện FoT, DoS')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Variational AE test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, input_dim, latent_dim=13):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        self.encoder = keras.Sequential([\n",
        "            keras.layers.Dense(input_dim, activation='tanh'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(100, activation='tanh'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(52, activation='tanh'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(32, activation='tanh'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(latent_dim*2, activation='linear')\n",
        "        ], name='encoder')\n",
        "        \n",
        "        self.decoder = keras.Sequential([\n",
        "            keras.layers.Dense(32, activation='tanh'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(52, activation='tanh'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(100, activation='tanh'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(input_dim, activation='sigmoid'),\n",
        "        ], name='decoder')\n",
        "\n",
        "        \n",
        "    def encode(self, x):\n",
        "        mean_logvar = self.encoder(x)\n",
        "        mean, logvar = tf.split(mean_logvar, num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        eps = tf.random.normal(shape=mean.shape)\n",
        "        return eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "    \n",
        "    def reconstruct(self, x):\n",
        "        mean, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "        reconstructed = self.decode(z)\n",
        "        \n",
        "        return reconstructed\n",
        "    \n",
        "    def call(self, inputs,training = True):\n",
        "        if training:\n",
        "            mean, logvar = self.encode(inputs)\n",
        "            z = self.reparameterize(mean, logvar)\n",
        "            reconstructed = self.decode(z)\n",
        "            return {'decoder_output': reconstructed, 'mean': mean, 'logvar': logvar}\n",
        "        else:\n",
        "            mean, logvar = self.encode(inputs)\n",
        "            z = self.reparameterize(mean, logvar)\n",
        "            reconstructed = self.decode(z)\n",
        "            return reconstructed\n",
        "\n",
        "# Loss function\n",
        "def vae_loss(x, decoded, mean, logvar):\n",
        "    reconstruction_loss = keras.losses.mean_squared_error(x, decoded)\n",
        "    kl_loss = -0.5 * tf.reduce_sum(1 + logvar - tf.square(mean) - tf.exp(logvar), axis=-1)\n",
        "    return tf.reduce_mean(reconstruction_loss + kl_loss) , kl_loss, reconstruction_loss\n",
        "\n",
        "# Compile and train the VAE\n",
        "vae = VAE(input_dim=Train_nor['data'].shape[1])\n",
        "vae.compile(optimizer=keras.optimizers.Adam(), loss=vae_loss)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(Train_nor['data'])\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(512)\n",
        "\n",
        "def train_step(x):\n",
        "    with tf.GradientTape() as tape:\n",
        "        outputs = vae(x)\n",
        "        loss, kl_loss, res = vae_loss(x, outputs['decoder_output'], outputs['mean'], outputs['logvar'])\n",
        "        loss = tf.reduce_mean(loss)\n",
        "    #print(\"finished loss\")\n",
        "    # Tính toán gradients\n",
        "    grads = tape.gradient(loss, vae.trainable_weights)\n",
        "    #print(\"apply optimizer\")\n",
        "    # Update weights\n",
        "    optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
        "\n",
        "    return loss, tf.reduce_mean(kl_loss), tf.reduce_mean(res)\n",
        "\n",
        "epochs = 300\n",
        "for epoch in range(epochs):\n",
        "    for step, x_batch_train in enumerate(train_dataset):\n",
        "        #print(f'Step: {step}, Batch shape: {x_batch_train.shape}')\n",
        "        loss, kl_loss, res = train_step(x_batch_train)\n",
        "    print(f'Epoch: {epoch+1}, Loss: {loss.numpy()}, KL_Loss: {kl_loss.numpy()}, Res_loss: {res.numpy()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_anomaly_score(x, decoded, mean, logvar, beta):\n",
        "    reconstruction_error = keras.losses.mean_squared_error(x, decoded)\n",
        "    kl_divergence = -0.5 * tf.reduce_sum(1 + logvar - tf.square(mean) - tf.exp(logvar), axis=-1)\n",
        "    \n",
        "    anomaly_score = reconstruction_error + beta * kl_divergence\n",
        "    return anomaly_score"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
