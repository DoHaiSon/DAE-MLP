{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager().update('notebook', {'limit_output': 20})\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nor_path = \"./Dataset/Normal_mixed.csv\"\n",
    "col_names = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
    "                \"land\", \"wrong_fragment\", \"urgent\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "                \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "                \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "                \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "                \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "                \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"]\n",
    "Nor_df = pd.read_csv(Nor_path, header=None,names= col_names, nrows= 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Abnor_path = \"./Dataset/Abnormal.csv\"\n",
    "Abnor_df = pd.read_csv(Abnor_path, header=None,names= col_names, nrows= 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kdd_path = \"./Dataset/kdd99_extracted.csv\"\n",
    "kdd99_df = pd.read_csv(Kdd_path, header=None,names= col_names, nrows= 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd99_nor = kdd99_df[kdd99_df['label'] == 'Normal']\n",
    "kdd99_abnor = kdd99_df[kdd99_df['label'] != 'Normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.concat([Nor_df.iloc[:8000],Abnor_df.iloc[:8000]], ignore_index=True)\n",
    "Train_nor = Nor_df.iloc[:8000]\n",
    "#Train_abnor = pd.concat([Abnor_df.iloc[:8000], kdd99_abnor.iloc[:4000]], ignore_index=True)\n",
    "Train_abnor = Abnor_df.iloc[:8000]\n",
    "\n",
    "Test = pd.concat([Nor_df.iloc[-2000:], Abnor_df.iloc[-2000:]], ignore_index=True)\n",
    "Test_nor = Nor_df.iloc[-2000:]\n",
    "Test_abnor = Abnor_df.iloc[-2000:]\n",
    "\n",
    "# Test_kdd = pd.concat([kdd99_nor.iloc[:2000],kdd99_abnor.iloc[:2000]], ignore_index=True)\n",
    "# Test_nor_kdd = kdd99_nor.iloc[:2000]\n",
    "# Test_abnor_kdd = kdd99_abnor.iloc[:2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, is_fit=True):\n",
    "    # chuyển normal thành 1 và các lớp khác thành 0\n",
    "    label = df['label'].map(lambda x: 'Abnormal' if x != 'Normal' else x)\n",
    "\n",
    "    # loại bỏ cột dữ liệu không cần thiết\n",
    "    df.drop([\"land\", \"wrong_fragment\",  \"urgent\", \"rerror_rate\",  \"srv_rerror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"], axis=1)\n",
    "\n",
    "    # chia dữ liệu ra số, chữ để tiện xử lý\n",
    "    numerical_data = df.select_dtypes(exclude='object').values\n",
    "    categorical_data = df.select_dtypes(include='object').values\n",
    "\n",
    "    # chỉ fit với dữ liệu train\n",
    "    if is_fit:\n",
    "        encoder.fit(categorical_data)\n",
    "\n",
    "    # chuyển từ dữ liệu chữ sang onehot\n",
    "    categorical_data = encoder.transform(categorical_data).toarray()\n",
    "\n",
    "    # nối dữ liệu số và onehot lại\n",
    "    data = np.concatenate([numerical_data, categorical_data], axis=1)\n",
    "\n",
    "    # chỉ fit với dữ liệu train\n",
    "    if is_fit:\n",
    "        scaler.fit(data)\n",
    "\n",
    "    # dữ liệu chuẩn hóa về dạng [0, 1]\n",
    "    data = scaler.transform(data)\n",
    "\n",
    "    return dict(data=data, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xử lý dữ liệu\n",
    "train = preprocess(Train, True)\n",
    "test = preprocess(Test, False)\n",
    "#test_kdd = preprocess(Test_kdd, False)\n",
    "#test_v1 = preprocess(Test_v1, False)\n",
    "#test_v2 = preprocess(Test_v2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 51), (4000, 51))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['data'].shape, test['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chia dữ liệu\n",
    "Train_nor = train['data'][train['label'] == 'Normal']\n",
    "Train_abnor = train['data'][train['label'] == 'Abnormal']\n",
    "\n",
    "Test_nor = test['data'][test['label'] == 'Normal']\n",
    "Test_abnor = test['data'][test['label'] == 'Abnormal']\n",
    "\n",
    "# kdd_nor = test_kdd['data'][test_kdd['label'] == 'Normal']\n",
    "# kdd_abnor = test_kdd['data'][test_kdd['label'] == 'Abnormal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(keras.Model):\n",
    "  def __init__(self, input_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.encoder = keras.Sequential([\n",
    "      # keras.layers.Dense(128, activation='tanh'),\n",
    "      keras.layers.Dense(48, activation='tanh'),\n",
    "      keras.layers.Dense(32, activation='tanh'),\n",
    "      keras.layers.Dense(16, activation='tanh'),\n",
    "      keras.layers.Dense(8, activation='tanh')\n",
    "    ])\n",
    "    self.decoder = keras.Sequential([\n",
    "      keras.layers.Dense(16, activation='tanh'),\n",
    "      keras.layers.Dense(32, activation='tanh'),\n",
    "      keras.layers.Dense(48, activation='tanh'),\n",
    "      # keras.layers.Dense(128, activation='tanh'),\n",
    "      keras.layers.Dense(input_dim, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    code = self.encoder(x)\n",
    "    r = self.decoder(code)\n",
    "    return r\n",
    "\n",
    "  def get_reconstruction_error(self, x):\n",
    "    r = self.predict(x)\n",
    "    return keras.metrics.mean_squared_error(x, r)\n",
    "\n",
    "  def predict_class(self, x, threshold):\n",
    "    reconstruction_error = self.get_reconstruction_error(x)\n",
    "    return np.where(reconstruction_error <= threshold, 'Normal', 'Abnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(Train_nor.shape[1])\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "model.compile(optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "125/125 [==============================] - 2s 2ms/step - loss: 0.2144\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1380\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0799\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0615\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0557\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0532\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0519\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0510\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0492\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0462\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0429\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0400\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0378\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0362\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0348\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0335\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0322\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0308\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0292\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0276\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0258\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0240\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0221\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0201\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0183\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0131\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0123\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0116\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0111\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0106\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0101\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0094\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0090\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0087\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0084\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0080\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0077\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0074\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0071\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0068\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0066\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0064\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0062\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0060\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0058\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0056\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0055\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0053\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0051\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0047\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0044\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0034\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0033\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0033\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0032\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 83/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 84/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 85/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 86/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 87/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 88/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 89/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 90/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 91/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 92/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 93/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 94/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 95/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 96/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 97/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 98/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 99/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 100/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 101/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 102/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 103/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 104/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 105/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 106/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 107/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 108/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 109/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 110/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 111/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 112/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 113/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 114/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 115/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 116/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 117/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 118/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 119/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 120/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 121/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 122/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 123/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 124/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 125/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 126/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 127/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 128/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 129/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 130/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 131/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 132/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 133/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 134/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 135/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 136/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 137/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 138/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 139/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 140/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 141/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 142/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 143/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 144/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 145/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 146/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 147/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 148/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 149/200\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 150/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 151/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 152/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 153/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.9950e-04\n",
      "Epoch 154/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.9435e-04\n",
      "Epoch 155/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.8572e-04\n",
      "Epoch 156/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.7995e-04\n",
      "Epoch 157/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.7401e-04\n",
      "Epoch 158/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.6917e-04\n",
      "Epoch 159/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.6279e-04\n",
      "Epoch 160/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.5790e-04\n",
      "Epoch 161/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.5274e-04\n",
      "Epoch 162/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.4476e-04\n",
      "Epoch 163/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.3939e-04\n",
      "Epoch 164/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.3341e-04\n",
      "Epoch 165/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.2848e-04\n",
      "Epoch 166/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.2365e-04\n",
      "Epoch 167/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.2035e-04\n",
      "Epoch 168/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.1780e-04\n",
      "Epoch 169/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.0879e-04\n",
      "Epoch 170/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.0274e-04\n",
      "Epoch 171/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.9767e-04\n",
      "Epoch 172/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.9331e-04\n",
      "Epoch 173/200\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.8923e-04\n",
      "Epoch 174/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.8398e-04\n",
      "Epoch 175/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.8281e-04\n",
      "Epoch 176/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.7647e-04\n",
      "Epoch 177/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.7136e-04\n",
      "Epoch 178/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.6809e-04\n",
      "Epoch 179/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.6534e-04\n",
      "Epoch 180/200\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.5965e-04\n",
      "Epoch 181/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.5567e-04\n",
      "Epoch 182/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.5218e-04\n",
      "Epoch 183/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.4666e-04\n",
      "Epoch 184/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.4428e-04\n",
      "Epoch 185/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.3850e-04\n",
      "Epoch 186/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.3652e-04\n",
      "Epoch 187/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.3384e-04\n",
      "Epoch 188/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.2785e-04\n",
      "Epoch 189/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.2505e-04\n",
      "Epoch 190/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.2095e-04\n",
      "Epoch 191/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.1827e-04\n",
      "Epoch 192/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.1677e-04\n",
      "Epoch 193/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.1380e-04\n",
      "Epoch 194/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0672e-04\n",
      "Epoch 195/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0339e-04\n",
      "Epoch 196/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0154e-04\n",
      "Epoch 197/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9779e-04\n",
      "Epoch 198/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9584e-04\n",
      "Epoch 199/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9282e-04\n",
      "Epoch 200/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.8731e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x256893d0490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Train_nor, Train_nor, batch_size=64, epochs=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step\n",
      "250/250 [==============================] - 0s 1ms/step\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "train_normal_re = model.get_reconstruction_error(Train_nor)\n",
    "train_abnormal_re = model.get_reconstruction_error(Train_abnor)\n",
    "\n",
    "test_normal_re = model.get_reconstruction_error(Test_nor)\n",
    "test_abnormal_re = model.get_reconstruction_error(Test_abnor)\n",
    "\n",
    "# kdd_nor_re = model.get_reconstruction_error(kdd_nor)\n",
    "# kdd_abnor_re = model.get_reconstruction_error(kdd_abnor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngưỡng vừa tìm được từ tập train: 0.015223712660372257\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "threshold = np.concatenate([train_normal_re, train_abnormal_re]).mean() * alpha\n",
    "print('Ngưỡng vừa tìm được từ tập train:', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/500 [==========>...................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 1ms/step\n",
      "Độ chính xác tập huấn luyện: 0.9990625\n",
      "125/125 [==============================] - 0s 1ms/step\n",
      "Độ chính xác tập test: 0.99775\n"
     ]
    }
   ],
   "source": [
    "label_predict = model.predict_class(train['data'], threshold)\n",
    "print('Độ chính xác tập huấn luyện', end=': ')\n",
    "print(accuracy_score(train['label'], label_predict))\n",
    "\n",
    "label_predict = model.predict_class(test['data'], threshold)\n",
    "print('Độ chính xác tập test', end=': ')\n",
    "print(accuracy_score(test['label'], label_predict))\n",
    "\n",
    "# label_predict = model.predict_class(test_kdd['data'], threshold)\n",
    "# print('Độ chính xác tập kdd', end=': ')\n",
    "# print(accuracy_score(test_kdd['label'], label_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.histplot(data=test_normal_re, label='Normal', kde=False, ax=ax, color='#330C2F')\n",
    "sns.histplot(data=test_abnormal_re, label='Abnormal', kde=False, ax=ax, color='#CBF3D2')\n",
    "ax.axvline(threshold, ls='-.', label='Threshold')\n",
    "ax.legend(loc='best', fontsize=20)\n",
    "ax.set_xlim([0, 0.2])\n",
    "fig.tight_layout()\n",
    "plt.title('Histogramm độ lỗi tái tạo của tập huấn luyện')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning A2C threshold adaption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent tự động tăng hoặc giảm hoặc giữ nguyên => cần được train\n",
    "#Train Agent dựa trên hiệu suất phân loại normal và abnormal\n",
    "#Reward, Action, Agent\n",
    "#Tạo environment: update_state, reset, act, get_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete\n",
    "import random\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLenv(Env):\n",
    "    def __init__(self, data, true_label, init_threshold):\n",
    "        super(RLenv,self).__init__()\n",
    "\n",
    "        self.normal_data = data\n",
    "        #self.abnormal_data = abnormal\n",
    "        self.true_label = true_label\n",
    "        self.threshold = init_threshold\n",
    "        self.action_space = Discrete(3) #3 actions: increase, decrease, keep\n",
    "        self.observation_space = Box(low=0 , high=1, shape= (len(data[0]), ) )\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        self.random_index = np.random.randint(len(self.normal_data))\n",
    "\n",
    "    def rand(self):\n",
    "        return np.random.randint(len(self.normal_data))\n",
    "    \n",
    "    #self.random_index = np.random.randint(len(self.normal_data))\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        #random_index = np.random.randint(len(self.normal_data))\n",
    "        init_state = self.normal_data[self.random_index]\n",
    "        # x_tensor = tf.convert_to_tensor(init_state, dtype=tf.float32)\n",
    "        return init_state\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "\n",
    "        if action == 0:\n",
    "            self.threshold += 0.01\n",
    "        elif action == 2:\n",
    "            self.threshold -= 0.01\n",
    "        else: self.threshold = self.threshold\n",
    "\n",
    "        state = self.normal_data[self.current_step]\n",
    "        state = np.expand_dims(state, axis=0) \n",
    "        reward = self.get_reward(state)\n",
    "\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= 200:\n",
    "            self.done = True\n",
    "    \n",
    "        return state, reward, self.done, {}\n",
    "    \n",
    "    def get_reward(self, state): \n",
    "        reconstruction_err = model.get_reconstruction_error(state)\n",
    "        predict_class = np.where(reconstruction_err <= self.threshold, 'Normal', 'Abnormal')\n",
    "        if predict_class == self.true_label[self.random_index]:\n",
    "            reward = 1.0\n",
    "        elif predict_class != self.true_label[self.random_index]:\n",
    "            reward = 0.0\n",
    "\n",
    "        return reward\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        if mode == 'human':\n",
    "            print(\"Current Threshold:\", self.threshold)\n",
    "            print(\"Current State:\", self.normal_data[self.current_step])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.dqn = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.Dense(27, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(keras.layers.Dense(27, activation='relu'))\n",
    "        model.add(keras.layers.Dense(9, activation='relu'))\n",
    "        model.add(keras.layers.Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=keras.optimizers.Adam())\n",
    "        return model        \n",
    "        \n",
    "\n",
    "    def predict(self, state):\n",
    "        return self.dqn.predict(state)\n",
    "\n",
    "    def fit(self, state, target):\n",
    "        return self.dqn.fit(state, target, epochs= 1, verbose= 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # Hệ số giảm sau mỗi bước\n",
    "        self.epsilon = 1.0  # Khả năng thực hiện hành động ngẫu nhiên\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.dqn = DQN(state_size, action_size)\n",
    "\n",
    "    def remember(self, action, reward, state, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_val = self.dqn.predict(state)\n",
    "        return np.argmax(act_val[0])\n",
    "        \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.dqn.predict(next_state)[0])\n",
    "            target_f = self.dqn.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.dqn.fit(state, target_f)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Episode: 1/200, Total Steps: 23, Total Reward: 2.00, Threshold: 0.0352\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Episode: 2/200, Total Steps: 23, Total Reward: 0.00, Threshold: 0.0852\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[39mprint\u001b[39m(done)\n\u001b[0;32m     29\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(agent\u001b[39m.\u001b[39mmemory) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m batch_size:\n\u001b[1;32m---> 30\u001b[0m             agent\u001b[39m.\u001b[39;49mreplay(batch_size)\n\u001b[0;32m     32\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpisode: \u001b[39m\u001b[39m{\u001b[39;00mepisode\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepisodes\u001b[39m}\u001b[39;00m\u001b[39m, Total Steps: \u001b[39m\u001b[39m{\u001b[39;00mstep\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Total Reward: \u001b[39m\u001b[39m{\u001b[39;00mtotal_reward\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Threshold: \u001b[39m\u001b[39m{\u001b[39;00menv\u001b[39m.\u001b[39mthreshold\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[39m# Lưu mạng nơ-ron sau khi huấn luyện (tuỳ chọn)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m, in \u001b[0;36mAgent.replay\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m     27\u001b[0m     target \u001b[39m=\u001b[39m reward \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mamax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdqn\u001b[39m.\u001b[39mpredict(next_state)[\u001b[39m0\u001b[39m])\n\u001b[1;32m---> 28\u001b[0m target_f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdqn\u001b[39m.\u001b[39;49mpredict(state)\n\u001b[0;32m     29\u001b[0m target_f[\u001b[39m0\u001b[39m][action] \u001b[39m=\u001b[39m target\n\u001b[0;32m     30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdqn\u001b[39m.\u001b[39mfit(state, target_f)\n",
      "Cell \u001b[1;32mIn[22], line 18\u001b[0m, in \u001b[0;36mDQN.predict\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdqn\u001b[39m.\u001b[39;49mpredict(state)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2521\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2512\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m   2513\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2514\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2515\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2518\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2519\u001b[0m         )\n\u001b[1;32m-> 2521\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[0;32m   2522\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m   2523\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2524\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[0;32m   2525\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m   2526\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   2527\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2528\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2529\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2530\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2531\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[0;32m   2532\u001b[0m )\n\u001b[0;32m   2534\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1678\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1676\u001b[0m         \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1677\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1678\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1285\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[0;32m   1282\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[0;32m   1284\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[0;32m   1286\u001b[0m     x,\n\u001b[0;32m   1287\u001b[0m     y,\n\u001b[0;32m   1288\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1289\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1290\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[0;32m   1291\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1292\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1293\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1294\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1295\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1296\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[0;32m   1297\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1298\u001b[0m     pss_evaluation_shards\u001b[39m=\u001b[39;49mpss_evaluation_shards,\n\u001b[0;32m   1299\u001b[0m )\n\u001b[0;32m   1301\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[0;32m   1303\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:353\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         flat_dataset \u001b[39m=\u001b[39m flat_dataset\u001b[39m.\u001b[39mshuffle(\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    351\u001b[0m     \u001b[39mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 353\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mflat_map(slice_batch_indices)\n\u001b[0;32m    355\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    357\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2323\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   2319\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> flat_map_op ->\u001b[39;00m\n\u001b[0;32m   2320\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2321\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2322\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m flat_map_op\n\u001b[1;32m-> 2323\u001b[0m \u001b[39mreturn\u001b[39;00m flat_map_op\u001b[39m.\u001b[39;49m_flat_map(\u001b[39mself\u001b[39;49m, map_func, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\flat_map_op.py:24\u001b[0m, in \u001b[0;36m_flat_map\u001b[1;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_flat_map\u001b[39m(input_dataset, map_func, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m   \u001b[39mreturn\u001b[39;00m _FlatMapDataset(input_dataset, map_func, name)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\flat_map_op.py:33\u001b[0m, in \u001b[0;36m_FlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, input_dataset, map_func, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[1;32m---> 33\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m     34\u001b[0m       map_func, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(), dataset\u001b[39m=\u001b[39;49minput_dataset)\n\u001b[0;32m     35\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure, dataset_ops\u001b[39m.\u001b[39mDatasetSpec):\n\u001b[0;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     37\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdataset_ops\u001b[39m.\u001b[39mget_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure)\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:272\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    269\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    270\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 272\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    273\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1189\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1188\u001b[0m   \u001b[39m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1189\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1190\u001b[0m   concrete\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1169\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1167\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1168\u001b[0m     initializers \u001b[39m=\u001b[39m []\n\u001b[1;32m-> 1169\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwargs, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[0;32m   1170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[0;32m   1173\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m   \u001b[39m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 694\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn    \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    695\u001b[0m     \u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(\n\u001b[0;32m    696\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[0;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[0;32m    699\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:176\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m--> 176\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    169\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:398\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[0;32m    396\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[1;32m--> 398\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[0;32m    399\u001b[0m     args, kwargs, func_graph)\n\u001b[0;32m    401\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:305\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[0;32m    304\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 305\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    306\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m    307\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m    308\u001b[0m         args,\n\u001b[0;32m    309\u001b[0m         kwargs,\n\u001b[0;32m    310\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    311\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[0;32m    312\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m    313\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[0;32m    314\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m    316\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m    317\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    322\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1055\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1052\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m   1054\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1055\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[0;32m   1057\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1059\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:597\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    594\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    595\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    596\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 597\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    598\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:238\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    239\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    240\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:168\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    167\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 168\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m    169\u001b[0m ret \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:342\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__.<locals>.slice_batch_indices\u001b[1;34m(indices)\u001b[0m\n\u001b[0;32m    339\u001b[0m flat_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices(first_k_indices)\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_partial_batch_size:\n\u001b[0;32m    341\u001b[0m     index_remainder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensors(\n\u001b[1;32m--> 342\u001b[0m         tf\u001b[39m.\u001b[39;49mslice(\n\u001b[0;32m    343\u001b[0m             indices, [num_in_full_batch], [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_batch_size]\n\u001b[0;32m    344\u001b[0m         )\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    346\u001b[0m     flat_dataset \u001b[39m=\u001b[39m flat_dataset\u001b[39m.\u001b[39mconcatenate(index_remainder)\n\u001b[0;32m    348\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    349\u001b[0m     \u001b[39m# 1024 is a magic constant that has not been properly evaluated\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1185\u001b[0m, in \u001b[0;36mslice\u001b[1;34m(input_, begin, size, name)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mslice\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1134\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mslice\u001b[39m(input_, begin, size, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1136\u001b[0m   \u001b[39m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Extracts a slice from a tensor.\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \n\u001b[0;32m   1139\u001b[0m \u001b[39m  See also `tf.strided_slice`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[39m    A `Tensor` the same type as `input_`.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1185\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_array_ops\u001b[39m.\u001b[39;49m_slice(input_, begin, size, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:11966\u001b[0m, in \u001b[0;36m_slice\u001b[1;34m(input, begin, size, name)\u001b[0m\n\u001b[0;32m  11964\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m  11965\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m> 11966\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m  11967\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mSlice\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, begin\u001b[39m=\u001b[39;49mbegin, size\u001b[39m=\u001b[39;49msize, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m  11968\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m  11969\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:795\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    790\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    791\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    792\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    793\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    794\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    796\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    797\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    799\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    800\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    803\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    668\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    669\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 670\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3381\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3378\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3379\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3380\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3381\u001b[0m   ret \u001b[39m=\u001b[39m Operation\u001b[39m.\u001b[39;49mfrom_node_def(\n\u001b[0;32m   3382\u001b[0m       node_def,\n\u001b[0;32m   3383\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3384\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3385\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3386\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3387\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3388\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3389\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def,\n\u001b[0;32m   3390\u001b[0m   )\n\u001b[0;32m   3391\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3392\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1889\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1886\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   1888\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 1889\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   1890\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Operation(c_op, GraphTensor)\n\u001b[0;32m   1891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init(g)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1748\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1744\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   1745\u001b[0m                                          serialized)\n\u001b[0;32m   1747\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1748\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   1749\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1750\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init_threshold = threshold\n",
    "env = RLenv(train['data'],train['label'], init_threshold)\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = 3\n",
    "agent = Agent(state_size, action_size)\n",
    "\n",
    "# Các tham số huấn luyện\n",
    "episodes = 200\n",
    "batch_size = 64\n",
    "max_steps_per_episode = 64\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        # print(step)\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        total_reward += reward\n",
    "        agent.remember(action, reward, state, next_state, done)\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        print(done)\n",
    "        if len(agent.memory) >= batch_size:\n",
    "            agent.replay(batch_size)\n",
    "    \n",
    "    print(f\"Episode: {episode + 1}/{episodes}, Total Steps: {step + 1}, Total Reward: {total_reward:.2f}, Threshold: {env.threshold:.4f}\")\n",
    "\n",
    "# Lưu mạng nơ-ron sau khi huấn luyện (tuỳ chọn)\n",
    "agent.dqn.dqn.save('trained_dqn_model.h5')\n",
    "print(\"Model Saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
