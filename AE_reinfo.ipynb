{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager().update('notebook', {'limit_output': 20})\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nor_path = \"./Dataset/Normal_mixed.csv\"\n",
    "col_names = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
    "                \"land\", \"wrong_fragment\", \"urgent\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "                \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "                \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "                \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "                \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "                \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"]\n",
    "Nor_df = pd.read_csv(Nor_path, header=None,names= col_names, nrows= 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Abnor_path = \"./Dataset/Abnormal.csv\"\n",
    "Abnor_df = pd.read_csv(Abnor_path, header=None,names= col_names, nrows= 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kdd_path = \"./Dataset/kdd99_extracted.csv\"\n",
    "kdd99_df = pd.read_csv(Kdd_path, header=None,names= col_names, nrows= 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd99_nor = kdd99_df[kdd99_df['label'] == 'Normal']\n",
    "kdd99_abnor = kdd99_df[kdd99_df['label'] != 'Normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.concat([Nor_df.iloc[:8000],Abnor_df.iloc[:8000]], ignore_index=True)\n",
    "Train_nor = Nor_df.iloc[:8000]\n",
    "#Train_abnor = pd.concat([Abnor_df.iloc[:8000], kdd99_abnor.iloc[:4000]], ignore_index=True)\n",
    "Train_abnor = Abnor_df.iloc[:8000]\n",
    "\n",
    "Test = pd.concat([Nor_df.iloc[-2000:], Abnor_df.iloc[-2000:]], ignore_index=True)\n",
    "Test_nor = Nor_df.iloc[-2000:]\n",
    "Test_abnor = Abnor_df.iloc[-2000:]\n",
    "\n",
    "# Test_kdd = pd.concat([kdd99_nor.iloc[:2000],kdd99_abnor.iloc[:2000]], ignore_index=True)\n",
    "# Test_nor_kdd = kdd99_nor.iloc[:2000]\n",
    "# Test_abnor_kdd = kdd99_abnor.iloc[:2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, is_fit=True):\n",
    "    # chuyển normal thành 1 và các lớp khác thành 0\n",
    "    label = df['label'].map(lambda x: 'Abnormal' if x != 'Normal' else x)\n",
    "\n",
    "    # loại bỏ cột dữ liệu không cần thiết\n",
    "    df.drop([\"land\", \"wrong_fragment\",  \"urgent\", \"rerror_rate\",  \"srv_rerror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"], axis=1)\n",
    "\n",
    "    # chia dữ liệu ra số, chữ để tiện xử lý\n",
    "    numerical_data = df.select_dtypes(exclude='object').values\n",
    "    categorical_data = df.select_dtypes(include='object').values\n",
    "\n",
    "    # chỉ fit với dữ liệu train\n",
    "    if is_fit:\n",
    "        encoder.fit(categorical_data)\n",
    "\n",
    "    # chuyển từ dữ liệu chữ sang onehot\n",
    "    categorical_data = encoder.transform(categorical_data).toarray()\n",
    "\n",
    "    # nối dữ liệu số và onehot lại\n",
    "    data = np.concatenate([numerical_data, categorical_data], axis=1)\n",
    "\n",
    "    # chỉ fit với dữ liệu train\n",
    "    if is_fit:\n",
    "        scaler.fit(data)\n",
    "\n",
    "    # dữ liệu chuẩn hóa về dạng [0, 1]\n",
    "    data = scaler.transform(data)\n",
    "\n",
    "    return dict(data=data, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xử lý dữ liệu\n",
    "train = preprocess(Train, True)\n",
    "test = preprocess(Test, False)\n",
    "#test_kdd = preprocess(Test_kdd, False)\n",
    "#test_v1 = preprocess(Test_v1, False)\n",
    "#test_v2 = preprocess(Test_v2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 51), (4000, 51))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['data'].shape, test['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chia dữ liệu\n",
    "Train_nor = train['data'][train['label'] == 'Normal']\n",
    "Train_abnor = train['data'][train['label'] == 'Abnormal']\n",
    "\n",
    "Test_nor = test['data'][test['label'] == 'Normal']\n",
    "Test_abnor = test['data'][test['label'] == 'Abnormal']\n",
    "\n",
    "# kdd_nor = test_kdd['data'][test_kdd['label'] == 'Normal']\n",
    "# kdd_abnor = test_kdd['data'][test_kdd['label'] == 'Abnormal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(keras.Model):\n",
    "  def __init__(self, input_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.encoder = keras.Sequential([\n",
    "      # keras.layers.Dense(128, activation='tanh'),\n",
    "      keras.layers.Dense(48, activation='tanh'),\n",
    "      keras.layers.Dense(32, activation='tanh'),\n",
    "      keras.layers.Dense(16, activation='tanh'),\n",
    "      keras.layers.Dense(8, activation='tanh')\n",
    "    ])\n",
    "    self.decoder = keras.Sequential([\n",
    "      keras.layers.Dense(16, activation='tanh'),\n",
    "      keras.layers.Dense(32, activation='tanh'),\n",
    "      keras.layers.Dense(48, activation='tanh'),\n",
    "      # keras.layers.Dense(128, activation='tanh'),\n",
    "      keras.layers.Dense(input_dim, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    code = self.encoder(x)\n",
    "    r = self.decoder(code)\n",
    "    return r\n",
    "\n",
    "  def get_reconstruction_error(self, x):\n",
    "    r = self.predict(x)\n",
    "    return keras.metrics.mean_squared_error(x, r)\n",
    "\n",
    "  def predict_class(self, x, threshold):\n",
    "    reconstruction_error = self.get_reconstruction_error(x)\n",
    "    return np.where(reconstruction_error <= threshold, 'Normal', 'Abnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(Train_nor.shape[1])\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "model.compile(optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "125/125 [==============================] - 2s 2ms/step - loss: 0.2000\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1215\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0774\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0615\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0558\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0533\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0519\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0507\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0483\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0452\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0414\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0384\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0362\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0346\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0332\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0320\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0308\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0297\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0286\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0274\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0261\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0248\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0236\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0224\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0201\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0188\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0124\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0115\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0106\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0093\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0088\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0083\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0079\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0076\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0072\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0069\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0067\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0064\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0062\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0060\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0058\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0056\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0055\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0053\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0051\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0047\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0034\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0033\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0032\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 83/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 84/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 85/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 86/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 87/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 88/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 89/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 90/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 91/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 92/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 93/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 94/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 95/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 96/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 97/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 98/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 99/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 100/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 101/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 102/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 103/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 104/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 105/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 106/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 107/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 108/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 109/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 110/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 111/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 112/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 113/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 114/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 115/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 116/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 117/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 118/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 119/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 120/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 121/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 122/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 123/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 124/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 125/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 126/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 127/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 128/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 129/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 130/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 131/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 132/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 133/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 134/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 135/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 136/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 137/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 138/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 139/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 140/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 141/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 142/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 143/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 144/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 145/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 146/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 147/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 148/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 149/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 150/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 151/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 152/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 153/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 154/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 155/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 156/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 157/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 158/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 159/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 160/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 161/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 162/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 163/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 164/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 165/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 166/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 167/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 168/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 169/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 170/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 171/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 172/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 173/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 174/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 175/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 176/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 177/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 178/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 179/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 180/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 181/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 182/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 183/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 184/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 185/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 186/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 187/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.9876e-04\n",
      "Epoch 188/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.9006e-04\n",
      "Epoch 189/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.8197e-04\n",
      "Epoch 190/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.7460e-04\n",
      "Epoch 191/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.6505e-04\n",
      "Epoch 192/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.5851e-04\n",
      "Epoch 193/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.5036e-04\n",
      "Epoch 194/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.4360e-04\n",
      "Epoch 195/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.3653e-04\n",
      "Epoch 196/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.3023e-04\n",
      "Epoch 197/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.2431e-04\n",
      "Epoch 198/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.1666e-04\n",
      "Epoch 199/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.1035e-04\n",
      "Epoch 200/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.0347e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ddac7c1d10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Train_nor, Train_nor, batch_size=64, epochs=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 1ms/step\n",
      "250/250 [==============================] - 0s 1ms/step\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "train_normal_re = model.get_reconstruction_error(Train_nor)\n",
    "train_abnormal_re = model.get_reconstruction_error(Train_abnor)\n",
    "\n",
    "test_normal_re = model.get_reconstruction_error(Test_nor)\n",
    "test_abnormal_re = model.get_reconstruction_error(Test_abnor)\n",
    "\n",
    "# kdd_nor_re = model.get_reconstruction_error(kdd_nor)\n",
    "# kdd_abnor_re = model.get_reconstruction_error(kdd_abnor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngưỡng vừa tìm được từ tập train: 0.028154021129012108\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "threshold = np.concatenate([train_normal_re, train_abnormal_re]).mean() * alpha\n",
    "print('Ngưỡng vừa tìm được từ tập train:', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/500 [==========>...................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 1ms/step\n",
      "Độ chính xác tập huấn luyện: 0.9990625\n",
      "125/125 [==============================] - 0s 1ms/step\n",
      "Độ chính xác tập test: 0.99775\n"
     ]
    }
   ],
   "source": [
    "label_predict = model.predict_class(train['data'], threshold)\n",
    "print('Độ chính xác tập huấn luyện', end=': ')\n",
    "print(accuracy_score(train['label'], label_predict))\n",
    "\n",
    "label_predict = model.predict_class(test['data'], threshold)\n",
    "print('Độ chính xác tập test', end=': ')\n",
    "print(accuracy_score(test['label'], label_predict))\n",
    "\n",
    "# label_predict = model.predict_class(test_kdd['data'], threshold)\n",
    "# print('Độ chính xác tập kdd', end=': ')\n",
    "# print(accuracy_score(test_kdd['label'], label_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.histplot(data=test_normal_re, label='Normal', kde=False, ax=ax, color='#330C2F')\n",
    "sns.histplot(data=test_abnormal_re, label='Abnormal', kde=False, ax=ax, color='#CBF3D2')\n",
    "ax.axvline(threshold, ls='-.', label='Threshold')\n",
    "ax.legend(loc='best', fontsize=20)\n",
    "ax.set_xlim([0, 0.2])\n",
    "fig.tight_layout()\n",
    "plt.title('Histogramm độ lỗi tái tạo của tập huấn luyện')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning A2C threshold adaption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_clustering_based_reward(reconstruction_error):\n",
    "    kmeans = KMeans(n_clusters=2,n_init=10, random_state=0)\n",
    "    reconstruction_error_np = reconstruction_error.numpy()\n",
    "    kmeans.fit(reconstruction_error_np.reshape(-1,1))\n",
    "    labels = kmeans.labels_\n",
    "    reward = np.mean(reconstruction_error[labels == 0]) - np.mean(reconstruction_error[labels == 1])\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 1ms/step\n",
      "125/125 [==============================] - 0s 1ms/step\n",
      "Initial Threshold: 0.11261608451604843\n",
      "0.62475\n"
     ]
    }
   ],
   "source": [
    "test_data = test['data']\n",
    "reconstruction_error = model.get_reconstruction_error(test_data)\n",
    "\n",
    "# Đặt threshold sai\n",
    "wrong_threshold = 4 * threshold\n",
    "\n",
    "initial_prediction = model.predict_class(test_data, wrong_threshold)\n",
    "print(\"Initial Threshold:\", wrong_threshold)\n",
    "print(accuracy_score(test['label'], initial_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mô hình A2C\n",
    "optimizer_actor = keras.optimizers.Adam(learning_rate=0.001)\n",
    "optimizer_critic = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "actor = keras.Sequential([\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "critic = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(1,))  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Critic Loss: [0.14890558 0.14904824 0.14981622 ... 0.27622706 0.21151412 0.31139657] Optimized Threshold: 0.055645997488035226\n",
      "Epoch: 1 Critic Loss: [0.1481975  0.1483397  0.14910528 ... 0.2751539  0.21061976 0.3102303 ] Optimized Threshold: 0.055394666889174715\n",
      "Epoch: 2 Critic Loss: [0.14749189 0.14763364 0.14839685 ... 0.27408403 0.2097283  0.30906752] Optimized Threshold: 0.05514368533728331\n",
      "Epoch: 3 Critic Loss: [0.14678875 0.14693007 0.14769088 ... 0.27301738 0.20883967 0.30790812] Optimized Threshold: 0.054893069613465295\n",
      "Epoch: 4 Critic Loss: [0.14608805 0.14622892 0.14698738 ... 0.2719539  0.20795391 0.3067522 ] Optimized Threshold: 0.05464283985504581\n",
      "Epoch: 5 Critic Loss: [0.14538983 0.14553027 0.14628634 ... 0.2708937  0.20707104 0.30559963] Optimized Threshold: 0.054392996062024856\n",
      "Epoch: 6 Critic Loss: [0.14469405 0.14483404 0.14558776 ... 0.26983672 0.20619096 0.30445057] Optimized Threshold: 0.054143568440390144\n",
      "Epoch: 7 Critic Loss: [0.14400071 0.14414027 0.14489162 ... 0.26878294 0.20531376 0.30330482] Optimized Threshold: 0.05389456034636253\n",
      "Epoch: 8 Critic Loss: [0.14330982 0.14344896 0.14419794 ... 0.26773238 0.2044394  0.3021626 ] Optimized Threshold: 0.05364599527348801\n",
      "Epoch: 9 Critic Loss: [0.14262138 0.14276005 0.14350669 ... 0.26668507 0.20356783 0.30102366] Optimized Threshold: 0.0533978799342083\n",
      "Epoch: 10 Critic Loss: [0.14193535 0.14207362 0.1428179  ... 0.2656409  0.20269914 0.29988813] Optimized Threshold: 0.0531502378220694\n",
      "Epoch: 11 Critic Loss: [0.14125177 0.14138958 0.14213154 ... 0.2645999  0.20183326 0.29875603] Optimized Threshold: 0.05290306893707131\n",
      "Epoch: 12 Critic Loss: [0.1405706  0.14070798 0.14144757 ... 0.26356214 0.20097019 0.29762727] Optimized Threshold: 0.05265639677276002\n",
      "Epoch: 13 Critic Loss: [0.13989183 0.14002879 0.14076607 ... 0.26252753 0.20010994 0.29650193] Optimized Threshold: 0.0524102313977981\n",
      "Epoch: 14 Critic Loss: [0.1392155  0.13935201 0.14008698 ... 0.26149616 0.19925246 0.29537988] Optimized Threshold: 0.05216458623706899\n",
      "Epoch: 15 Critic Loss: [0.13854155 0.13867764 0.13941027 ... 0.2604679  0.1983978  0.29426125] Optimized Threshold: 0.05191948142789782\n",
      "Epoch: 16 Critic Loss: [0.13787001 0.13800566 0.13873598 ... 0.25944284 0.19754595 0.29314592] Optimized Threshold: 0.05167492032650545\n",
      "Epoch: 17 Critic Loss: [0.13720088 0.13733609 0.1380641  ... 0.25842088 0.19669686 0.292034  ] Optimized Threshold: 0.0514309163577753\n",
      "Epoch: 18 Critic Loss: [0.13653411 0.1366689  0.1373946  ... 0.25740212 0.19585055 0.29092532] Optimized Threshold: 0.051187489659032526\n",
      "Epoch: 19 Critic Loss: [0.13586974 0.1360041  0.13672751 ... 0.25638643 0.19500706 0.28982008] Optimized Threshold: 0.05094464358649797\n",
      "Epoch: 20 Critic Loss: [0.13520774 0.13534169 0.1360628  ... 0.25537398 0.19416629 0.2887181 ] Optimized Threshold: 0.050702398277496785\n",
      "Epoch: 21 Critic Loss: [0.13454816 0.13468166 0.13540046 ... 0.2543646  0.1933283  0.28761947] Optimized Threshold: 0.05046076380069153\n",
      "Epoch: 22 Critic Loss: [0.13389091 0.13402398 0.13474053 ... 0.25335836 0.19249308 0.2865241 ] Optimized Threshold: 0.05021974351230307\n",
      "Epoch: 23 Critic Loss: [0.13323602 0.13336867 0.13408294 ... 0.2523552  0.19166061 0.28543213] Optimized Threshold: 0.049979357549656545\n",
      "Epoch: 24 Critic Loss: [0.13258351 0.13271576 0.13342771 ... 0.2513552  0.19083087 0.2843434 ] Optimized Threshold: 0.049739622693856234\n",
      "Epoch: 25 Critic Loss: [0.13193335 0.13206516 0.13277487 ... 0.25035828 0.1900039  0.28325793] Optimized Threshold: 0.04950053894490214\n",
      "Epoch: 26 Critic Loss: [0.1312855  0.13141693 0.13212436 ... 0.24936448 0.18917966 0.28217584] Optimized Threshold: 0.04926211972767769\n",
      "Epoch: 27 Critic Loss: [0.13064004 0.13077101 0.13147621 ... 0.24837378 0.18835813 0.28109694] Optimized Threshold: 0.04902437846706631\n",
      "Epoch: 28 Critic Loss: [0.1299969  0.13012746 0.1308304  ... 0.24738617 0.18753935 0.28002137] Optimized Threshold: 0.04878732523173057\n",
      "Epoch: 29 Critic Loss: [0.1293561  0.12948625 0.13018695 ... 0.24640162 0.18672326 0.27894905] Optimized Threshold: 0.048550970090333045\n",
      "Epoch: 30 Critic Loss: [0.12871763 0.12884736 0.1295458  ... 0.24542017 0.18590993 0.27787998] Optimized Threshold: 0.0483153231115363\n",
      "Epoch: 31 Critic Loss: [0.12808149 0.12821078 0.128907   ... 0.24444176 0.18509926 0.27681425] Optimized Threshold: 0.048080387651561196\n",
      "Epoch: 32 Critic Loss: [0.12744763 0.12757654 0.1282705  ... 0.24346642 0.1842913  0.27575165] Optimized Threshold: 0.04784618720395373\n",
      "Epoch: 33 Critic Loss: [0.12681614 0.12694462 0.12763636 ... 0.24249418 0.18348607 0.2746924 ] Optimized Threshold: 0.04761272512493475\n",
      "Epoch: 34 Critic Loss: [0.12618694 0.12631498 0.12700449 ... 0.24152496 0.18268351 0.2736363 ] Optimized Threshold: 0.04738000812694598\n",
      "Epoch: 35 Critic Loss: [0.12556002 0.12568766 0.12637495 ... 0.24055877 0.18188363 0.27258345] Optimized Threshold: 0.04714804627864999\n",
      "Epoch: 36 Critic Loss: [0.12493541 0.12506266 0.12574773 ... 0.23959565 0.18108645 0.27153388] Optimized Threshold: 0.04691684629248849\n",
      "Epoch: 37 Critic Loss: [0.12431309 0.12443992 0.12512279 ... 0.23863557 0.18029192 0.27048752] Optimized Threshold: 0.046686424949565763\n",
      "Epoch: 38 Critic Loss: [0.12369306 0.12381946 0.12450013 ... 0.23767847 0.17950006 0.2694443 ] Optimized Threshold: 0.04645678224988181\n",
      "Epoch: 39 Critic Loss: [0.12307531 0.1232013  0.12387977 ... 0.2367244  0.17871088 0.26840428] Optimized Threshold: 0.04622793161832006\n",
      "Epoch: 40 Critic Loss: [0.12245982 0.12258544 0.12326169 ... 0.23577337 0.17792434 0.26736754] Optimized Threshold: 0.04599987976732223\n",
      "Epoch: 41 Critic Loss: [0.12184663 0.12197183 0.12264591 ... 0.23482536 0.17714047 0.26633397] Optimized Threshold: 0.045772630053109165\n",
      "Epoch: 42 Critic Loss: [0.1212357  0.1213605  0.12203237 ... 0.23388034 0.17635924 0.26530358] Optimized Threshold: 0.0455461959005643\n",
      "Epoch: 43 Critic Loss: [0.12062704 0.12075142 0.12142112 ... 0.23293829 0.17558065 0.26427633] Optimized Threshold: 0.045320590734571065\n",
      "Epoch: 44 Critic Loss: [0.12002062 0.12014461 0.12081213 ... 0.2319993  0.17480469 0.26325232] Optimized Threshold: 0.04509580784268774\n",
      "Epoch: 45 Critic Loss: [0.11941646 0.11954004 0.1202054  ... 0.23106322 0.17403138 0.26223144] Optimized Threshold: 0.04487186064979776\n",
      "Epoch: 46 Critic Loss: [0.11881454 0.11893772 0.11960092 ... 0.23013014 0.17326067 0.26121375] Optimized Threshold: 0.044648755868342827\n",
      "Epoch: 47 Critic Loss: [0.11821488 0.11833767 0.1189987  ... 0.22920007 0.1724926  0.26019916] Optimized Threshold: 0.04442650356698552\n",
      "Epoch: 48 Critic Loss: [0.11761744 0.11773983 0.1183987  ... 0.22827291 0.17172712 0.25918776] Optimized Threshold: 0.04420510038950498\n",
      "Epoch: 49 Critic Loss: [0.11702223 0.11714421 0.11780094 ... 0.22734874 0.17096427 0.25817952] Optimized Threshold: 0.04398456647322635\n",
      "Epoch: 50 Critic Loss: [0.11642927 0.11655085 0.1172054  ... 0.22642754 0.170204   0.25717434] Optimized Threshold: 0.043764891749487056\n",
      "Epoch: 51 Critic Loss: [0.11583851 0.11595969 0.11661212 ... 0.22550927 0.16944633 0.2561724 ] Optimized Threshold: 0.04354609635561224\n",
      "Epoch: 52 Critic Loss: [0.11524998 0.11537073 0.11602104 ... 0.22459394 0.16869125 0.25517347] Optimized Threshold: 0.043328176935381046\n",
      "Epoch: 53 Critic Loss: [0.11466363 0.11478403 0.1154322  ... 0.22368157 0.16793877 0.25417772] Optimized Threshold: 0.0431111469136769\n",
      "Epoch: 54 Critic Loss: [0.11407951 0.1141995  0.11484555 ... 0.2227721  0.16718887 0.2531851 ] Optimized Threshold: 0.04289500293427895\n",
      "Epoch: 55 Critic Loss: [0.11349759 0.11361718 0.11426111 ... 0.22186555 0.16644153 0.25219557] Optimized Threshold: 0.042679755065849756\n",
      "Epoch: 56 Critic Loss: [0.11291785 0.11303705 0.11367887 ... 0.22096194 0.16569676 0.2512091 ] Optimized Threshold: 0.042465406664610184\n",
      "Epoch: 57 Critic Loss: [0.11234031 0.11245913 0.11309882 ... 0.22006124 0.16495454 0.25022572] Optimized Threshold: 0.04225196108678109\n",
      "Epoch: 58 Critic Loss: [0.11176497 0.11188338 0.11252098 ... 0.21916343 0.1642149  0.2492455 ] Optimized Threshold: 0.042039428401025036\n",
      "Epoch: 59 Critic Loss: [0.11119179 0.11130983 0.11194529 ... 0.21826859 0.1634778  0.2482683 ] Optimized Threshold: 0.041827805251121175\n",
      "Epoch: 60 Critic Loss: [0.1106208  0.11073843 0.1113718  ... 0.21737656 0.16274326 0.24729416] Optimized Threshold: 0.04161709834951122\n",
      "Epoch: 61 Critic Loss: [0.11005196 0.1101692  0.1108005  ... 0.21648742 0.16201122 0.24632314] Optimized Threshold: 0.041407314408636875\n",
      "Epoch: 62 Critic Loss: [0.10948531 0.10960216 0.11023137 ... 0.2156012  0.16128175 0.24535511] Optimized Threshold: 0.041198456784719006\n",
      "Epoch: 63 Critic Loss: [0.1089208  0.10903727 0.10966439 ... 0.21471784 0.16055478 0.24439019] Optimized Threshold: 0.040990522121536754\n",
      "Epoch: 64 Critic Loss: [0.10835845 0.10847454 0.10909957 ... 0.21383731 0.15983036 0.2434283 ] Optimized Threshold: 0.04078352048775269\n",
      "Epoch: 65 Critic Loss: [0.10779826 0.10791396 0.10853691 ... 0.2129597  0.15910845 0.24246943] Optimized Threshold: 0.04057745523958767\n",
      "Epoch: 66 Critic Loss: [0.10724019 0.10735551 0.10797642 ... 0.21208495 0.15838906 0.24151362] Optimized Threshold: 0.040372329733262546\n",
      "Epoch: 67 Critic Loss: [0.10668429 0.10679922 0.10741805 ... 0.21121301 0.15767218 0.24056087] Optimized Threshold: 0.04016813725633561\n",
      "Epoch: 68 Critic Loss: [0.10613051 0.10624505 0.10686184 ... 0.21034396 0.15695778 0.23961112] Optimized Threshold: 0.039964897946132005\n",
      "Epoch: 69 Critic Loss: [0.10557885 0.10569303 0.10630775 ... 0.20947774 0.15624589 0.23866434] Optimized Threshold: 0.0397625983777683\n",
      "Epoch: 70 Critic Loss: [0.10502934 0.10514311 0.10575579 ... 0.20861433 0.15553647 0.2377206 ] Optimized Threshold: 0.03956124526368621\n",
      "Epoch: 71 Critic Loss: [0.10448193 0.10459534 0.10520598 ... 0.20775375 0.15482956 0.23677988] Optimized Threshold: 0.039360841960106585\n",
      "Epoch: 72 Critic Loss: [0.10393663 0.10404968 0.10465825 ... 0.20689599 0.15412512 0.23584215] Optimized Threshold: 0.03916139182325029\n",
      "Epoch: 73 Critic Loss: [0.10339347 0.10350612 0.10411267 ... 0.20604107 0.15342315 0.23490742] Optimized Threshold: 0.03896289149689647\n",
      "Epoch: 74 Critic Loss: [0.10285238 0.10296466 0.10356918 ... 0.20518892 0.15272364 0.23397565] Optimized Threshold: 0.038765351049707686\n",
      "Epoch: 75 Critic Loss: [0.10231342 0.10242531 0.10302778 ... 0.20433964 0.1520266  0.23304687] Optimized Threshold: 0.03856876712546309\n",
      "Epoch: 76 Critic Loss: [0.10177652 0.10188805 0.10248852 ... 0.20349309 0.151332   0.2321211 ] Optimized Threshold: 0.03837314308038353\n",
      "Epoch: 77 Critic Loss: [0.10124173 0.10135288 0.10195135 ... 0.20264935 0.15063988 0.23119825] Optimized Threshold: 0.0381784722020273\n",
      "Epoch: 78 Critic Loss: [0.10070902 0.1008198  0.10141623 ... 0.20180841 0.14995019 0.23027836] Optimized Threshold: 0.037984771271498685\n",
      "Epoch: 79 Critic Loss: [0.10017838 0.1002888  0.10088323 ... 0.20097025 0.14926293 0.22936144] Optimized Threshold: 0.03779202015147254\n",
      "Epoch: 80 Critic Loss: [0.09964983 0.09975984 0.10035229 ... 0.20013484 0.14857814 0.22844747] Optimized Threshold: 0.037600235623053146\n",
      "Epoch: 81 Critic Loss: [0.09912334 0.09923299 0.09982345 ... 0.19930221 0.14789575 0.22753642] Optimized Threshold: 0.03740941433001965\n",
      "Epoch: 82 Critic Loss: [0.09859893 0.0987082  0.09929664 ... 0.19847234 0.14721577 0.22662833] Optimized Threshold: 0.0372195529161512\n",
      "Epoch: 83 Critic Loss: [0.09807654 0.09818547 0.09877192 ... 0.19764525 0.14653824 0.22572313] Optimized Threshold: 0.0370306580938895\n",
      "Epoch: 84 Critic Loss: [0.09755625 0.09766478 0.09824926 ... 0.19682088 0.14586312 0.22482088] Optimized Threshold: 0.036842723150792844\n",
      "Epoch: 85 Critic Loss: [0.09703798 0.09714616 0.09772865 ... 0.19599925 0.1451904  0.22392154] Optimized Threshold: 0.0366557581555238\n",
      "Epoch: 86 Critic Loss: [0.09652176 0.09662957 0.0972101  ... 0.19518037 0.14452006 0.22302511] Optimized Threshold: 0.03646974968319894\n",
      "Epoch: 87 Critic Loss: [0.0960076  0.09611505 0.09669358 ... 0.19436422 0.14385214 0.22213162] Optimized Threshold: 0.03628470780248083\n",
      "Epoch: 88 Critic Loss: [0.09549545 0.09560253 0.0961791  ... 0.1935508  0.1431866  0.22124098] Optimized Threshold: 0.03610062915714862\n",
      "Epoch: 89 Critic Loss: [0.09498533 0.09509204 0.09566666 ... 0.19274008 0.14252347 0.22035325] Optimized Threshold: 0.035917510390981455\n",
      "Epoch: 90 Critic Loss: [0.09447724 0.09458359 0.09515624 ... 0.19193211 0.14186269 0.21946841] Optimized Threshold: 0.03573535150397933\n",
      "Epoch: 91 Critic Loss: [0.09397116 0.09407715 0.09464786 ... 0.19112681 0.14120428 0.21858646] Optimized Threshold: 0.03555415920858396\n",
      "Epoch: 92 Critic Loss: [0.09346711 0.09357274 0.0941415  ... 0.19032423 0.14054826 0.21770738] Optimized Threshold: 0.03537392679235363\n",
      "Epoch: 93 Critic Loss: [0.09296506 0.09307031 0.09363715 ... 0.18952435 0.1398946  0.21683116] Optimized Threshold: 0.03519465425528834\n",
      "Epoch: 94 Critic Loss: [0.09246501 0.09256991 0.09313481 ... 0.18872716 0.13924329 0.21595779] Optimized Threshold: 0.03501633152872552\n",
      "Epoch: 95 Critic Loss: [0.09196697 0.09207151 0.09263445 ... 0.18793263 0.13859433 0.21508728] Optimized Threshold: 0.0348389720375486\n",
      "Epoch: 96 Critic Loss: [0.0914709  0.09157509 0.09213611 ... 0.18714082 0.1379477  0.21421961] Optimized Threshold: 0.03466256906931586\n",
      "Epoch: 97 Critic Loss: [0.09097682 0.09108066 0.09163976 ... 0.18635163 0.13730344 0.2133548 ] Optimized Threshold: 0.034487119267806454\n",
      "Epoch: 98 Critic Loss: [0.09048475 0.09058823 0.09114539 ... 0.18556514 0.13666148 0.21249281] Optimized Threshold: 0.034312619276799516\n",
      "Epoch: 99 Critic Loss: [0.08999464 0.09009777 0.09065303 ... 0.18478131 0.1360219  0.21163365] Optimized Threshold: 0.03413907916495762\n",
      "Epoch: 100 Critic Loss: [0.08950651 0.0896093  0.09016264 ... 0.1840001  0.1353846  0.21077731] Optimized Threshold: 0.03396648215117648\n",
      "Epoch: 101 Critic Loss: [0.08902037 0.08912279 0.08967422 ... 0.18322158 0.13474965 0.20992382] Optimized Threshold: 0.033794831591676955\n",
      "Epoch: 102 Critic Loss: [0.08853617 0.08863824 0.08918778 ... 0.18244568 0.13411699 0.2090731 ] Optimized Threshold: 0.03362412748645904\n",
      "Epoch: 103 Critic Loss: [0.08805393 0.08815565 0.08870329 ... 0.18167242 0.13348666 0.2082252 ] Optimized Threshold: 0.033454369835522746\n",
      "Epoch: 104 Critic Loss: [0.08757366 0.08767501 0.08822075 ... 0.1809018  0.1328586  0.20738009] Optimized Threshold: 0.033285555282647206\n",
      "Epoch: 105 Critic Loss: [0.08709532 0.08719632 0.08774018 ... 0.1801338  0.13223286 0.20653778] Optimized Threshold: 0.033117680471611566\n",
      "Epoch: 106 Critic Loss: [0.08661892 0.08671957 0.08726156 ... 0.1793684  0.13160942 0.20569828] Optimized Threshold: 0.03295074204619497\n",
      "Epoch: 107 Critic Loss: [0.08614449 0.08624478 0.08678488 ... 0.17860565 0.13098824 0.20486155] Optimized Threshold: 0.03278474000639742\n",
      "Epoch: 108 Critic Loss: [0.08567196 0.08577192 0.08631016 ... 0.17784546 0.13036938 0.20402756] Optimized Threshold: 0.03261967099599805\n",
      "Epoch: 109 Critic Loss: [0.08520139 0.08530099 0.08583736 ... 0.17708792 0.12975276 0.20319635] Optimized Threshold: 0.03245553501499687\n",
      "Epoch: 110 Critic Loss: [0.08473273 0.08483198 0.08536647 ... 0.17633294 0.12913841 0.20236793] Optimized Threshold: 0.03229232535095217\n",
      "Epoch: 111 Critic Loss: [0.08426598 0.08436489 0.08489754 ... 0.17558056 0.12852636 0.20154226] Optimized Threshold: 0.03213003529142222\n",
      "Epoch: 112 Critic Loss: [0.08380116 0.08389973 0.08443049 ... 0.17483076 0.12791653 0.20071934] Optimized Threshold: 0.031968674905069605\n",
      "Epoch: 113 Critic Loss: [0.08333823 0.08343646 0.08396538 ... 0.17408352 0.12730895 0.19989914] Optimized Threshold: 0.03180823412323175\n",
      "Epoch: 114 Critic Loss: [0.08287721 0.0829751  0.08350217 ... 0.17333889 0.12670365 0.19908169] Optimized Threshold: 0.031648709589687796\n",
      "Epoch: 115 Critic Loss: [0.08241811 0.08251563 0.08304087 ... 0.1725968  0.12610057 0.19826697] Optimized Threshold: 0.031490101304437745\n",
      "Epoch: 116 Critic Loss: [0.08196089 0.08205807 0.08258148 ... 0.17185727 0.12549974 0.19745497] Optimized Threshold: 0.031332402555039884\n",
      "Epoch: 117 Critic Loss: [0.08150554 0.0816024  0.08212398 ... 0.17112029 0.12490112 0.19664566] Optimized Threshold: 0.031175609985273356\n",
      "Epoch: 118 Critic Loss: [0.08105211 0.08114862 0.08166836 ... 0.17038587 0.12430474 0.1958391 ] Optimized Threshold: 0.03101972359513816\n",
      "Epoch: 119 Critic Loss: [0.08060054 0.08069672 0.08121464 ... 0.16965398 0.12371059 0.19503528] Optimized Threshold: 0.030864746740855153\n",
      "Epoch: 120 Critic Loss: [0.08015084 0.08024669 0.08076277 ... 0.16892463 0.12311865 0.19423412] Optimized Threshold: 0.030710659285099196\n",
      "Epoch: 121 Critic Loss: [0.07970303 0.07979852 0.0803128  ... 0.16819781 0.12252891 0.19343565] Optimized Threshold: 0.030557474652753713\n",
      "Epoch: 122 Critic Loss: [0.07925707 0.07935224 0.0798647  ... 0.16747352 0.1219414  0.19263987] Optimized Threshold: 0.03040517941893528\n",
      "Epoch: 123 Critic Loss: [0.07881299 0.07890781 0.07941848 ... 0.16675176 0.12135606 0.19184679] Optimized Threshold: 0.03025378029608561\n",
      "Epoch: 124 Critic Loss: [0.07837075 0.07846522 0.07897408 ... 0.16603248 0.12077292 0.19105636] Optimized Threshold: 0.030103260503100415\n",
      "Epoch: 125 Critic Loss: [0.07793035 0.07802451 0.07853155 ... 0.1653157  0.12019197 0.19026862] Optimized Threshold: 0.029953623396200557\n",
      "Epoch: 126 Critic Loss: [0.07749181 0.07758564 0.07809088 ... 0.16460146 0.11961321 0.18948354] Optimized Threshold: 0.029804868975386034\n",
      "Epoch: 127 Critic Loss: [0.0770551  0.07714858 0.07765206 ... 0.16388968 0.11903661 0.1887011 ] Optimized Threshold: 0.02965698381577342\n",
      "Epoch: 128 Critic Loss: [0.07662024 0.07671339 0.07721508 ... 0.1631804  0.1184622  0.18792132] Optimized Threshold: 0.029509974629804425\n",
      "Epoch: 129 Critic Loss: [0.0761872  0.07628002 0.07677993 ... 0.16247362 0.11788996 0.18714419] Optimized Threshold: 0.02936383470503734\n",
      "Epoch: 130 Critic Loss: [0.07575599 0.07584848 0.07634661 ... 0.16176932 0.11731987 0.18636972] Optimized Threshold: 0.029218560685251305\n",
      "Epoch: 131 Critic Loss: [0.0753266  0.07541876 0.07591513 ... 0.16106746 0.11675194 0.18559785] Optimized Threshold: 0.02907414250178375\n",
      "Epoch: 132 Critic Loss: [0.07489903 0.07499086 0.07548546 ... 0.16036807 0.11618616 0.18482864] Optimized Threshold: 0.028930590223297248\n",
      "Epoch: 133 Critic Loss: [0.07447326 0.07456477 0.0750576  ... 0.15967119 0.11562252 0.18406203] Optimized Threshold: 0.028787883712466655\n",
      "Epoch: 134 Critic Loss: [0.07404931 0.07414047 0.07463155 ... 0.1589767  0.11506104 0.18329802] Optimized Threshold: 0.028646033037954544\n",
      "Epoch: 135 Critic Loss: [0.07362715 0.073718   0.07420733 ... 0.15828468 0.11450168 0.18253663] Optimized Threshold: 0.028505028131098342\n",
      "Epoch: 136 Critic Loss: [0.07320679 0.07329732 0.07378487 ... 0.1575951  0.11394444 0.18177785] Optimized Threshold: 0.02836485892323548\n",
      "Epoch: 137 Critic Loss: [0.07278822 0.07287843 0.07336424 ... 0.15690795 0.11338932 0.18102168] Optimized Threshold: 0.02822553548302853\n",
      "Epoch: 138 Critic Loss: [0.07237145 0.07246132 0.07294539 ... 0.15622324 0.11283635 0.18026808] Optimized Threshold: 0.028087044385594062\n",
      "Epoch: 139 Critic Loss: [0.07195646 0.072046   0.07252833 ... 0.15554097 0.11228546 0.17951708] Optimized Threshold: 0.02794938395282165\n",
      "Epoch: 140 Critic Loss: [0.07154323 0.07163246 0.07211306 ... 0.15486108 0.11173669 0.17876863] Optimized Threshold: 0.027812547472269578\n",
      "Epoch: 141 Critic Loss: [0.07113177 0.07122069 0.07169955 ... 0.15418363 0.11119003 0.17802277] Optimized Threshold: 0.027676539978269132\n",
      "Epoch: 142 Critic Loss: [0.0707221  0.0708107  0.07128783 ... 0.15350859 0.11064544 0.1772795 ] Optimized Threshold: 0.027541348045936886\n",
      "Epoch: 143 Critic Loss: [0.07031417 0.07040245 0.07087786 ... 0.15283595 0.11010297 0.17653875] Optimized Threshold: 0.027406966640941555\n",
      "Epoch: 144 Critic Loss: [0.06990802 0.06999596 0.07046968 ... 0.1521657  0.10956258 0.17580056] Optimized Threshold: 0.027273400797614422\n",
      "Epoch: 145 Critic Loss: [0.06950361 0.06959124 0.07006325 ... 0.15149783 0.10902426 0.17506497] Optimized Threshold: 0.027140643803513775\n",
      "Epoch: 146 Critic Loss: [0.06910096 0.06918826 0.06965856 ... 0.15083236 0.10848803 0.17433187] Optimized Threshold: 0.027008683911866616\n",
      "Epoch: 147 Critic Loss: [0.06870002 0.06878704 0.06925561 ... 0.15016927 0.10795386 0.1736013 ] Optimized Threshold: 0.026877527835114656\n",
      "Epoch: 148 Critic Loss: [0.06830085 0.06838753 0.06885441 ... 0.14950852 0.10742176 0.17287332] Optimized Threshold: 0.026747165504595327\n",
      "Epoch: 149 Critic Loss: [0.0679034  0.06798978 0.06845497 ... 0.14885016 0.10689171 0.1721478 ] Optimized Threshold: 0.026617591885977343\n",
      "Epoch: 150 Critic Loss: [0.06750769 0.06759373 0.06805725 ... 0.14819415 0.10636374 0.17142482] Optimized Threshold: 0.026488803623039847\n",
      "Epoch: 151 Critic Loss: [0.0671137  0.06719943 0.06766126 ... 0.14754052 0.1058378  0.17070436] Optimized Threshold: 0.026360795681451554\n",
      "Epoch: 152 Critic Loss: [0.06672142 0.06680686 0.06726699 ... 0.14688924 0.1053139  0.16998641] Optimized Threshold: 0.026233569739322893\n",
      "Epoch: 153 Critic Loss: [0.06633087 0.06641597 0.06687442 ... 0.14624028 0.10479204 0.16927095] Optimized Threshold: 0.026107115727991292\n",
      "Epoch: 154 Critic Loss: [0.06594201 0.06602682 0.06648361 ... 0.14559364 0.10427222 0.16855799] Optimized Threshold: 0.02598143700367761\n",
      "Epoch: 155 Critic Loss: [0.06555486 0.06563936 0.06609446 ... 0.14494936 0.10375441 0.1678475 ] Optimized Threshold: 0.02585651678527756\n",
      "Epoch: 156 Critic Loss: [0.06516941 0.06525361 0.06570705 ... 0.14430742 0.10323865 0.16713952] Optimized Threshold: 0.02573236178523286\n",
      "Epoch: 157 Critic Loss: [0.06478568 0.06486955 0.06532133 ... 0.14366777 0.10272488 0.16643399] Optimized Threshold: 0.025608961934880936\n",
      "Epoch: 158 Critic Loss: [0.06440361 0.06448718 0.0649373  ... 0.14303045 0.10221314 0.16573097] Optimized Threshold: 0.02548631723422179\n",
      "Epoch: 159 Critic Loss: [0.06402323 0.06410649 0.06455497 ... 0.14239544 0.1017034  0.16503035] Optimized Threshold: 0.025364422648924134\n",
      "Epoch: 160 Critic Loss: [0.06364454 0.06372751 0.06417432 ... 0.14176273 0.10119567 0.16433223] Optimized Threshold: 0.0252432681103254\n",
      "Epoch: 161 Critic Loss: [0.06326753 0.06335018 0.06379536 ... 0.14113232 0.10068993 0.16363658] Optimized Threshold: 0.02512285361842559\n",
      "Epoch: 162 Critic Loss: [0.06289218 0.06297453 0.06341807 ... 0.14050421 0.10018618 0.16294336] Optimized Threshold: 0.025003180851335127\n",
      "Epoch: 163 Critic Loss: [0.06251851 0.06260053 0.06304244 ... 0.13987838 0.09968442 0.16225256] Optimized Threshold: 0.024884236384170588\n",
      "Epoch: 164 Critic Loss: [0.06214649 0.06222822 0.06266849 ... 0.13925482 0.09918463 0.16156423] Optimized Threshold: 0.0247660218950424\n",
      "Epoch: 165 Critic Loss: [0.06177613 0.06185756 0.0622962  ... 0.13863355 0.09868684 0.16087833] Optimized Threshold: 0.024648527315287994\n",
      "Epoch: 166 Critic Loss: [0.06140743 0.06148856 0.06192557 ... 0.13801454 0.098191   0.16019483] Optimized Threshold: 0.024531756001128224\n",
      "Epoch: 167 Critic Loss: [0.06104036 0.0611212  0.06155658 ... 0.13739781 0.09769712 0.15951374] Optimized Threshold: 0.02441569956201095\n",
      "Epoch: 168 Critic Loss: [0.06067494 0.06075547 0.06118925 ... 0.13678332 0.09720521 0.15883505] Optimized Threshold: 0.024300354641715316\n",
      "Epoch: 169 Critic Loss: [0.06031116 0.06039139 0.06082356 ... 0.13617106 0.09671525 0.15815881] Optimized Threshold: 0.024185714527799607\n",
      "Epoch: 170 Critic Loss: [0.05994902 0.06002894 0.06045951 ... 0.13556108 0.09622724 0.15748495] Optimized Threshold: 0.02407178089837425\n",
      "Epoch: 171 Critic Loss: [0.05958849 0.05966813 0.06009708 ... 0.13495332 0.09574118 0.15681347] Optimized Threshold: 0.02395854200666625\n",
      "Epoch: 172 Critic Loss: [0.0592296  0.05930894 0.0597363  ... 0.13434783 0.09525704 0.15614438] Optimized Threshold: 0.023845999530786033\n",
      "Epoch: 173 Critic Loss: [0.05887233 0.05895137 0.05937713 ... 0.13374454 0.09477486 0.15547769] Optimized Threshold: 0.023734145080181457\n",
      "Epoch: 174 Critic Loss: [0.05851667 0.05859541 0.05901958 ... 0.13314348 0.09429458 0.15481335] Optimized Threshold: 0.023622978654852522\n",
      "Epoch: 175 Critic Loss: [0.05816262 0.05824107 0.05866364 ... 0.13254462 0.09381625 0.15415142] Optimized Threshold: 0.023512496898578372\n",
      "Epoch: 176 Critic Loss: [0.05781017 0.05788833 0.05830932 ... 0.131948   0.09333981 0.15349181] Optimized Threshold: 0.023402688064586008\n",
      "Epoch: 177 Critic Loss: [0.05745932 0.05753719 0.0579566  ... 0.13135357 0.0928653  0.15283456] Optimized Threshold: 0.023293555509096286\n",
      "Epoch: 178 Critic Loss: [0.05711007 0.05718764 0.05760548 ... 0.13076136 0.09239269 0.15217969] Optimized Threshold: 0.023185094197777922\n",
      "Epoch: 179 Critic Loss: [0.05676241 0.05683969 0.05725596 ... 0.13017133 0.09192199 0.15152715] Optimized Threshold: 0.023077295740078774\n",
      "Epoch: 180 Critic Loss: [0.05641634 0.05649332 0.05690803 ... 0.1295835  0.09145318 0.15087694] Optimized Threshold: 0.02297016013599884\n",
      "Epoch: 181 Critic Loss: [0.05607184 0.05614853 0.05656167 ... 0.12899782 0.09098626 0.1502291 ] Optimized Threshold: 0.022863677316875552\n",
      "Epoch: 182 Critic Loss: [0.05572893 0.05580533 0.05621691 ... 0.12841435 0.09052123 0.14958355] Optimized Threshold: 0.022757853995150623\n",
      "Epoch: 183 Critic Loss: [0.05538759 0.0554637  0.05587373 ... 0.12783305 0.0900581  0.14894035] Optimized Threshold: 0.022652676745940625\n",
      "Epoch: 184 Critic Loss: [0.05504781 0.05512363 0.05553211 ... 0.1272539  0.08959681 0.14829944] Optimized Threshold: 0.02254814389113513\n",
      "Epoch: 185 Critic Loss: [0.05470959 0.05478513 0.05519206 ... 0.12667693 0.08913741 0.14766088] Optimized Threshold: 0.022444252074513282\n",
      "Epoch: 186 Critic Loss: [0.05437293 0.05444819 0.05485357 ... 0.1261021  0.08867987 0.14702457] Optimized Threshold: 0.022340997939854224\n",
      "Epoch: 187 Critic Loss: [0.05403783 0.05411279 0.05451664 ... 0.12552944 0.0882242  0.14639062] Optimized Threshold: 0.022238378130937098\n",
      "Epoch: 188 Critic Loss: [0.05370427 0.05377895 0.05418127 ... 0.1249589  0.08777037 0.1457589 ] Optimized Threshold: 0.02213638593532019\n",
      "Epoch: 189 Critic Loss: [0.05337227 0.05344667 0.05384744 ... 0.12439052 0.08731841 0.14512952] Optimized Threshold: 0.022035016318672218\n",
      "Epoch: 190 Critic Loss: [0.05304179 0.0531159  0.05351516 ... 0.12382426 0.08686829 0.14450239] Optimized Threshold: 0.021934270959103608\n",
      "Epoch: 191 Critic Loss: [0.05271285 0.05278668 0.05318442 ... 0.12326014 0.08642    0.14387754] Optimized Threshold: 0.021834141466062218\n",
      "Epoch: 192 Critic Loss: [0.05238543 0.05245899 0.0528552  ... 0.12269811 0.08597354 0.14325498] Optimized Threshold: 0.021734622805216763\n",
      "Epoch: 193 Critic Loss: [0.05205957 0.05213283 0.05252752 ... 0.12213825 0.08552893 0.14263466] Optimized Threshold: 0.0216357183327881\n",
      "Epoch: 194 Critic Loss: [0.0517352  0.05180819 0.05220137 ... 0.12158048 0.08508614 0.1420166 ] Optimized Threshold: 0.021537414623892803\n",
      "Epoch: 195 Critic Loss: [0.05141237 0.05148506 0.05187674 ... 0.12102481 0.08464517 0.14140083] Optimized Threshold: 0.0214397133566413\n",
      "Epoch: 196 Critic Loss: [0.05109103 0.05116345 0.05155363 ... 0.12047122 0.08420601 0.14078727] Optimized Threshold: 0.02134261117481273\n",
      "Epoch: 197 Critic Loss: [0.0507712  0.05084335 0.05123202 ... 0.11991975 0.08376865 0.14017595] Optimized Threshold: 0.02124609800974453\n",
      "Epoch: 198 Critic Loss: [0.05045288 0.05052475 0.05091193 ... 0.11937037 0.08333313 0.1395669 ] Optimized Threshold: 0.02115017721765755\n",
      "Epoch: 199 Critic Loss: [0.05013606 0.05020765 0.05059334 ... 0.11882309 0.08289937 0.13896006] Optimized Threshold: 0.02105484376422051\n",
      "Optimized threshold: 0.02105484376422051\n",
      "125/125 [==============================] - 0s 1ms/step\n",
      "0.995\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(200):\n",
    "    # Chuẩn bị dữ liệu clustering\n",
    "    reward = get_clustering_based_reward(reconstruction_error)\n",
    "\n",
    "    # Thực hiện một bước gradient ascent cho Actor\n",
    "    with tf.GradientTape() as tape_actor:\n",
    "        action = actor(test_data)\n",
    "    grads_actor = tape_actor.gradient(action, actor.trainable_variables)\n",
    "    optimizer_actor.apply_gradients(zip(grads_actor, actor.trainable_variables))\n",
    "\n",
    "    # Thực hiện một bước gradient descent cho Critic\n",
    "    with tf.GradientTape() as tape_critic:\n",
    "        critic_value = critic(reconstruction_error)\n",
    "        critic_loss = keras.losses.mean_squared_error(reward, critic_value)\n",
    "    grads_critic = tape_critic.gradient(critic_loss, critic.trainable_variables)\n",
    "    optimizer_critic.apply_gradients(zip(grads_critic, critic.trainable_variables))\n",
    "\n",
    "    # Lưu lại giá trị threshold sau mỗi bước tối ưu hóa\n",
    "    optimized_threshold = actor(test_data).numpy()[0][0] * wrong_threshold\n",
    "\n",
    "    # Hiển thị thông tin về quá trình huấn luyện\n",
    "    print(\"Epoch:\", epoch, \"Critic Loss:\", critic_loss.numpy(), \"Optimized Threshold:\", optimized_threshold)\n",
    "\n",
    "# Đánh giá lại hiệu suất với threshold đã được tối ưu\n",
    "print(\"Optimized threshold:\",optimized_threshold)\n",
    "optimized_prediction = model.predict_class(test_data, optimized_threshold)\n",
    "print(accuracy_score(test['label'], optimized_prediction))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
